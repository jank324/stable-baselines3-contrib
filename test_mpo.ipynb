{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sb3_contrib import MPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Creating environment from the given name 'MountainCarContinuous-v0'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 999      |\n",
      "|    ep_rew_mean     | -33      |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 21888    |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 3996     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 999      |\n",
      "|    ep_rew_mean     | -33.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 21548    |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 7992     |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 999      |\n",
      "|    ep_rew_mean         | -43.6    |\n",
      "| time/                  |          |\n",
      "|    episodes            | 12       |\n",
      "|    fps                 | 1404     |\n",
      "|    time_elapsed        | 8        |\n",
      "|    total_timesteps     | 11988    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.81     |\n",
      "|    alpha_mean          | 1.22     |\n",
      "|    alpha_std           | 10.2     |\n",
      "|    critic_loss         | 0.000778 |\n",
      "|    dual_loss           | -0.39    |\n",
      "|    kl_loss             | 0.00203  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 999      |\n",
      "|    penalty_temperature | 1.42     |\n",
      "|    policy_loss         | 5.2      |\n",
      "|    temperature         | 1.21     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 999      |\n",
      "|    ep_rew_mean         | -49.5    |\n",
      "| time/                  |          |\n",
      "|    episodes            | 16       |\n",
      "|    fps                 | 398      |\n",
      "|    time_elapsed        | 40       |\n",
      "|    total_timesteps     | 15984    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.72     |\n",
      "|    alpha_mean          | 0.582    |\n",
      "|    alpha_std           | 11.2     |\n",
      "|    critic_loss         | 0.000391 |\n",
      "|    dual_loss           | -1.64    |\n",
      "|    kl_loss             | 0.0011   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 4995     |\n",
      "|    penalty_temperature | 2.09     |\n",
      "|    policy_loss         | 4.36     |\n",
      "|    temperature         | 0.581    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 999      |\n",
      "|    ep_rew_mean         | -48.4    |\n",
      "| time/                  |          |\n",
      "|    episodes            | 20       |\n",
      "|    fps                 | 278      |\n",
      "|    time_elapsed        | 71       |\n",
      "|    total_timesteps     | 19980    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.37     |\n",
      "|    alpha_mean          | 0.252    |\n",
      "|    alpha_std           | 12.4     |\n",
      "|    critic_loss         | 0.000184 |\n",
      "|    dual_loss           | -2.21    |\n",
      "|    kl_loss             | 0.00116  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 8991     |\n",
      "|    penalty_temperature | 2.45     |\n",
      "|    policy_loss         | 3.58     |\n",
      "|    temperature         | 0.258    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 999      |\n",
      "|    ep_rew_mean         | -45.1    |\n",
      "| time/                  |          |\n",
      "|    episodes            | 24       |\n",
      "|    fps                 | 232      |\n",
      "|    time_elapsed        | 103      |\n",
      "|    total_timesteps     | 23976    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 0.306    |\n",
      "|    alpha_mean          | 0.105    |\n",
      "|    alpha_std           | 13.6     |\n",
      "|    critic_loss         | 8.73e-05 |\n",
      "|    dual_loss           | -2.39    |\n",
      "|    kl_loss             | 0.00159  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 12987    |\n",
      "|    penalty_temperature | 1.7      |\n",
      "|    policy_loss         | 2.7      |\n",
      "|    temperature         | 0.113    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 999      |\n",
      "|    ep_rew_mean         | -41.3    |\n",
      "| time/                  |          |\n",
      "|    episodes            | 28       |\n",
      "|    fps                 | 207      |\n",
      "|    time_elapsed        | 135      |\n",
      "|    total_timesteps     | 27972    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -0.618   |\n",
      "|    alpha_mean          | 0.0434   |\n",
      "|    alpha_std           | 14.9     |\n",
      "|    critic_loss         | 3.98e-05 |\n",
      "|    dual_loss           | -2.34    |\n",
      "|    kl_loss             | 0.00211  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 16983    |\n",
      "|    penalty_temperature | 0.845    |\n",
      "|    policy_loss         | 1.72     |\n",
      "|    temperature         | 0.0513   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 999      |\n",
      "|    ep_rew_mean         | -37.6    |\n",
      "| time/                  |          |\n",
      "|    episodes            | 32       |\n",
      "|    fps                 | 191      |\n",
      "|    time_elapsed        | 166      |\n",
      "|    total_timesteps     | 31968    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -1.45    |\n",
      "|    alpha_mean          | 0.0178   |\n",
      "|    alpha_std           | 16.1     |\n",
      "|    critic_loss         | 1.75e-05 |\n",
      "|    dual_loss           | -2.15    |\n",
      "|    kl_loss             | 0.00248  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 20979    |\n",
      "|    penalty_temperature | 0.364    |\n",
      "|    policy_loss         | 0.697    |\n",
      "|    temperature         | 0.0248   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 999      |\n",
      "|    ep_rew_mean         | -34.2    |\n",
      "| time/                  |          |\n",
      "|    episodes            | 36       |\n",
      "|    fps                 | 181      |\n",
      "|    time_elapsed        | 198      |\n",
      "|    total_timesteps     | 35964    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -2.23    |\n",
      "|    alpha_mean          | 0.00731  |\n",
      "|    alpha_std           | 17.3     |\n",
      "|    critic_loss         | 8.29e-06 |\n",
      "|    dual_loss           | -1.91    |\n",
      "|    kl_loss             | 0.00267  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 24975    |\n",
      "|    penalty_temperature | 0.15     |\n",
      "|    policy_loss         | -0.328   |\n",
      "|    temperature         | 0.0132   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 999      |\n",
      "|    ep_rew_mean         | -31.2    |\n",
      "| time/                  |          |\n",
      "|    episodes            | 40       |\n",
      "|    fps                 | 173      |\n",
      "|    time_elapsed        | 229      |\n",
      "|    total_timesteps     | 39960    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -2.96    |\n",
      "|    alpha_mean          | 0.003    |\n",
      "|    alpha_std           | 18.5     |\n",
      "|    critic_loss         | 4.18e-06 |\n",
      "|    dual_loss           | -1.65    |\n",
      "|    kl_loss             | 0.00265  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 28971    |\n",
      "|    penalty_temperature | 0.0619   |\n",
      "|    policy_loss         | -1.31    |\n",
      "|    temperature         | 0.00771  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 999      |\n",
      "|    ep_rew_mean         | -28.6    |\n",
      "| time/                  |          |\n",
      "|    episodes            | 44       |\n",
      "|    fps                 | 168      |\n",
      "|    time_elapsed        | 261      |\n",
      "|    total_timesteps     | 43956    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -3.65    |\n",
      "|    alpha_mean          | 0.00123  |\n",
      "|    alpha_std           | 19.6     |\n",
      "|    critic_loss         | 2.74e-06 |\n",
      "|    dual_loss           | -1.4     |\n",
      "|    kl_loss             | 0.00254  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 32967    |\n",
      "|    penalty_temperature | 0.0254   |\n",
      "|    policy_loss         | -2.25    |\n",
      "|    temperature         | 0.00477  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 999      |\n",
      "|    ep_rew_mean         | -26.4    |\n",
      "| time/                  |          |\n",
      "|    episodes            | 48       |\n",
      "|    fps                 | 163      |\n",
      "|    time_elapsed        | 293      |\n",
      "|    total_timesteps     | 47952    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -4.32    |\n",
      "|    alpha_mean          | 0.000508 |\n",
      "|    alpha_std           | 20.8     |\n",
      "|    critic_loss         | 2.77e-06 |\n",
      "|    dual_loss           | -1.18    |\n",
      "|    kl_loss             | 0.00243  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 36963    |\n",
      "|    penalty_temperature | 0.0104   |\n",
      "|    policy_loss         | -3.14    |\n",
      "|    temperature         | 0.00305  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.mpo.mpo.MPO at 0x16a709280>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MPO(policy=\"MlpPolicy\", env=\"MountainCarContinuous-v0\", verbose=2)\n",
    "model.learn(total_timesteps=50_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.02586734]], dtype=float32), None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.ones((1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable-baselines3-contrib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
