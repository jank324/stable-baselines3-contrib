{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sb3_contrib import MPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Creating environment from the given name 'BipedalWalker-v3'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 83.2     |\n",
      "|    ep_rew_mean     | -111     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 5410     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 333      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 462      |\n",
      "|    ep_rew_mean     | -100     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 5957     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 3693     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 332      |\n",
      "|    ep_rew_mean     | -104     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 5913     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 3985     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 465      |\n",
      "|    ep_rew_mean     | -102     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 5992     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 7434     |\n",
      "---------------------------------\n",
      "---------------\n",
      "next_action_samples.shape = torch.Size([20, 100, 4])\n",
      "---------------\n",
      "tiled_observations.shape = torch.Size([20, 100, 24])\n",
      "tiled_next_observations.shape = torch.Size([20, 100, 24])\n",
      "---------------\n",
      "flat_observations.shape = torch.Size([2000, 24])\n",
      "flat_next_observations.shape = torch.Size([2000, 24])\n",
      "flat_actions.shape = torch.Size([2000, 4])\n",
      "---------------\n",
      "flat_values.shape = torch.Size([2000, 1])\n",
      "flat_next_values.shape = torch.Size([2000, 1])\n",
      "---------------\n",
      "values.shape = torch.Size([20, 100, 1])\n",
      "next_values.shape = torch.Size([20, 100, 1])\n",
      "---------------\n",
      "replay_data.rewards.shape = torch.Size([100, 1])\n",
      "replay_data.dones.shape = torch.Size([100, 1])\n",
      "---------------\n",
      "returns.shape = torch.Size([100, 1])\n",
      "target_distributions = Independent(Normal(loc: torch.Size([100, 4]), scale: torch.Size([100, 4])), -1)\n",
      "---------------\n",
      "distributions = Normal(loc: torch.Size([100, 4]), scale: torch.Size([100, 4]))\n",
      "distributions = Independent(Normal(loc: torch.Size([100, 4]), scale: torch.Size([100, 4])), -1)\n",
      " -- q_values.shape = torch.Size([20, 100, 1])\n",
      " -- epsilon = 0.1\n",
      " -- temperature.shape = torch.Size([]) / temperature = tensor(1.3133, grad_fn=<AddBackward0>)\n",
      " -- tempered_q_values.shape = torch.Size([20, 100, 1])\n",
      " -- weights.shape = torch.Size([20, 100, 1])\n",
      " -- q_log_sum_exp.shape = torch.Size([100, 1])\n",
      " -- num_actions.shape = torch.Size([]) / num_actions = tensor(20.)\n",
      " -- log_num_actions.shape = torch.Size([]) / log_num_actions = tensor(2.9957)\n",
      " -- BEFORE TEMPERATURE loss.shape = torch.Size([]) / loss = tensor(0.0561, grad_fn=<SubBackward0>)\n",
      " -- AFTER TEMPERATURE loss.shape = torch.Size([]) / loss = tensor(0.0737, grad_fn=<MulBackward0>)\n",
      "---------------\n",
      "self.log_temperature.shape = torch.Size([]) / self.log_temperature = Parameter containing:\n",
      "tensor(1., requires_grad=True)\n",
      "temperature.shape = torch.Size([]) / temperature = tensor(1.3133, grad_fn=<AddBackward0>)\n",
      "self.log_alpha_mean.shape = torch.Size([4]) / self.log_alpha_mean = Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "alpha_mean.shape = torch.Size([4]) / alpha_mean = tensor([1.3133, 1.3133, 1.3133, 1.3133], grad_fn=<AddBackward0>)\n",
      "self.log_alpha_std.shape = torch.Size([4]) / self.log_alpha_std = Parameter containing:\n",
      "tensor([10., 10., 10., 10.], requires_grad=True)\n",
      "alpha_std.shape = torch.Size([4]) / alpha_std = tensor([10.0000, 10.0000, 10.0000, 10.0000], grad_fn=<AddBackward0>)\n",
      "weights.shape = torch.Size([20, 100, 1])\n",
      "temperature_loss.shape = torch.Size([]) / temperature_loss = tensor(0.0737, grad_fn=<MulBackward0>)\n",
      "---------------\n",
      "self.log_penalty_temperature.shape = torch.Size([]) / self.log_penalty_temperature = Parameter containing:\n",
      "tensor(1., requires_grad=True)\n",
      "penalty_temperature.shape = torch.Size([]) / penalty_temperature = tensor(1.3133, grad_fn=<AddBackward0>)\n",
      "diff_bounds.shape = torch.Size([20, 100, 4])\n",
      "action_bound_costs.shape = torch.Size([20, 100, 1])\n",
      " -- q_values.shape = torch.Size([20, 100, 1])\n",
      " -- epsilon = 0.001\n",
      " -- temperature.shape = torch.Size([]) / temperature = tensor(1.3133, grad_fn=<AddBackward0>)\n",
      " -- tempered_q_values.shape = torch.Size([20, 100, 1])\n",
      " -- weights.shape = torch.Size([20, 100, 1])\n",
      " -- q_log_sum_exp.shape = torch.Size([100, 1])\n",
      " -- num_actions.shape = torch.Size([]) / num_actions = tensor(20.)\n",
      " -- log_num_actions.shape = torch.Size([]) / log_num_actions = tensor(2.9957)\n",
      " -- BEFORE TEMPERATURE loss.shape = torch.Size([]) / loss = tensor(-0.3445, grad_fn=<SubBackward0>)\n",
      " -- AFTER TEMPERATURE loss.shape = torch.Size([]) / loss = tensor(-0.4524, grad_fn=<MulBackward0>)\n",
      "penalty_weights.shape = torch.Size([20, 100, 1])\n",
      "penalty_temperature_loss.shape = torch.Size([]) / penalty_temperature_loss = tensor(-0.4524, grad_fn=<MulBackward0>)\n",
      "---------------\n",
      "fixed_std_distribution = Independent(Normal(loc: torch.Size([100, 4]), scale: torch.Size([100, 4])), -1)\n",
      "fixed_mean_distribution = Independent(Normal(loc: torch.Size([100, 4]), scale: torch.Size([100, 4])), -1)\n",
      "---------------\n",
      "next_action_samples.shape = torch.Size([20, 100, 4])\n",
      "fixed_std_distribution.base_dist.log_prob(next_action_samples).shape = torch.Size([20, 100, 4])\n",
      "fixed_std_distribution.base_dist.log_prob(next_action_samples).sum(dim=-1).unsqueeze(-1).shape = torch.Size([20, 100, 1])\n",
      "weights.shape = torch.Size([20, 100, 1])\n",
      "policy_mean_losses.shape = torch.Size([100, 1])\n",
      "policy_mean_loss.shape = torch.Size([]) / policy_mean_loss = tensor(10.8892, grad_fn=<NegBackward0>)\n",
      "fixed_mean_distribution.base_dist.log_prob(next_action_samples).shape = torch.Size([20, 100, 4])\n",
      "fixed_mean_distribution.base_dist.log_prob(next_action_samples).sum(dim=-1).unsqueeze(-1).shape = torch.Size([20, 100, 1])\n",
      "policy_std_losses.shape = torch.Size([100, 1])\n",
      "policy_std_loss.shape = torch.Size([]) / policy_std_loss = tensor(10.8880, grad_fn=<NegBackward0>)\n",
      "---------------\n",
      "target_distributions = Independent(Normal(loc: torch.Size([100, 4]), scale: torch.Size([100, 4])), -1)\n",
      "target_distributions.base_dist = Normal(loc: torch.Size([100, 4]), scale: torch.Size([100, 4]))\n",
      "fixed_std_distribution = Independent(Normal(loc: torch.Size([100, 4]), scale: torch.Size([100, 4])), -1)\n",
      "fixed_std_distribution.base_dist = Normal(loc: torch.Size([100, 4]), scale: torch.Size([100, 4]))\n",
      "fixed_mean_distribution = Independent(Normal(loc: torch.Size([100, 4]), scale: torch.Size([100, 4])), -1)\n",
      "fixed_mean_distribution.base_dist = Normal(loc: torch.Size([100, 4]), scale: torch.Size([100, 4]))\n",
      "per_dim_constraining kl_mean.shape = torch.Size([100, 4])\n",
      "per_dim_constraining kl_std.shape = torch.Size([100, 4])\n",
      "---------------\n",
      " .. kl.shape = torch.Size([100, 4])\n",
      " .. alpha.shape = torch.Size([4])\n",
      " .. epsilon = 0.001\n",
      " .. kl_mean.shape = torch.Size([4])\n",
      " .. kl_loss.shape = torch.Size([]) / kl_loss = tensor(0.0021, grad_fn=<SumBackward0>)\n",
      " .. alpha_loss.shape = torch.Size([]) / alpha_loss = tensor(0.0031, grad_fn=<SumBackward0>)\n",
      " .. kl.shape = torch.Size([100, 4])\n",
      " .. alpha.shape = torch.Size([4])\n",
      " .. epsilon = 1e-06\n",
      " .. kl_mean.shape = torch.Size([4])\n",
      " .. kl_loss.shape = torch.Size([]) / kl_loss = tensor(0., grad_fn=<SumBackward0>)\n",
      " .. alpha_loss.shape = torch.Size([]) / alpha_loss = tensor(4.0000e-05, grad_fn=<SumBackward0>)\n",
      "self.epsilon_mean = 0.001\n",
      "self.epsilon_std = 1e-06\n",
      "kl_mean_loss.shape = torch.Size([]) / kl_mean_loss = tensor(0.0021, grad_fn=<SumBackward0>)\n",
      "alpha_mean_loss.shape = torch.Size([]) / alpha_mean_loss = tensor(0.0031, grad_fn=<SumBackward0>)\n",
      "kl_std_loss.shape = torch.Size([]) / kl_std_loss = tensor(0., grad_fn=<SumBackward0>)\n",
      "alpha_std_loss.shape = torch.Size([]) / alpha_std_loss = tensor(4.0000e-05, grad_fn=<SumBackward0>)\n",
      "---------------\n",
      "policy_loss.shape = torch.Size([]) / policy_loss = tensor(21.7772, grad_fn=<AddBackward0>)\n",
      "kl_loss.shape = torch.Size([]) / kl_loss = tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "dual_loss.shape = torch.Size([]) / dual_loss = tensor(-0.3756, grad_fn=<AddBackward0>)\n",
      "actor_loss.shape = torch.Size([]) / actor_loss = tensor(21.4037, grad_fn=<AddBackward0>)\n",
      "---------------\n",
      "replay_data.observations.shape = torch.Size([100, 24])\n",
      "replay_data.actions.shape = torch.Size([100, 4])\n",
      "returns.shape = torch.Size([100, 1])\n",
      "critic_values.shape = torch.Size([100, 1])\n",
      "critic_loss.shape = torch.Size([]) / critic_loss = tensor(0.0198, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m MPO(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     policy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMlpPolicy\u001b[39m\u001b[39m\"\u001b[39m, env\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBipedalWalker-v3\u001b[39m\u001b[39m\"\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )  \u001b[39m# , tensorboard_log=\"./logs\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m2_000_000\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/DESY/stable-baselines3-contrib/sb3_contrib/mpo/mpo.py:532\u001b[0m, in \u001b[0;36mMPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    524\u001b[0m     \u001b[39mself\u001b[39m: SelfMPO,\n\u001b[1;32m    525\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    531\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfMPO:\n\u001b[0;32m--> 532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    533\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    534\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    535\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    536\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    537\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    538\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m    539\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/stable-baselines3-contrib/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:331\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[39m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    330\u001b[0m         \u001b[39mif\u001b[39;00m gradient_steps \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size, gradient_steps\u001b[39m=\u001b[39;49mgradient_steps)\n\u001b[1;32m    333\u001b[0m callback\u001b[39m.\u001b[39mon_training_end()\n\u001b[1;32m    335\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/DESY/stable-baselines3-contrib/sb3_contrib/mpo/mpo.py:473\u001b[0m, in \u001b[0;36mMPO.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    470\u001b[0m critic_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(critic_values, returns)\n\u001b[1;32m    471\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcritic_loss\u001b[39m.\u001b[39mshape\u001b[39m \u001b[39m\u001b[39m= }\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m{\u001b[39;00mcritic_loss\u001b[39m \u001b[39m\u001b[39m= }\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 473\u001b[0m exit()\n\u001b[1;32m    475\u001b[0m actor_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    476\u001b[0m critic_loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "model = MPO(\n",
    "    policy=\"MlpPolicy\", env=\"BipedalWalker-v3\", verbose=2, tensorboard_log=\"./logs\"\n",
    ")\n",
    "model.learn(total_timesteps=2_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable-baselines3-contrib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
