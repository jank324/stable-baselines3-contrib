{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sb3_contrib import MPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Creating environment from the given name 'BipedalWalker-v3'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/MPO_14\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 472      |\n",
      "|    ep_rew_mean         | -91.7    |\n",
      "| time/                  |          |\n",
      "|    episodes            | 4        |\n",
      "|    fps                 | 75       |\n",
      "|    time_elapsed        | 25       |\n",
      "|    total_timesteps     | 1890     |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 11.5     |\n",
      "|    alpha_mean          | 0.99     |\n",
      "|    alpha_mean_loss     | 0.0332   |\n",
      "|    alpha_std           | 10.3     |\n",
      "|    alpha_std_loss      | 1.54e-05 |\n",
      "|    critic_loss         | 3.89     |\n",
      "|    dual_loss           | 0.0951   |\n",
      "|    kl_loss             | 0.00645  |\n",
      "|    kl_mean_loss        | 0.00642  |\n",
      "|    kl_std_loss         | 2.56e-05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 1716     |\n",
      "|    penalty_temperature | 1.64     |\n",
      "|    policy_loss         | 11.4     |\n",
      "|    policy_mean_loss    | 5.67     |\n",
      "|    policy_std_loss     | 5.69     |\n",
      "|    std                 | 0.494    |\n",
      "|    temperature         | 1.02     |\n",
      "|    temperature_loss    | 0.0619   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 283      |\n",
      "|    ep_rew_mean         | -97.9    |\n",
      "| time/                  |          |\n",
      "|    episodes            | 8        |\n",
      "|    fps                 | 72       |\n",
      "|    time_elapsed        | 31       |\n",
      "|    total_timesteps     | 2266     |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 12.1     |\n",
      "|    alpha_mean          | 0.927    |\n",
      "|    alpha_mean_loss     | 0.0311   |\n",
      "|    alpha_std           | 10.4     |\n",
      "|    alpha_std_loss      | -0.00015 |\n",
      "|    critic_loss         | 7.11     |\n",
      "|    dual_loss           | 0.758    |\n",
      "|    kl_loss             | 0.00623  |\n",
      "|    kl_mean_loss        | 0.00604  |\n",
      "|    kl_std_loss         | 0.000191 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 2122     |\n",
      "|    penalty_temperature | 1.75     |\n",
      "|    policy_loss         | 11.3     |\n",
      "|    policy_mean_loss    | 5.65     |\n",
      "|    policy_std_loss     | 5.66     |\n",
      "|    std                 | 0.494    |\n",
      "|    temperature         | 0.996    |\n",
      "|    temperature_loss    | 0.728    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 227      |\n",
      "|    ep_rew_mean         | -99.5    |\n",
      "| time/                  |          |\n",
      "|    episodes            | 12       |\n",
      "|    fps                 | 71       |\n",
      "|    time_elapsed        | 38       |\n",
      "|    total_timesteps     | 2721     |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 11.8     |\n",
      "|    alpha_mean          | 0.862    |\n",
      "|    alpha_mean_loss     | 0.0296   |\n",
      "|    alpha_std           | 10.5     |\n",
      "|    alpha_std_loss      | -0.00028 |\n",
      "|    critic_loss         | 4.44     |\n",
      "|    dual_loss           | 0.709    |\n",
      "|    kl_loss             | 0.00517  |\n",
      "|    kl_mean_loss        | 0.00485  |\n",
      "|    kl_std_loss         | 0.000322 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 2558     |\n",
      "|    penalty_temperature | 1.88     |\n",
      "|    policy_loss         | 11.1     |\n",
      "|    policy_mean_loss    | 5.54     |\n",
      "|    policy_std_loss     | 5.55     |\n",
      "|    std                 | 0.491    |\n",
      "|    temperature         | 0.939    |\n",
      "|    temperature_loss    | 0.68     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 190       |\n",
      "|    ep_rew_mean         | -103      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 16        |\n",
      "|    fps                 | 70        |\n",
      "|    time_elapsed        | 43        |\n",
      "|    total_timesteps     | 3046      |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 11.4      |\n",
      "|    alpha_mean          | 0.812     |\n",
      "|    alpha_mean_loss     | 0.0261    |\n",
      "|    alpha_std           | 10.6      |\n",
      "|    alpha_std_loss      | -0.000306 |\n",
      "|    critic_loss         | 5.73      |\n",
      "|    dual_loss           | 0.36      |\n",
      "|    kl_loss             | 0.0067    |\n",
      "|    kl_mean_loss        | 0.00635   |\n",
      "|    kl_std_loss         | 0.000349  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 2873      |\n",
      "|    penalty_temperature | 1.98      |\n",
      "|    policy_loss         | 11        |\n",
      "|    policy_mean_loss    | 5.5       |\n",
      "|    policy_std_loss     | 5.51      |\n",
      "|    std                 | 0.489     |\n",
      "|    temperature         | 0.909     |\n",
      "|    temperature_loss    | 0.334     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 173      |\n",
      "|    ep_rew_mean         | -104     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 20       |\n",
      "|    fps                 | 71       |\n",
      "|    time_elapsed        | 48       |\n",
      "|    total_timesteps     | 3459     |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 10.5     |\n",
      "|    alpha_mean          | 0.767    |\n",
      "|    alpha_mean_loss     | 0.0216   |\n",
      "|    alpha_std           | 10.7     |\n",
      "|    alpha_std_loss      | -0.00032 |\n",
      "|    critic_loss         | 6.24     |\n",
      "|    dual_loss           | -0.489   |\n",
      "|    kl_loss             | 0.00945  |\n",
      "|    kl_mean_loss        | 0.00908  |\n",
      "|    kl_std_loss         | 0.000363 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 3232     |\n",
      "|    penalty_temperature | 2.07     |\n",
      "|    policy_loss         | 10.9     |\n",
      "|    policy_mean_loss    | 5.46     |\n",
      "|    policy_std_loss     | 5.48     |\n",
      "|    std                 | 0.486    |\n",
      "|    temperature         | 0.924    |\n",
      "|    temperature_loss    | -0.511   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 159      |\n",
      "|    ep_rew_mean         | -103     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 24       |\n",
      "|    fps                 | 69       |\n",
      "|    time_elapsed        | 54       |\n",
      "|    total_timesteps     | 3809     |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.7      |\n",
      "|    alpha_mean          | 0.718    |\n",
      "|    alpha_mean_loss     | 0.0166   |\n",
      "|    alpha_std           | 10.8     |\n",
      "|    alpha_std_loss      | -0.00012 |\n",
      "|    critic_loss         | 2.88     |\n",
      "|    dual_loss           | -1.27    |\n",
      "|    kl_loss             | 0.0122   |\n",
      "|    kl_mean_loss        | 0.0121   |\n",
      "|    kl_std_loss         | 0.000163 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 3676     |\n",
      "|    penalty_temperature | 2.18     |\n",
      "|    policy_loss         | 11       |\n",
      "|    policy_mean_loss    | 5.47     |\n",
      "|    policy_std_loss     | 5.49     |\n",
      "|    std                 | 0.485    |\n",
      "|    temperature         | 1.01     |\n",
      "|    temperature_loss    | -1.29    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 192       |\n",
      "|    ep_rew_mean         | -106      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 28        |\n",
      "|    fps                 | 69        |\n",
      "|    time_elapsed        | 78        |\n",
      "|    total_timesteps     | 5389      |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 9.52      |\n",
      "|    alpha_mean          | 0.632     |\n",
      "|    alpha_mean_loss     | 0.0109    |\n",
      "|    alpha_std           | 10.8      |\n",
      "|    alpha_std_loss      | -6.71e-06 |\n",
      "|    critic_loss         | 1.17      |\n",
      "|    dual_loss           | -1.5      |\n",
      "|    kl_loss             | 0.0144    |\n",
      "|    kl_mean_loss        | 0.0144    |\n",
      "|    kl_std_loss         | 5.01e-05  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 5245      |\n",
      "|    penalty_temperature | 2.42      |\n",
      "|    policy_loss         | 11        |\n",
      "|    policy_mean_loss    | 5.51      |\n",
      "|    policy_std_loss     | 5.5       |\n",
      "|    std                 | 0.483     |\n",
      "|    temperature         | 1.17      |\n",
      "|    temperature_loss    | -1.51     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 368      |\n",
      "|    ep_rew_mean         | -104     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 32       |\n",
      "|    fps                 | 78       |\n",
      "|    time_elapsed        | 150      |\n",
      "|    total_timesteps     | 11789    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 13.8     |\n",
      "|    alpha_mean          | 0.466    |\n",
      "|    alpha_mean_loss     | 0.00589  |\n",
      "|    alpha_std           | 10.8     |\n",
      "|    alpha_std_loss      | 1.15e-05 |\n",
      "|    critic_loss         | 1.2      |\n",
      "|    dual_loss           | 2.76     |\n",
      "|    kl_loss             | 0.0128   |\n",
      "|    kl_mean_loss        | 0.0127   |\n",
      "|    kl_std_loss         | 3.17e-05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 10126    |\n",
      "|    penalty_temperature | 3.5      |\n",
      "|    policy_loss         | 11       |\n",
      "|    policy_mean_loss    | 5.53     |\n",
      "|    policy_std_loss     | 5.51     |\n",
      "|    std                 | 0.482    |\n",
      "|    temperature         | 1.23     |\n",
      "|    temperature_loss    | 2.75     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 378       |\n",
      "|    ep_rew_mean         | -105      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 36        |\n",
      "|    fps                 | 68        |\n",
      "|    time_elapsed        | 199       |\n",
      "|    total_timesteps     | 13616     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 14.7      |\n",
      "|    alpha_mean          | 0.355     |\n",
      "|    alpha_mean_loss     | -0.00188  |\n",
      "|    alpha_std           | 10.6      |\n",
      "|    alpha_std_loss      | -1.22e-05 |\n",
      "|    critic_loss         | 0.722     |\n",
      "|    dual_loss           | 3.79      |\n",
      "|    kl_loss             | 0.0161    |\n",
      "|    kl_mean_loss        | 0.0161    |\n",
      "|    kl_std_loss         | 5.46e-05  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 13480     |\n",
      "|    penalty_temperature | 4.16      |\n",
      "|    policy_loss         | 10.9      |\n",
      "|    policy_mean_loss    | 5.48      |\n",
      "|    policy_std_loss     | 5.44      |\n",
      "|    std                 | 0.478     |\n",
      "|    temperature         | 0.749     |\n",
      "|    temperature_loss    | 3.79      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 388      |\n",
      "|    ep_rew_mean         | -106     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 40       |\n",
      "|    fps                 | 68       |\n",
      "|    time_elapsed        | 227      |\n",
      "|    total_timesteps     | 15520    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 15.6     |\n",
      "|    alpha_mean          | 0.448    |\n",
      "|    alpha_mean_loss     | -0.0204  |\n",
      "|    alpha_std           | 10.4     |\n",
      "|    alpha_std_loss      | 2.21e-05 |\n",
      "|    critic_loss         | 2.5      |\n",
      "|    dual_loss           | 4.55     |\n",
      "|    kl_loss             | 0.0383   |\n",
      "|    kl_mean_loss        | 0.0383   |\n",
      "|    kl_std_loss         | 1.93e-05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 15337    |\n",
      "|    penalty_temperature | 4.51     |\n",
      "|    policy_loss         | 11       |\n",
      "|    policy_mean_loss    | 5.55     |\n",
      "|    policy_std_loss     | 5.43     |\n",
      "|    std                 | 0.477    |\n",
      "|    temperature         | 0.684    |\n",
      "|    temperature_loss    | 4.57     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 359      |\n",
      "|    ep_rew_mean         | -107     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 44       |\n",
      "|    fps                 | 68       |\n",
      "|    time_elapsed        | 231      |\n",
      "|    total_timesteps     | 15816    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 15.6     |\n",
      "|    alpha_mean          | 0.485    |\n",
      "|    alpha_mean_loss     | -0.0275  |\n",
      "|    alpha_std           | 10.3     |\n",
      "|    alpha_std_loss      | 1.76e-05 |\n",
      "|    critic_loss         | 2.87     |\n",
      "|    dual_loss           | 4.58     |\n",
      "|    kl_loss             | 0.0469   |\n",
      "|    kl_mean_loss        | 0.0469   |\n",
      "|    kl_std_loss         | 2.37e-05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 15658    |\n",
      "|    penalty_temperature | 4.57     |\n",
      "|    policy_loss         | 10.9     |\n",
      "|    policy_mean_loss    | 5.53     |\n",
      "|    policy_std_loss     | 5.4      |\n",
      "|    std                 | 0.476    |\n",
      "|    temperature         | 0.708    |\n",
      "|    temperature_loss    | 4.61     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 338      |\n",
      "|    ep_rew_mean         | -109     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 48       |\n",
      "|    fps                 | 68       |\n",
      "|    time_elapsed        | 238      |\n",
      "|    total_timesteps     | 16217    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 15.3     |\n",
      "|    alpha_mean          | 0.535    |\n",
      "|    alpha_mean_loss     | -0.0301  |\n",
      "|    alpha_std           | 10.3     |\n",
      "|    alpha_std_loss      | 1.48e-05 |\n",
      "|    critic_loss         | 5.76     |\n",
      "|    dual_loss           | 4.37     |\n",
      "|    kl_loss             | 0.0515   |\n",
      "|    kl_mean_loss        | 0.0515   |\n",
      "|    kl_std_loss         | 2.62e-05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 16096    |\n",
      "|    penalty_temperature | 4.65     |\n",
      "|    policy_loss         | 10.9     |\n",
      "|    policy_mean_loss    | 5.51     |\n",
      "|    policy_std_loss     | 5.39     |\n",
      "|    std                 | 0.476    |\n",
      "|    temperature         | 0.764    |\n",
      "|    temperature_loss    | 4.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 320       |\n",
      "|    ep_rew_mean         | -110      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 52        |\n",
      "|    fps                 | 68        |\n",
      "|    time_elapsed        | 243       |\n",
      "|    total_timesteps     | 16621     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 14.9      |\n",
      "|    alpha_mean          | 0.566     |\n",
      "|    alpha_mean_loss     | -0.0405   |\n",
      "|    alpha_std           | 10.3      |\n",
      "|    alpha_std_loss      | -2.77e-06 |\n",
      "|    critic_loss         | 4.73      |\n",
      "|    dual_loss           | 3.92      |\n",
      "|    kl_loss             | 0.0632    |\n",
      "|    kl_mean_loss        | 0.0631    |\n",
      "|    kl_std_loss         | 4.38e-05  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 16449     |\n",
      "|    penalty_temperature | 4.71      |\n",
      "|    policy_loss         | 10.9      |\n",
      "|    policy_mean_loss    | 5.52      |\n",
      "|    policy_std_loss     | 5.36      |\n",
      "|    std                 | 0.475     |\n",
      "|    temperature         | 0.834     |\n",
      "|    temperature_loss    | 3.96      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 303      |\n",
      "|    ep_rew_mean         | -111     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 56       |\n",
      "|    fps                 | 68       |\n",
      "|    time_elapsed        | 249      |\n",
      "|    total_timesteps     | 16995    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 15.1     |\n",
      "|    alpha_mean          | 0.61     |\n",
      "|    alpha_mean_loss     | -0.0686  |\n",
      "|    alpha_std           | 10.2     |\n",
      "|    alpha_std_loss      | 1.34e-05 |\n",
      "|    critic_loss         | 3.35     |\n",
      "|    dual_loss           | 4.07     |\n",
      "|    kl_loss             | 0.093    |\n",
      "|    kl_mean_loss        | 0.093    |\n",
      "|    kl_std_loss         | 2.75e-05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 16863    |\n",
      "|    penalty_temperature | 4.78     |\n",
      "|    policy_loss         | 11       |\n",
      "|    policy_mean_loss    | 5.6      |\n",
      "|    policy_std_loss     | 5.37     |\n",
      "|    std                 | 0.475    |\n",
      "|    temperature         | 0.907    |\n",
      "|    temperature_loss    | 4.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 291      |\n",
      "|    ep_rew_mean         | -112     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 60       |\n",
      "|    fps                 | 68       |\n",
      "|    time_elapsed        | 255      |\n",
      "|    total_timesteps     | 17473    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 15       |\n",
      "|    alpha_mean          | 0.658    |\n",
      "|    alpha_mean_loss     | -0.0804  |\n",
      "|    alpha_std           | 10.2     |\n",
      "|    alpha_std_loss      | 1.44e-05 |\n",
      "|    critic_loss         | 3.88     |\n",
      "|    dual_loss           | 3.92     |\n",
      "|    kl_loss             | 0.107    |\n",
      "|    kl_mean_loss        | 0.107    |\n",
      "|    kl_std_loss         | 2.63e-05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 17259    |\n",
      "|    penalty_temperature | 4.83     |\n",
      "|    policy_loss         | 11       |\n",
      "|    policy_mean_loss    | 5.63     |\n",
      "|    policy_std_loss     | 5.38     |\n",
      "|    std                 | 0.474    |\n",
      "|    temperature         | 0.961    |\n",
      "|    temperature_loss    | 4        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 278      |\n",
      "|    ep_rew_mean         | -112     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 64       |\n",
      "|    fps                 | 68       |\n",
      "|    time_elapsed        | 261      |\n",
      "|    total_timesteps     | 17779    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 14.6     |\n",
      "|    alpha_mean          | 0.716    |\n",
      "|    alpha_mean_loss     | -0.0727  |\n",
      "|    alpha_std           | 10.1     |\n",
      "|    alpha_std_loss      | 2.36e-05 |\n",
      "|    critic_loss         | 3.68     |\n",
      "|    dual_loss           | 3.56     |\n",
      "|    kl_loss             | 0.101    |\n",
      "|    kl_mean_loss        | 0.101    |\n",
      "|    kl_std_loss         | 1.69e-05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 17637    |\n",
      "|    penalty_temperature | 4.88     |\n",
      "|    policy_loss         | 11       |\n",
      "|    policy_mean_loss    | 5.6      |\n",
      "|    policy_std_loss     | 5.38     |\n",
      "|    std                 | 0.474    |\n",
      "|    temperature         | 1.03     |\n",
      "|    temperature_loss    | 3.63     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 266      |\n",
      "|    ep_rew_mean         | -112     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 68       |\n",
      "|    fps                 | 68       |\n",
      "|    time_elapsed        | 265      |\n",
      "|    total_timesteps     | 18113    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 14.6     |\n",
      "|    alpha_mean          | 0.752    |\n",
      "|    alpha_mean_loss     | -0.117   |\n",
      "|    alpha_std           | 10.1     |\n",
      "|    alpha_std_loss      | 6.03e-06 |\n",
      "|    critic_loss         | 3.45     |\n",
      "|    dual_loss           | 3.36     |\n",
      "|    kl_loss             | 0.147    |\n",
      "|    kl_mean_loss        | 0.147    |\n",
      "|    kl_std_loss         | 3.42e-05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 17921    |\n",
      "|    penalty_temperature | 4.92     |\n",
      "|    policy_loss         | 11       |\n",
      "|    policy_mean_loss    | 5.68     |\n",
      "|    policy_std_loss     | 5.36     |\n",
      "|    std                 | 0.474    |\n",
      "|    temperature         | 1.08     |\n",
      "|    temperature_loss    | 3.48     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 256      |\n",
      "|    ep_rew_mean         | -113     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 72       |\n",
      "|    fps                 | 68       |\n",
      "|    time_elapsed        | 271      |\n",
      "|    total_timesteps     | 18450    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 13.9     |\n",
      "|    alpha_mean          | 0.806    |\n",
      "|    alpha_mean_loss     | -0.153   |\n",
      "|    alpha_std           | 9.99     |\n",
      "|    alpha_std_loss      | 1.88e-05 |\n",
      "|    critic_loss         | 5.38     |\n",
      "|    dual_loss           | 2.62     |\n",
      "|    kl_loss             | 0.185    |\n",
      "|    kl_mean_loss        | 0.185    |\n",
      "|    kl_std_loss         | 2.12e-05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 18305    |\n",
      "|    penalty_temperature | 4.98     |\n",
      "|    policy_loss         | 11.1     |\n",
      "|    policy_mean_loss    | 5.76     |\n",
      "|    policy_std_loss     | 5.36     |\n",
      "|    std                 | 0.474    |\n",
      "|    temperature         | 1.14     |\n",
      "|    temperature_loss    | 2.77     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 287       |\n",
      "|    ep_rew_mean         | -113      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 76        |\n",
      "|    fps                 | 72        |\n",
      "|    time_elapsed        | 299       |\n",
      "|    total_timesteps     | 21836     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 10.6      |\n",
      "|    alpha_mean          | 1.08      |\n",
      "|    alpha_mean_loss     | -0.405    |\n",
      "|    alpha_std           | 9.96      |\n",
      "|    alpha_std_loss      | -3.69e-05 |\n",
      "|    critic_loss         | 20.8      |\n",
      "|    dual_loss           | -1.15     |\n",
      "|    kl_loss             | 0.449     |\n",
      "|    kl_mean_loss        | 0.449     |\n",
      "|    kl_std_loss         | 7.67e-05  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 20173     |\n",
      "|    penalty_temperature | 5.3       |\n",
      "|    policy_loss         | 11.3      |\n",
      "|    policy_mean_loss    | 6.02      |\n",
      "|    policy_std_loss     | 5.27      |\n",
      "|    std                 | 0.47      |\n",
      "|    temperature         | 1.48      |\n",
      "|    temperature_loss    | -0.742    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 277       |\n",
      "|    ep_rew_mean         | -113      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 80        |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 326       |\n",
      "|    total_timesteps     | 22176     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 10.1      |\n",
      "|    alpha_mean          | 1.39      |\n",
      "|    alpha_mean_loss     | -1.54     |\n",
      "|    alpha_std           | 9.99      |\n",
      "|    alpha_std_loss      | -1.81e-05 |\n",
      "|    critic_loss         | 51        |\n",
      "|    dual_loss           | -4.06     |\n",
      "|    kl_loss             | 1.59      |\n",
      "|    kl_mean_loss        | 1.59      |\n",
      "|    kl_std_loss         | 5.81e-05  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 22024     |\n",
      "|    penalty_temperature | 5.54      |\n",
      "|    policy_loss         | 12.6      |\n",
      "|    policy_mean_loss    | 7.4       |\n",
      "|    policy_std_loss     | 5.21      |\n",
      "|    std                 | 0.466     |\n",
      "|    temperature         | 1.68      |\n",
      "|    temperature_loss    | -2.53     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 268       |\n",
      "|    ep_rew_mean         | -113      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 84        |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 331       |\n",
      "|    total_timesteps     | 22543     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 8.86      |\n",
      "|    alpha_mean          | 1.46      |\n",
      "|    alpha_mean_loss     | -2.13     |\n",
      "|    alpha_std           | 9.99      |\n",
      "|    alpha_std_loss      | -9.38e-06 |\n",
      "|    critic_loss         | 138       |\n",
      "|    dual_loss           | -6.64     |\n",
      "|    kl_loss             | 2.19      |\n",
      "|    kl_mean_loss        | 2.19      |\n",
      "|    kl_std_loss         | 4.93e-05  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 22397     |\n",
      "|    penalty_temperature | 5.55      |\n",
      "|    policy_loss         | 13.3      |\n",
      "|    policy_mean_loss    | 8.11      |\n",
      "|    policy_std_loss     | 5.2       |\n",
      "|    std                 | 0.466     |\n",
      "|    temperature         | 1.72      |\n",
      "|    temperature_loss    | -4.51     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 262       |\n",
      "|    ep_rew_mean         | -114      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 88        |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 339       |\n",
      "|    total_timesteps     | 23034     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 7.99      |\n",
      "|    alpha_mean          | 1.53      |\n",
      "|    alpha_mean_loss     | -3.33     |\n",
      "|    alpha_std           | 10        |\n",
      "|    alpha_std_loss      | -2.89e-05 |\n",
      "|    critic_loss         | 226       |\n",
      "|    dual_loss           | -10.1     |\n",
      "|    kl_loss             | 3.39      |\n",
      "|    kl_mean_loss        | 3.39      |\n",
      "|    kl_std_loss         | 6.89e-05  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 22899     |\n",
      "|    penalty_temperature | 5.56      |\n",
      "|    policy_loss         | 14.7      |\n",
      "|    policy_mean_loss    | 9.5       |\n",
      "|    policy_std_loss     | 5.18      |\n",
      "|    std                 | 0.464     |\n",
      "|    temperature         | 1.83      |\n",
      "|    temperature_loss    | -6.74     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 254       |\n",
      "|    ep_rew_mean         | -114      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 92        |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 343       |\n",
      "|    total_timesteps     | 23343     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.27      |\n",
      "|    alpha_mean          | 1.59      |\n",
      "|    alpha_mean_loss     | -2.63     |\n",
      "|    alpha_std           | 10        |\n",
      "|    alpha_std_loss      | -2.13e-05 |\n",
      "|    critic_loss         | 233       |\n",
      "|    dual_loss           | -12.1     |\n",
      "|    kl_loss             | 2.69      |\n",
      "|    kl_mean_loss        | 2.69      |\n",
      "|    kl_std_loss         | 6.14e-05  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 23184     |\n",
      "|    penalty_temperature | 5.56      |\n",
      "|    policy_loss         | 13.6      |\n",
      "|    policy_mean_loss    | 8.47      |\n",
      "|    policy_std_loss     | 5.17      |\n",
      "|    std                 | 0.464     |\n",
      "|    temperature         | 1.96      |\n",
      "|    temperature_loss    | -9.43     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 248       |\n",
      "|    ep_rew_mean         | -114      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 96        |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 350       |\n",
      "|    total_timesteps     | 23766     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.64      |\n",
      "|    alpha_mean          | 1.65      |\n",
      "|    alpha_mean_loss     | -3.45     |\n",
      "|    alpha_std           | 10        |\n",
      "|    alpha_std_loss      | -2.76e-05 |\n",
      "|    critic_loss         | 137       |\n",
      "|    dual_loss           | -13.3     |\n",
      "|    kl_loss             | 3.51      |\n",
      "|    kl_mean_loss        | 3.51      |\n",
      "|    kl_std_loss         | 6.77e-05  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 23616     |\n",
      "|    penalty_temperature | 5.57      |\n",
      "|    policy_loss         | 14.4      |\n",
      "|    policy_mean_loss    | 9.29      |\n",
      "|    policy_std_loss     | 5.15      |\n",
      "|    std                 | 0.463     |\n",
      "|    temperature         | 2.11      |\n",
      "|    temperature_loss    | -9.86     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 242       |\n",
      "|    ep_rew_mean         | -115      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 100       |\n",
      "|    fps                 | 68        |\n",
      "|    time_elapsed        | 354       |\n",
      "|    total_timesteps     | 24169     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 5.42      |\n",
      "|    alpha_mean          | 1.71      |\n",
      "|    alpha_mean_loss     | -4.67     |\n",
      "|    alpha_std           | 10        |\n",
      "|    alpha_std_loss      | -3.03e-06 |\n",
      "|    critic_loss         | 150       |\n",
      "|    dual_loss           | -15.1     |\n",
      "|    kl_loss             | 4.74      |\n",
      "|    kl_mean_loss        | 4.74      |\n",
      "|    kl_std_loss         | 4.31e-05  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 23950     |\n",
      "|    penalty_temperature | 5.57      |\n",
      "|    policy_loss         | 15.8      |\n",
      "|    policy_mean_loss    | 10.6      |\n",
      "|    policy_std_loss     | 5.15      |\n",
      "|    std                 | 0.463     |\n",
      "|    temperature         | 2.22      |\n",
      "|    temperature_loss    | -10.4     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 227      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 104      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 362      |\n",
      "|    total_timesteps     | 24560    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.38     |\n",
      "|    alpha_mean          | 1.8      |\n",
      "|    alpha_mean_loss     | -9.7     |\n",
      "|    alpha_std           | 9.99     |\n",
      "|    alpha_std_loss      | 1.35e-05 |\n",
      "|    critic_loss         | 116      |\n",
      "|    dual_loss           | -21.4    |\n",
      "|    kl_loss             | 9.77     |\n",
      "|    kl_mean_loss        | 9.77     |\n",
      "|    kl_std_loss         | 2.64e-05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 24442    |\n",
      "|    penalty_temperature | 5.59     |\n",
      "|    policy_loss         | 21       |\n",
      "|    policy_mean_loss    | 15.9     |\n",
      "|    policy_std_loss     | 5.15     |\n",
      "|    std                 | 0.462    |\n",
      "|    temperature         | 2.36     |\n",
      "|    temperature_loss    | -11.7    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 242      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 108      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 389      |\n",
      "|    total_timesteps     | 26418    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 16.1     |\n",
      "|    alpha_mean          | 1.98     |\n",
      "|    alpha_mean_loss     | -19.1    |\n",
      "|    alpha_std           | 9.89     |\n",
      "|    alpha_std_loss      | 8.85e-06 |\n",
      "|    critic_loss         | 153      |\n",
      "|    dual_loss           | -32.2    |\n",
      "|    kl_loss             | 19.1     |\n",
      "|    kl_mean_loss        | 19.1     |\n",
      "|    kl_std_loss         | 3.07e-05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 26270    |\n",
      "|    penalty_temperature | 5.71     |\n",
      "|    policy_loss         | 29.2     |\n",
      "|    policy_mean_loss    | 24.1     |\n",
      "|    policy_std_loss     | 5.13     |\n",
      "|    std                 | 0.46     |\n",
      "|    temperature         | 2.55     |\n",
      "|    temperature_loss    | -13.2    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 254       |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 112       |\n",
      "|    fps                 | 71        |\n",
      "|    time_elapsed        | 394       |\n",
      "|    total_timesteps     | 28155     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 27.5      |\n",
      "|    alpha_mean          | 2.17      |\n",
      "|    alpha_mean_loss     | -40.8     |\n",
      "|    alpha_std           | 9.91      |\n",
      "|    alpha_std_loss      | -5.51e-05 |\n",
      "|    critic_loss         | 737       |\n",
      "|    dual_loss           | -61.2     |\n",
      "|    kl_loss             | 40.9      |\n",
      "|    kl_mean_loss        | 40.9      |\n",
      "|    kl_std_loss         | 9.47e-05  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 26622     |\n",
      "|    penalty_temperature | 5.8       |\n",
      "|    policy_loss         | 47.8      |\n",
      "|    policy_mean_loss    | 42.7      |\n",
      "|    policy_std_loss     | 5.08      |\n",
      "|    std                 | 0.459     |\n",
      "|    temperature         | 2.71      |\n",
      "|    temperature_loss    | -20.4     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 256       |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 116       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 421       |\n",
      "|    total_timesteps     | 28612     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 67        |\n",
      "|    alpha_mean          | 2.42      |\n",
      "|    alpha_mean_loss     | -102      |\n",
      "|    alpha_std           | 10.2      |\n",
      "|    alpha_std_loss      | -6.79e-05 |\n",
      "|    critic_loss         | 892       |\n",
      "|    dual_loss           | -129      |\n",
      "|    kl_loss             | 102       |\n",
      "|    kl_mean_loss        | 102       |\n",
      "|    kl_std_loss         | 0.000109  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 28455     |\n",
      "|    penalty_temperature | 5.93      |\n",
      "|    policy_loss         | 94.4      |\n",
      "|    policy_mean_loss    | 89.4      |\n",
      "|    policy_std_loss     | 5.03      |\n",
      "|    std                 | 0.456     |\n",
      "|    temperature         | 3.17      |\n",
      "|    temperature_loss    | -27.5     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 258       |\n",
      "|    ep_rew_mean         | -119      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 120       |\n",
      "|    fps                 | 68        |\n",
      "|    time_elapsed        | 427       |\n",
      "|    total_timesteps     | 29232     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 118       |\n",
      "|    alpha_mean          | 2.49      |\n",
      "|    alpha_mean_loss     | -182      |\n",
      "|    alpha_std           | 10.3      |\n",
      "|    alpha_std_loss      | -0.000102 |\n",
      "|    critic_loss         | 6.47e+03  |\n",
      "|    dual_loss           | -220      |\n",
      "|    kl_loss             | 182       |\n",
      "|    kl_mean_loss        | 182       |\n",
      "|    kl_std_loss         | 0.000143  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 28900     |\n",
      "|    penalty_temperature | 5.98      |\n",
      "|    policy_loss         | 157       |\n",
      "|    policy_mean_loss    | 152       |\n",
      "|    policy_std_loss     | 5.02      |\n",
      "|    std                 | 0.455     |\n",
      "|    temperature         | 3.38      |\n",
      "|    temperature_loss    | -38.8     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 261       |\n",
      "|    ep_rew_mean         | -120      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 124       |\n",
      "|    fps                 | 68        |\n",
      "|    time_elapsed        | 437       |\n",
      "|    total_timesteps     | 29956     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 68.3      |\n",
      "|    alpha_mean          | 2.58      |\n",
      "|    alpha_mean_loss     | -125      |\n",
      "|    alpha_std           | 10.4      |\n",
      "|    alpha_std_loss      | -4.49e-05 |\n",
      "|    critic_loss         | 2.81e+03  |\n",
      "|    dual_loss           | -165      |\n",
      "|    kl_loss             | 125       |\n",
      "|    kl_mean_loss        | 125       |\n",
      "|    kl_std_loss         | 8.64e-05  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 29556     |\n",
      "|    penalty_temperature | 6.06      |\n",
      "|    policy_loss         | 108       |\n",
      "|    policy_mean_loss    | 103       |\n",
      "|    policy_std_loss     | 5.04      |\n",
      "|    std                 | 0.456     |\n",
      "|    temperature         | 3.64      |\n",
      "|    temperature_loss    | -39.7     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 253       |\n",
      "|    ep_rew_mean         | -120      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 128       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 452       |\n",
      "|    total_timesteps     | 30645     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 215       |\n",
      "|    alpha_mean          | 2.71      |\n",
      "|    alpha_mean_loss     | -360      |\n",
      "|    alpha_std           | 10.4      |\n",
      "|    alpha_std_loss      | -5.14e-05 |\n",
      "|    critic_loss         | 1.29e+04  |\n",
      "|    dual_loss           | -424      |\n",
      "|    kl_loss             | 360       |\n",
      "|    kl_mean_loss        | 360       |\n",
      "|    kl_std_loss         | 9.3e-05   |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 30524     |\n",
      "|    penalty_temperature | 6.28      |\n",
      "|    policy_loss         | 279       |\n",
      "|    policy_mean_loss    | 274       |\n",
      "|    policy_std_loss     | 5.08      |\n",
      "|    std                 | 0.457     |\n",
      "|    temperature         | 4.07      |\n",
      "|    temperature_loss    | -63.8     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 216       |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 132       |\n",
      "|    fps                 | 69        |\n",
      "|    time_elapsed        | 480       |\n",
      "|    total_timesteps     | 33341     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 316       |\n",
      "|    alpha_mean          | 2.91      |\n",
      "|    alpha_mean_loss     | -535      |\n",
      "|    alpha_std           | 10.7      |\n",
      "|    alpha_std_loss      | -0.000174 |\n",
      "|    critic_loss         | 1.56e+04  |\n",
      "|    dual_loss           | -601      |\n",
      "|    kl_loss             | 535       |\n",
      "|    kl_mean_loss        | 535       |\n",
      "|    kl_std_loss         | 0.000216  |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 32402     |\n",
      "|    penalty_temperature | 6.7       |\n",
      "|    policy_loss         | 382       |\n",
      "|    policy_mean_loss    | 377       |\n",
      "|    policy_std_loss     | 5.21      |\n",
      "|    std                 | 0.464     |\n",
      "|    temperature         | 4.61      |\n",
      "|    temperature_loss    | -66.3     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 230       |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 136       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 541       |\n",
      "|    total_timesteps     | 36665     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.16e+03 |\n",
      "|    alpha_mean          | 3.53      |\n",
      "|    alpha_mean_loss     | -1.26e+03 |\n",
      "|    alpha_std           | 12.5      |\n",
      "|    alpha_std_loss      | -0.0184   |\n",
      "|    critic_loss         | 1.55e+09  |\n",
      "|    dual_loss           | -3.13e+03 |\n",
      "|    kl_loss             | 1.26e+03  |\n",
      "|    kl_mean_loss        | 1.26e+03  |\n",
      "|    kl_std_loss         | 0.0184    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 36544     |\n",
      "|    penalty_temperature | 8.39      |\n",
      "|    policy_loss         | 709       |\n",
      "|    policy_mean_loss    | 701       |\n",
      "|    policy_std_loss     | 8.16      |\n",
      "|    std                 | 0.6       |\n",
      "|    temperature         | 6.52      |\n",
      "|    temperature_loss    | -1.87e+03 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 229       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 140       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 567       |\n",
      "|    total_timesteps     | 38387     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -8.2e+04  |\n",
      "|    alpha_mean          | 3.76      |\n",
      "|    alpha_mean_loss     | -4.42e+03 |\n",
      "|    alpha_std           | 13        |\n",
      "|    alpha_std_loss      | -0.0307   |\n",
      "|    critic_loss         | 2.91e+12  |\n",
      "|    dual_loss           | -8.87e+04 |\n",
      "|    kl_loss             | 4.42e+03  |\n",
      "|    kl_mean_loss        | 4.42e+03  |\n",
      "|    kl_std_loss         | 0.0307    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 38286     |\n",
      "|    penalty_temperature | 9.08      |\n",
      "|    policy_loss         | 2.25e+03  |\n",
      "|    policy_mean_loss    | 2.24e+03  |\n",
      "|    policy_std_loss     | 9.38      |\n",
      "|    std                 | 0.701     |\n",
      "|    temperature         | 6.68      |\n",
      "|    temperature_loss    | -8.42e+04 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 227       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 144       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 570       |\n",
      "|    total_timesteps     | 38551     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.16e+05 |\n",
      "|    alpha_mean          | 3.78      |\n",
      "|    alpha_mean_loss     | -3.25e+03 |\n",
      "|    alpha_std           | 13        |\n",
      "|    alpha_std_loss      | -0.033    |\n",
      "|    critic_loss         | 6.09e+12  |\n",
      "|    dual_loss           | -1.21e+05 |\n",
      "|    kl_loss             | 3.25e+03  |\n",
      "|    kl_mean_loss        | 3.25e+03  |\n",
      "|    kl_std_loss         | 0.033     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 38447     |\n",
      "|    penalty_temperature | 9.16      |\n",
      "|    policy_loss         | 1.65e+03  |\n",
      "|    policy_mean_loss    | 1.64e+03  |\n",
      "|    policy_std_loss     | 9.52      |\n",
      "|    std                 | 0.714     |\n",
      "|    temperature         | 6.68      |\n",
      "|    temperature_loss    | -1.17e+05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 241       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 148       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 596       |\n",
      "|    total_timesteps     | 40292     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 7.55e+05  |\n",
      "|    alpha_mean          | 3.9       |\n",
      "|    alpha_mean_loss     | -7.64e+03 |\n",
      "|    alpha_std           | 13.2      |\n",
      "|    alpha_std_loss      | -0.0253   |\n",
      "|    critic_loss         | 1.44e+14  |\n",
      "|    dual_loss           | 7.44e+05  |\n",
      "|    kl_loss             | 7.64e+03  |\n",
      "|    kl_mean_loss        | 7.64e+03  |\n",
      "|    kl_std_loss         | 0.0253    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 40182     |\n",
      "|    penalty_temperature | 9.58      |\n",
      "|    policy_loss         | 3.66e+03  |\n",
      "|    policy_mean_loss    | 3.65e+03  |\n",
      "|    policy_std_loss     | 10.3      |\n",
      "|    std                 | 0.856     |\n",
      "|    temperature         | 6.68      |\n",
      "|    temperature_loss    | 7.52e+05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 239       |\n",
      "|    ep_rew_mean         | -122      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 152       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 599       |\n",
      "|    total_timesteps     | 40497     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 8.05e+06  |\n",
      "|    alpha_mean          | 4.02      |\n",
      "|    alpha_mean_loss     | -1.39e+04 |\n",
      "|    alpha_std           | 13.5      |\n",
      "|    alpha_std_loss      | -0.025    |\n",
      "|    critic_loss         | 1.39e+14  |\n",
      "|    dual_loss           | 8.03e+06  |\n",
      "|    kl_loss             | 1.39e+04  |\n",
      "|    kl_mean_loss        | 1.39e+04  |\n",
      "|    kl_std_loss         | 0.025     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 40376     |\n",
      "|    penalty_temperature | 9.99      |\n",
      "|    policy_loss         | 6.42e+03  |\n",
      "|    policy_mean_loss    | 6.41e+03  |\n",
      "|    policy_std_loss     | 11        |\n",
      "|    std                 | 0.874     |\n",
      "|    temperature         | 6.66      |\n",
      "|    temperature_loss    | 8.05e+06  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 237       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 156       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 601       |\n",
      "|    total_timesteps     | 40682     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.5e+07   |\n",
      "|    alpha_mean          | 4.04      |\n",
      "|    alpha_mean_loss     | -1.03e+04 |\n",
      "|    alpha_std           | 13.6      |\n",
      "|    alpha_std_loss      | -0.027    |\n",
      "|    critic_loss         | 3.08e+14  |\n",
      "|    dual_loss           | 1.5e+07   |\n",
      "|    kl_loss             | 1.03e+04  |\n",
      "|    kl_mean_loss        | 1.03e+04  |\n",
      "|    kl_std_loss         | 0.0271    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 40571     |\n",
      "|    penalty_temperature | 10.1      |\n",
      "|    policy_loss         | 4.7e+03   |\n",
      "|    policy_mean_loss    | 4.69e+03  |\n",
      "|    policy_std_loss     | 11.2      |\n",
      "|    std                 | 0.893     |\n",
      "|    temperature         | 6.66      |\n",
      "|    temperature_loss    | 1.5e+07   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 250       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 160       |\n",
      "|    fps                 | 70        |\n",
      "|    time_elapsed        | 605       |\n",
      "|    total_timesteps     | 42438     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.95e+07  |\n",
      "|    alpha_mean          | 4.06      |\n",
      "|    alpha_mean_loss     | -4.98e+03 |\n",
      "|    alpha_std           | 13.6      |\n",
      "|    alpha_std_loss      | -0.0298   |\n",
      "|    critic_loss         | 2.87e+15  |\n",
      "|    dual_loss           | 2.95e+07  |\n",
      "|    kl_loss             | 4.98e+03  |\n",
      "|    kl_mean_loss        | 4.98e+03  |\n",
      "|    kl_std_loss         | 0.0299    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 40775     |\n",
      "|    penalty_temperature | 10.1      |\n",
      "|    policy_loss         | 2.27e+03  |\n",
      "|    policy_mean_loss    | 2.26e+03  |\n",
      "|    policy_std_loss     | 11.4      |\n",
      "|    std                 | 0.916     |\n",
      "|    temperature         | 6.66      |\n",
      "|    temperature_loss    | 2.95e+07  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 251       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 164       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 634       |\n",
      "|    total_timesteps     | 42841     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.76e+09  |\n",
      "|    alpha_mean          | 4.3       |\n",
      "|    alpha_mean_loss     | -2.65e+04 |\n",
      "|    alpha_std           | 14.1      |\n",
      "|    alpha_std_loss      | -0.0288   |\n",
      "|    critic_loss         | 4.48e+18  |\n",
      "|    dual_loss           | 1.76e+09  |\n",
      "|    kl_loss             | 2.65e+04  |\n",
      "|    kl_mean_loss        | 2.65e+04  |\n",
      "|    kl_std_loss         | 0.0288    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 42727     |\n",
      "|    penalty_temperature | 10.9      |\n",
      "|    policy_loss         | 1.12e+04  |\n",
      "|    policy_mean_loss    | 1.12e+04  |\n",
      "|    policy_std_loss     | 12.9      |\n",
      "|    std                 | 1.14      |\n",
      "|    temperature         | 6.69      |\n",
      "|    temperature_loss    | 1.76e+09  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 249      |\n",
      "|    ep_rew_mean         | -121     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 168      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 637      |\n",
      "|    total_timesteps     | 43041    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.5e+09  |\n",
      "|    alpha_mean          | 4.33     |\n",
      "|    alpha_mean_loss     | -1.2e+04 |\n",
      "|    alpha_std           | 14.2     |\n",
      "|    alpha_std_loss      | -0.0302  |\n",
      "|    critic_loss         | 8.82e+18 |\n",
      "|    dual_loss           | 2.5e+09  |\n",
      "|    kl_loss             | 1.2e+04  |\n",
      "|    kl_mean_loss        | 1.2e+04  |\n",
      "|    kl_std_loss         | 0.0302   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 42934    |\n",
      "|    penalty_temperature | 11       |\n",
      "|    policy_loss         | 5.01e+03 |\n",
      "|    policy_mean_loss    | 5e+03    |\n",
      "|    policy_std_loss     | 13.1     |\n",
      "|    std                 | 1.17     |\n",
      "|    temperature         | 6.69     |\n",
      "|    temperature_loss    | 2.5e+09  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 251       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 172       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 644       |\n",
      "|    total_timesteps     | 43509     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.91e+09  |\n",
      "|    alpha_mean          | 4.37      |\n",
      "|    alpha_mean_loss     | -1.74e+04 |\n",
      "|    alpha_std           | 14.3      |\n",
      "|    alpha_std_loss      | -0.0328   |\n",
      "|    critic_loss         | 4.05e+19  |\n",
      "|    dual_loss           | 4.91e+09  |\n",
      "|    kl_loss             | 1.74e+04  |\n",
      "|    kl_mean_loss        | 1.74e+04  |\n",
      "|    kl_std_loss         | 0.0328    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 43402     |\n",
      "|    penalty_temperature | 11.1      |\n",
      "|    policy_loss         | 7.19e+03  |\n",
      "|    policy_mean_loss    | 7.18e+03  |\n",
      "|    policy_std_loss     | 13.4      |\n",
      "|    std                 | 1.25      |\n",
      "|    temperature         | 6.69      |\n",
      "|    temperature_loss    | 4.91e+09  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 237       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 176       |\n",
      "|    fps                 | 69        |\n",
      "|    time_elapsed        | 651       |\n",
      "|    total_timesteps     | 45527     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 7.96e+09  |\n",
      "|    alpha_mean          | 4.42      |\n",
      "|    alpha_mean_loss     | -2.21e+04 |\n",
      "|    alpha_std           | 14.4      |\n",
      "|    alpha_std_loss      | -0.0355   |\n",
      "|    critic_loss         | 1.27e+20  |\n",
      "|    dual_loss           | 7.96e+09  |\n",
      "|    kl_loss             | 2.21e+04  |\n",
      "|    kl_mean_loss        | 2.21e+04  |\n",
      "|    kl_std_loss         | 0.0356    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 43864     |\n",
      "|    penalty_temperature | 11.3      |\n",
      "|    policy_loss         | 9.02e+03  |\n",
      "|    policy_mean_loss    | 9.01e+03  |\n",
      "|    policy_std_loss     | 13.7      |\n",
      "|    std                 | 1.33      |\n",
      "|    temperature         | 6.69      |\n",
      "|    temperature_loss    | 7.96e+09  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 251       |\n",
      "|    ep_rew_mean         | -122      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 180       |\n",
      "|    fps                 | 69        |\n",
      "|    time_elapsed        | 678       |\n",
      "|    total_timesteps     | 47291     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.63e+10  |\n",
      "|    alpha_mean          | 4.66      |\n",
      "|    alpha_mean_loss     | -7.01e+04 |\n",
      "|    alpha_std           | 14.7      |\n",
      "|    alpha_std_loss      | -0.049    |\n",
      "|    critic_loss         | 3.82e+21  |\n",
      "|    dual_loss           | 4.63e+10  |\n",
      "|    kl_loss             | 7.01e+04  |\n",
      "|    kl_mean_loss        | 7.01e+04  |\n",
      "|    kl_std_loss         | 0.0491    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 45628     |\n",
      "|    penalty_temperature | 12.1      |\n",
      "|    policy_loss         | 2.67e+04  |\n",
      "|    policy_mean_loss    | 2.67e+04  |\n",
      "|    policy_std_loss     | 15.1      |\n",
      "|    std                 | 1.78      |\n",
      "|    temperature         | 6.7       |\n",
      "|    temperature_loss    | 4.63e+10  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 249       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 184       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 703       |\n",
      "|    total_timesteps     | 47465     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.58e+11  |\n",
      "|    alpha_mean          | 4.9       |\n",
      "|    alpha_mean_loss     | -5.38e+04 |\n",
      "|    alpha_std           | 14.9      |\n",
      "|    alpha_std_loss      | -0.0579   |\n",
      "|    critic_loss         | 6.02e+22  |\n",
      "|    dual_loss           | 1.58e+11  |\n",
      "|    kl_loss             | 5.38e+04  |\n",
      "|    kl_mean_loss        | 5.38e+04  |\n",
      "|    kl_std_loss         | 0.0579    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 47361     |\n",
      "|    penalty_temperature | 12.8      |\n",
      "|    policy_loss         | 1.95e+04  |\n",
      "|    policy_mean_loss    | 1.94e+04  |\n",
      "|    policy_std_loss     | 16.3      |\n",
      "|    std                 | 2.55      |\n",
      "|    temperature         | 6.7       |\n",
      "|    temperature_loss    | 1.58e+11  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 246      |\n",
      "|    ep_rew_mean         | -121     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 188      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 706      |\n",
      "|    total_timesteps     | 47641    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.77e+11 |\n",
      "|    alpha_mean          | 4.92     |\n",
      "|    alpha_mean_loss     | -7.6e+04 |\n",
      "|    alpha_std           | 14.9     |\n",
      "|    alpha_std_loss      | -0.0585  |\n",
      "|    critic_loss         | 8.53e+22 |\n",
      "|    dual_loss           | 1.77e+11 |\n",
      "|    kl_loss             | 7.6e+04  |\n",
      "|    kl_mean_loss        | 7.6e+04  |\n",
      "|    kl_std_loss         | 0.0585   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 47533    |\n",
      "|    penalty_temperature | 12.9     |\n",
      "|    policy_loss         | 2.73e+04 |\n",
      "|    policy_mean_loss    | 2.73e+04 |\n",
      "|    policy_std_loss     | 16.4     |\n",
      "|    std                 | 2.65     |\n",
      "|    temperature         | 6.7      |\n",
      "|    temperature_loss    | 1.77e+11 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 245       |\n",
      "|    ep_rew_mean         | -120      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 192       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 709       |\n",
      "|    total_timesteps     | 47824     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.98e+11  |\n",
      "|    alpha_mean          | 4.94      |\n",
      "|    alpha_mean_loss     | -7.55e+04 |\n",
      "|    alpha_std           | 14.9      |\n",
      "|    alpha_std_loss      | -0.0602   |\n",
      "|    critic_loss         | 7.71e+22  |\n",
      "|    dual_loss           | 1.98e+11  |\n",
      "|    kl_loss             | 7.55e+04  |\n",
      "|    kl_mean_loss        | 7.55e+04  |\n",
      "|    kl_std_loss         | 0.0602    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 47713     |\n",
      "|    penalty_temperature | 13        |\n",
      "|    policy_loss         | 2.7e+04   |\n",
      "|    policy_mean_loss    | 2.7e+04   |\n",
      "|    policy_std_loss     | 16.6      |\n",
      "|    std                 | 2.77      |\n",
      "|    temperature         | 6.7       |\n",
      "|    temperature_loss    | 1.98e+11  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 258       |\n",
      "|    ep_rew_mean         | -120      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 196       |\n",
      "|    fps                 | 69        |\n",
      "|    time_elapsed        | 712       |\n",
      "|    total_timesteps     | 49565     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.24e+11  |\n",
      "|    alpha_mean          | 4.96      |\n",
      "|    alpha_mean_loss     | -1.64e+05 |\n",
      "|    alpha_std           | 14.9      |\n",
      "|    alpha_std_loss      | -0.0607   |\n",
      "|    critic_loss         | 1.39e+23  |\n",
      "|    dual_loss           | 2.24e+11  |\n",
      "|    kl_loss             | 1.64e+05  |\n",
      "|    kl_mean_loss        | 1.64e+05  |\n",
      "|    kl_std_loss         | 0.0608    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 47902     |\n",
      "|    penalty_temperature | 13.1      |\n",
      "|    policy_loss         | 5.85e+04  |\n",
      "|    policy_mean_loss    | 5.85e+04  |\n",
      "|    policy_std_loss     | 16.7      |\n",
      "|    std                 | 2.89      |\n",
      "|    temperature         | 6.7       |\n",
      "|    temperature_loss    | 2.24e+11  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 256       |\n",
      "|    ep_rew_mean         | -120      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 200       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 738       |\n",
      "|    total_timesteps     | 49751     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 5.56e+11  |\n",
      "|    alpha_mean          | 5.2       |\n",
      "|    alpha_mean_loss     | -3.09e+05 |\n",
      "|    alpha_std           | 15.1      |\n",
      "|    alpha_std_loss      | -0.066    |\n",
      "|    critic_loss         | 6.34e+23  |\n",
      "|    dual_loss           | 5.56e+11  |\n",
      "|    kl_loss             | 3.09e+05  |\n",
      "|    kl_mean_loss        | 3.09e+05  |\n",
      "|    kl_std_loss         | 0.0661    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 49648     |\n",
      "|    penalty_temperature | 13.8      |\n",
      "|    policy_loss         | 1.05e+05  |\n",
      "|    policy_mean_loss    | 1.05e+05  |\n",
      "|    policy_std_loss     | 17.9      |\n",
      "|    std                 | 4.55      |\n",
      "|    temperature         | 6.71      |\n",
      "|    temperature_loss    | 5.56e+11  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 269      |\n",
      "|    ep_rew_mean         | -120     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 204      |\n",
      "|    fps                 | 69       |\n",
      "|    time_elapsed        | 741      |\n",
      "|    total_timesteps     | 51482    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.96e+11 |\n",
      "|    alpha_mean          | 5.23     |\n",
      "|    alpha_mean_loss     | -8.3e+04 |\n",
      "|    alpha_std           | 15.1     |\n",
      "|    alpha_std_loss      | -0.0681  |\n",
      "|    critic_loss         | 5.66e+23 |\n",
      "|    dual_loss           | 5.96e+11 |\n",
      "|    kl_loss             | 8.3e+04  |\n",
      "|    kl_mean_loss        | 8.3e+04  |\n",
      "|    kl_std_loss         | 0.0682   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 49819    |\n",
      "|    penalty_temperature | 13.9     |\n",
      "|    policy_loss         | 2.8e+04  |\n",
      "|    policy_mean_loss    | 2.8e+04  |\n",
      "|    policy_std_loss     | 18.1     |\n",
      "|    std                 | 4.77     |\n",
      "|    temperature         | 6.71     |\n",
      "|    temperature_loss    | 5.96e+11 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 268       |\n",
      "|    ep_rew_mean         | -120      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 208       |\n",
      "|    fps                 | 69        |\n",
      "|    time_elapsed        | 768       |\n",
      "|    total_timesteps     | 53218     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.05e+12  |\n",
      "|    alpha_mean          | 5.45      |\n",
      "|    alpha_mean_loss     | -4.29e+05 |\n",
      "|    alpha_std           | 15.2      |\n",
      "|    alpha_std_loss      | -0.0725   |\n",
      "|    critic_loss         | 1.61e+24  |\n",
      "|    dual_loss           | 1.05e+12  |\n",
      "|    kl_loss             | 4.29e+05  |\n",
      "|    kl_mean_loss        | 4.29e+05  |\n",
      "|    kl_std_loss         | 0.0726    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 51555     |\n",
      "|    penalty_temperature | 14.6      |\n",
      "|    policy_loss         | 1.39e+05  |\n",
      "|    policy_mean_loss    | 1.39e+05  |\n",
      "|    policy_std_loss     | 19.4      |\n",
      "|    std                 | 8         |\n",
      "|    temperature         | 6.71      |\n",
      "|    temperature_loss    | 1.05e+12  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 268       |\n",
      "|    ep_rew_mean         | -119      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 212       |\n",
      "|    fps                 | 69        |\n",
      "|    time_elapsed        | 793       |\n",
      "|    total_timesteps     | 54958     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.64e+12  |\n",
      "|    alpha_mean          | 5.67      |\n",
      "|    alpha_mean_loss     | -7.65e+05 |\n",
      "|    alpha_std           | 15.2      |\n",
      "|    alpha_std_loss      | -0.0671   |\n",
      "|    critic_loss         | 2.55e+24  |\n",
      "|    dual_loss           | 1.64e+12  |\n",
      "|    kl_loss             | 7.65e+05  |\n",
      "|    kl_mean_loss        | 7.65e+05  |\n",
      "|    kl_std_loss         | 0.0671    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 53295     |\n",
      "|    penalty_temperature | 15.2      |\n",
      "|    policy_loss         | 2.37e+05  |\n",
      "|    policy_mean_loss    | 2.37e+05  |\n",
      "|    policy_std_loss     | 20.5      |\n",
      "|    std                 | 13.6      |\n",
      "|    temperature         | 6.71      |\n",
      "|    temperature_loss    | 1.64e+12  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 265      |\n",
      "|    ep_rew_mean         | -118     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 216      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 819      |\n",
      "|    total_timesteps     | 55141    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.8e+12  |\n",
      "|    alpha_mean          | 5.92     |\n",
      "|    alpha_mean_loss     | -5.7e+05 |\n",
      "|    alpha_std           | 15.2     |\n",
      "|    alpha_std_loss      | -0.0599  |\n",
      "|    critic_loss         | 6.85e+24 |\n",
      "|    dual_loss           | 2.8e+12  |\n",
      "|    kl_loss             | 5.7e+05  |\n",
      "|    kl_mean_loss        | 5.7e+05  |\n",
      "|    kl_std_loss         | 0.06     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 55032    |\n",
      "|    penalty_temperature | 15.8     |\n",
      "|    policy_loss         | 1.69e+05 |\n",
      "|    policy_mean_loss    | 1.69e+05 |\n",
      "|    policy_std_loss     | 21.5     |\n",
      "|    std                 | 22.5     |\n",
      "|    temperature         | 6.72     |\n",
      "|    temperature_loss    | 2.8e+12  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 261       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 220       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 822       |\n",
      "|    total_timesteps     | 55342     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.93e+12  |\n",
      "|    alpha_mean          | 5.94      |\n",
      "|    alpha_mean_loss     | -7.77e+05 |\n",
      "|    alpha_std           | 15.1      |\n",
      "|    alpha_std_loss      | -0.0599   |\n",
      "|    critic_loss         | 7.49e+24  |\n",
      "|    dual_loss           | 2.93e+12  |\n",
      "|    kl_loss             | 7.77e+05  |\n",
      "|    kl_mean_loss        | 7.77e+05  |\n",
      "|    kl_std_loss         | 0.0599    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 55227     |\n",
      "|    penalty_temperature | 15.9      |\n",
      "|    policy_loss         | 2.3e+05   |\n",
      "|    policy_mean_loss    | 2.3e+05   |\n",
      "|    policy_std_loss     | 21.6      |\n",
      "|    std                 | 23.8      |\n",
      "|    temperature         | 6.73      |\n",
      "|    temperature_loss    | 2.93e+12  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 271       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 224       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 848       |\n",
      "|    total_timesteps     | 57080     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 5.04e+12  |\n",
      "|    alpha_mean          | 6.18      |\n",
      "|    alpha_mean_loss     | -1.68e+06 |\n",
      "|    alpha_std           | 15        |\n",
      "|    alpha_std_loss      | -0.0559   |\n",
      "|    critic_loss         | 2.15e+25  |\n",
      "|    dual_loss           | 5.04e+12  |\n",
      "|    kl_loss             | 1.68e+06  |\n",
      "|    kl_mean_loss        | 1.68e+06  |\n",
      "|    kl_std_loss         | 0.0559    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 56972     |\n",
      "|    penalty_temperature | 16.5      |\n",
      "|    policy_loss         | 4.78e+05  |\n",
      "|    policy_mean_loss    | 4.78e+05  |\n",
      "|    policy_std_loss     | 22.6      |\n",
      "|    std                 | 38.9      |\n",
      "|    temperature         | 6.73      |\n",
      "|    temperature_loss    | 5.04e+12  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 297       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 228       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 896       |\n",
      "|    total_timesteps     | 60374     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.42e+13  |\n",
      "|    alpha_mean          | 6.61      |\n",
      "|    alpha_mean_loss     | -3.16e+06 |\n",
      "|    alpha_std           | 14.8      |\n",
      "|    alpha_std_loss      | -0.0549   |\n",
      "|    critic_loss         | 7.99e+25  |\n",
      "|    dual_loss           | 1.42e+13  |\n",
      "|    kl_loss             | 3.16e+06  |\n",
      "|    kl_mean_loss        | 3.16e+06  |\n",
      "|    kl_std_loss         | 0.055     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 60264     |\n",
      "|    penalty_temperature | 17.6      |\n",
      "|    policy_loss         | 8.39e+05  |\n",
      "|    policy_mean_loss    | 8.39e+05  |\n",
      "|    policy_std_loss     | 24.4      |\n",
      "|    std                 | 95.5      |\n",
      "|    temperature         | 6.73      |\n",
      "|    temperature_loss    | 1.42e+13  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 303       |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 232       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 945       |\n",
      "|    total_timesteps     | 63670     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.96e+13  |\n",
      "|    alpha_mean          | 6.97      |\n",
      "|    alpha_mean_loss     | -7.78e+06 |\n",
      "|    alpha_std           | 14.7      |\n",
      "|    alpha_std_loss      | -0.0545   |\n",
      "|    critic_loss         | 2.28e+26  |\n",
      "|    dual_loss           | 2.96e+13  |\n",
      "|    kl_loss             | 7.78e+06  |\n",
      "|    kl_mean_loss        | 7.78e+06  |\n",
      "|    kl_std_loss         | 0.0546    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 63562     |\n",
      "|    penalty_temperature | 18.4      |\n",
      "|    policy_loss         | 1.96e+06  |\n",
      "|    policy_mean_loss    | 1.96e+06  |\n",
      "|    policy_std_loss     | 25.7      |\n",
      "|    std                 | 231       |\n",
      "|    temperature         | 6.72      |\n",
      "|    temperature_loss    | 2.96e+13  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 272       |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 236       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 948       |\n",
      "|    total_timesteps     | 63886     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.83e+13  |\n",
      "|    alpha_mean          | 7.1       |\n",
      "|    alpha_mean_loss     | -7.91e+06 |\n",
      "|    alpha_std           | 14.7      |\n",
      "|    alpha_std_loss      | -0.0553   |\n",
      "|    critic_loss         | 3.37e+26  |\n",
      "|    dual_loss           | 3.83e+13  |\n",
      "|    kl_loss             | 7.91e+06  |\n",
      "|    kl_mean_loss        | 7.91e+06  |\n",
      "|    kl_std_loss         | 0.0554    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 63766     |\n",
      "|    penalty_temperature | 18.7      |\n",
      "|    policy_loss         | 1.95e+06  |\n",
      "|    policy_mean_loss    | 1.95e+06  |\n",
      "|    policy_std_loss     | 26.2      |\n",
      "|    std                 | 244       |\n",
      "|    temperature         | 6.71      |\n",
      "|    temperature_loss    | 3.83e+13  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 257       |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 240       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 951       |\n",
      "|    total_timesteps     | 64099     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.06e+13  |\n",
      "|    alpha_mean          | 7.14      |\n",
      "|    alpha_mean_loss     | -1.06e+07 |\n",
      "|    alpha_std           | 14.7      |\n",
      "|    alpha_std_loss      | -0.0554   |\n",
      "|    critic_loss         | 3.95e+26  |\n",
      "|    dual_loss           | 4.06e+13  |\n",
      "|    kl_loss             | 1.06e+07  |\n",
      "|    kl_mean_loss        | 1.06e+07  |\n",
      "|    kl_std_loss         | 0.0555    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 63986     |\n",
      "|    penalty_temperature | 18.7      |\n",
      "|    policy_loss         | 2.6e+06   |\n",
      "|    policy_mean_loss    | 2.6e+06   |\n",
      "|    policy_std_loss     | 26.3      |\n",
      "|    std                 | 258       |\n",
      "|    temperature         | 6.71      |\n",
      "|    temperature_loss    | 4.06e+13  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 289       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 244       |\n",
      "|    fps                 | 68        |\n",
      "|    time_elapsed        | 978       |\n",
      "|    total_timesteps     | 67410     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 5.24e+13  |\n",
      "|    alpha_mean          | 7.29      |\n",
      "|    alpha_mean_loss     | -1.53e+07 |\n",
      "|    alpha_std           | 14.6      |\n",
      "|    alpha_std_loss      | -0.0553   |\n",
      "|    critic_loss         | 5.81e+26  |\n",
      "|    dual_loss           | 5.24e+13  |\n",
      "|    kl_loss             | 1.53e+07  |\n",
      "|    kl_mean_loss        | 1.53e+07  |\n",
      "|    kl_std_loss         | 0.0554    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 65747     |\n",
      "|    penalty_temperature | 19        |\n",
      "|    policy_loss         | 3.68e+06  |\n",
      "|    policy_mean_loss    | 3.68e+06  |\n",
      "|    policy_std_loss     | 26.9      |\n",
      "|    std                 | 411       |\n",
      "|    temperature         | 6.68      |\n",
      "|    temperature_loss    | 5.24e+13  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 273       |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 248       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1003      |\n",
      "|    total_timesteps     | 67615     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 9.85e+13  |\n",
      "|    alpha_mean          | 7.65      |\n",
      "|    alpha_mean_loss     | -1.77e+07 |\n",
      "|    alpha_std           | 14.6      |\n",
      "|    alpha_std_loss      | -0.055    |\n",
      "|    critic_loss         | 1.78e+27  |\n",
      "|    dual_loss           | 9.85e+13  |\n",
      "|    kl_loss             | 1.77e+07  |\n",
      "|    kl_mean_loss        | 1.77e+07  |\n",
      "|    kl_std_loss         | 0.0551    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 67495     |\n",
      "|    penalty_temperature | 19.8      |\n",
      "|    policy_loss         | 4.07e+06  |\n",
      "|    policy_mean_loss    | 4.07e+06  |\n",
      "|    policy_std_loss     | 28.1      |\n",
      "|    std                 | 648       |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 9.85e+13  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 289       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 252       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1029      |\n",
      "|    total_timesteps     | 69357     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.27e+14  |\n",
      "|    alpha_mean          | 7.8       |\n",
      "|    alpha_mean_loss     | -3.59e+07 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0547   |\n",
      "|    critic_loss         | 2.91e+27  |\n",
      "|    dual_loss           | 1.27e+14  |\n",
      "|    kl_loss             | 3.59e+07  |\n",
      "|    kl_mean_loss        | 3.59e+07  |\n",
      "|    kl_std_loss         | 0.0548    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 69247     |\n",
      "|    penalty_temperature | 20.1      |\n",
      "|    policy_loss         | 8.09e+06  |\n",
      "|    policy_mean_loss    | 8.09e+06  |\n",
      "|    policy_std_loss     | 28.6      |\n",
      "|    std                 | 1.02e+03  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 1.27e+14  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 335       |\n",
      "|    ep_rew_mean         | -119      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 256       |\n",
      "|    fps                 | 68        |\n",
      "|    time_elapsed        | 1078      |\n",
      "|    total_timesteps     | 74217     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.88e+14  |\n",
      "|    alpha_mean          | 8.26      |\n",
      "|    alpha_mean_loss     | -6.55e+07 |\n",
      "|    alpha_std           | 14.4      |\n",
      "|    alpha_std_loss      | -0.0536   |\n",
      "|    critic_loss         | 1.4e+28   |\n",
      "|    dual_loss           | 2.88e+14  |\n",
      "|    kl_loss             | 6.55e+07  |\n",
      "|    kl_mean_loss        | 6.55e+07  |\n",
      "|    kl_std_loss         | 0.0537    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 72554     |\n",
      "|    penalty_temperature | 21.1      |\n",
      "|    policy_loss         | 1.39e+07  |\n",
      "|    policy_mean_loss    | 1.39e+07  |\n",
      "|    policy_std_loss     | 30.3      |\n",
      "|    std                 | 2.32e+03  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 2.88e+14  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 320       |\n",
      "|    ep_rew_mean         | -119      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 260       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1105      |\n",
      "|    total_timesteps     | 74467     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 5.22e+14  |\n",
      "|    alpha_mean          | 8.63      |\n",
      "|    alpha_mean_loss     | -1.97e+08 |\n",
      "|    alpha_std           | 14.3      |\n",
      "|    alpha_std_loss      | -0.0519   |\n",
      "|    critic_loss         | 4.39e+28  |\n",
      "|    dual_loss           | 5.22e+14  |\n",
      "|    kl_loss             | 1.97e+08  |\n",
      "|    kl_mean_loss        | 1.97e+08  |\n",
      "|    kl_std_loss         | 0.052     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 74331     |\n",
      "|    penalty_temperature | 21.9      |\n",
      "|    policy_loss         | 4e+07     |\n",
      "|    policy_mean_loss    | 4e+07     |\n",
      "|    policy_std_loss     | 31.5      |\n",
      "|    std                 | 3.57e+03  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 5.22e+14  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 335       |\n",
      "|    ep_rew_mean         | -119      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 264       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1133      |\n",
      "|    total_timesteps     | 76359     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 6.9e+14   |\n",
      "|    alpha_mean          | 8.8       |\n",
      "|    alpha_mean_loss     | -1.27e+08 |\n",
      "|    alpha_std           | 14.3      |\n",
      "|    alpha_std_loss      | -0.0507   |\n",
      "|    critic_loss         | 7.67e+28  |\n",
      "|    dual_loss           | 6.9e+14   |\n",
      "|    kl_loss             | 1.27e+08  |\n",
      "|    kl_mean_loss        | 1.27e+08  |\n",
      "|    kl_std_loss         | 0.0508    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 76246     |\n",
      "|    penalty_temperature | 22.2      |\n",
      "|    policy_loss         | 2.53e+07  |\n",
      "|    policy_mean_loss    | 2.53e+07  |\n",
      "|    policy_std_loss     | 32.1      |\n",
      "|    std                 | 5.61e+03  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 6.9e+14   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 352       |\n",
      "|    ep_rew_mean         | -120      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 268       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1160      |\n",
      "|    total_timesteps     | 78255     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.22e+15  |\n",
      "|    alpha_mean          | 9.17      |\n",
      "|    alpha_mean_loss     | -1.99e+08 |\n",
      "|    alpha_std           | 14.2      |\n",
      "|    alpha_std_loss      | -0.0479   |\n",
      "|    critic_loss         | 2.31e+29  |\n",
      "|    dual_loss           | 1.22e+15  |\n",
      "|    kl_loss             | 1.99e+08  |\n",
      "|    kl_mean_loss        | 1.99e+08  |\n",
      "|    kl_std_loss         | 0.048     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 78081     |\n",
      "|    penalty_temperature | 23        |\n",
      "|    policy_loss         | 3.81e+07  |\n",
      "|    policy_mean_loss    | 3.81e+07  |\n",
      "|    policy_std_loss     | 33.2      |\n",
      "|    std                 | 8.53e+03  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 1.22e+15  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 356       |\n",
      "|    ep_rew_mean         | -120      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 272       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1174      |\n",
      "|    total_timesteps     | 79103     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.5e+15   |\n",
      "|    alpha_mean          | 9.31      |\n",
      "|    alpha_mean_loss     | -2.62e+08 |\n",
      "|    alpha_std           | 14.1      |\n",
      "|    alpha_std_loss      | -0.0472   |\n",
      "|    critic_loss         | 3.41e+29  |\n",
      "|    dual_loss           | 1.5e+15   |\n",
      "|    kl_loss             | 2.62e+08  |\n",
      "|    kl_mean_loss        | 2.62e+08  |\n",
      "|    kl_std_loss         | 0.0473    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 78986     |\n",
      "|    penalty_temperature | 23.3      |\n",
      "|    policy_loss         | 4.96e+07  |\n",
      "|    policy_mean_loss    | 4.96e+07  |\n",
      "|    policy_std_loss     | 33.6      |\n",
      "|    std                 | 1.05e+04  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 1.5e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 338       |\n",
      "|    ep_rew_mean         | -120      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 276       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1178      |\n",
      "|    total_timesteps     | 79369     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.59e+15  |\n",
      "|    alpha_mean          | 9.35      |\n",
      "|    alpha_mean_loss     | -1.22e+08 |\n",
      "|    alpha_std           | 14.1      |\n",
      "|    alpha_std_loss      | -0.0469   |\n",
      "|    critic_loss         | 3.77e+29  |\n",
      "|    dual_loss           | 1.59e+15  |\n",
      "|    kl_loss             | 1.22e+08  |\n",
      "|    kl_mean_loss        | 1.22e+08  |\n",
      "|    kl_std_loss         | 0.047     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 79244     |\n",
      "|    penalty_temperature | 23.4      |\n",
      "|    policy_loss         | 2.3e+07   |\n",
      "|    policy_mean_loss    | 2.3e+07   |\n",
      "|    policy_std_loss     | 33.8      |\n",
      "|    std                 | 1.11e+04  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 1.59e+15  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 323       |\n",
      "|    ep_rew_mean         | -119      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 280       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1182      |\n",
      "|    total_timesteps     | 79621     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.68e+15  |\n",
      "|    alpha_mean          | 9.39      |\n",
      "|    alpha_mean_loss     | -2.49e+08 |\n",
      "|    alpha_std           | 14.1      |\n",
      "|    alpha_std_loss      | -0.0462   |\n",
      "|    critic_loss         | 4.19e+29  |\n",
      "|    dual_loss           | 1.68e+15  |\n",
      "|    kl_loss             | 2.49e+08  |\n",
      "|    kl_mean_loss        | 2.49e+08  |\n",
      "|    kl_std_loss         | 0.0462    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 79513     |\n",
      "|    penalty_temperature | 23.4      |\n",
      "|    policy_loss         | 4.67e+07  |\n",
      "|    policy_mean_loss    | 4.67e+07  |\n",
      "|    policy_std_loss     | 33.9      |\n",
      "|    std                 | 1.17e+04  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 1.68e+15  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 335       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 284       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1200      |\n",
      "|    total_timesteps     | 80916     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.21e+15  |\n",
      "|    alpha_mean          | 9.59      |\n",
      "|    alpha_mean_loss     | -3.32e+08 |\n",
      "|    alpha_std           | 14.1      |\n",
      "|    alpha_std_loss      | -0.0455   |\n",
      "|    critic_loss         | 7.12e+29  |\n",
      "|    dual_loss           | 2.21e+15  |\n",
      "|    kl_loss             | 3.32e+08  |\n",
      "|    kl_mean_loss        | 3.32e+08  |\n",
      "|    kl_std_loss         | 0.0455    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 80792     |\n",
      "|    penalty_temperature | 23.8      |\n",
      "|    policy_loss         | 6.1e+07   |\n",
      "|    policy_mean_loss    | 6.1e+07   |\n",
      "|    policy_std_loss     | 34.4      |\n",
      "|    std                 | 1.55e+04  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 2.21e+15  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 335       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 288       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1203      |\n",
      "|    total_timesteps     | 81124     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.3e+15   |\n",
      "|    alpha_mean          | 9.62      |\n",
      "|    alpha_mean_loss     | -4.86e+08 |\n",
      "|    alpha_std           | 14.1      |\n",
      "|    alpha_std_loss      | -0.0443   |\n",
      "|    critic_loss         | 7.69e+29  |\n",
      "|    dual_loss           | 2.3e+15   |\n",
      "|    kl_loss             | 4.86e+08  |\n",
      "|    kl_mean_loss        | 4.86e+08  |\n",
      "|    kl_std_loss         | 0.0444    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 80994     |\n",
      "|    penalty_temperature | 23.9      |\n",
      "|    policy_loss         | 8.9e+07   |\n",
      "|    policy_mean_loss    | 8.9e+07   |\n",
      "|    policy_std_loss     | 34.5      |\n",
      "|    std                 | 1.62e+04  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 2.3e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 338       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 292       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1209      |\n",
      "|    total_timesteps     | 81582     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.48e+15  |\n",
      "|    alpha_mean          | 9.67      |\n",
      "|    alpha_mean_loss     | -2.83e+08 |\n",
      "|    alpha_std           | 14.1      |\n",
      "|    alpha_std_loss      | -0.0434   |\n",
      "|    critic_loss         | 8.68e+29  |\n",
      "|    dual_loss           | 2.48e+15  |\n",
      "|    kl_loss             | 2.83e+08  |\n",
      "|    kl_mean_loss        | 2.83e+08  |\n",
      "|    kl_std_loss         | 0.0435    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 81392     |\n",
      "|    penalty_temperature | 24        |\n",
      "|    policy_loss         | 5.14e+07  |\n",
      "|    policy_mean_loss    | 5.14e+07  |\n",
      "|    policy_std_loss     | 34.7      |\n",
      "|    std                 | 1.76e+04  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 2.48e+15  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 367       |\n",
      "|    ep_rew_mean         | -122      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 296       |\n",
      "|    fps                 | 68        |\n",
      "|    time_elapsed        | 1256      |\n",
      "|    total_timesteps     | 86217     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.03e+15  |\n",
      "|    alpha_mean          | 9.97      |\n",
      "|    alpha_mean_loss     | -5.17e+08 |\n",
      "|    alpha_std           | 14.1      |\n",
      "|    alpha_std_loss      | -0.041    |\n",
      "|    critic_loss         | 2.16e+30  |\n",
      "|    dual_loss           | 4.03e+15  |\n",
      "|    kl_loss             | 5.17e+08  |\n",
      "|    kl_mean_loss        | 5.17e+08  |\n",
      "|    kl_std_loss         | 0.041     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 84554     |\n",
      "|    penalty_temperature | 24.7      |\n",
      "|    policy_loss         | 9.1e+07   |\n",
      "|    policy_mean_loss    | 9.1e+07   |\n",
      "|    policy_std_loss     | 35.6      |\n",
      "|    std                 | 3.36e+04  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 4.03e+15  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 412       |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 300       |\n",
      "|    fps                 | 68        |\n",
      "|    time_elapsed        | 1328      |\n",
      "|    total_timesteps     | 90920     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 9.75e+15  |\n",
      "|    alpha_mean          | 10.2      |\n",
      "|    alpha_mean_loss     | -9.51e+08 |\n",
      "|    alpha_std           | 14        |\n",
      "|    alpha_std_loss      | -0.0343   |\n",
      "|    critic_loss         | 1.08e+31  |\n",
      "|    dual_loss           | 9.75e+15  |\n",
      "|    kl_loss             | 9.51e+08  |\n",
      "|    kl_mean_loss        | 9.51e+08  |\n",
      "|    kl_std_loss         | 0.0343    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 89424     |\n",
      "|    penalty_temperature | 26.2      |\n",
      "|    policy_loss         | 1.57e+08  |\n",
      "|    policy_mean_loss    | 1.57e+08  |\n",
      "|    policy_std_loss     | 37.4      |\n",
      "|    std                 | 8.31e+04  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 9.75e+15  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 439       |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 304       |\n",
      "|    fps                 | 68        |\n",
      "|    time_elapsed        | 1399      |\n",
      "|    total_timesteps     | 95353     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.1e+16   |\n",
      "|    alpha_mean          | 10.4      |\n",
      "|    alpha_mean_loss     | -1.91e+09 |\n",
      "|    alpha_std           | 14.1      |\n",
      "|    alpha_std_loss      | -0.0293   |\n",
      "|    critic_loss         | 4.33e+31  |\n",
      "|    dual_loss           | 2.1e+16   |\n",
      "|    kl_loss             | 1.91e+09  |\n",
      "|    kl_mean_loss        | 1.91e+09  |\n",
      "|    kl_std_loss         | 0.0294    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 94144     |\n",
      "|    penalty_temperature | 27.6      |\n",
      "|    policy_loss         | 2.96e+08  |\n",
      "|    policy_mean_loss    | 2.96e+08  |\n",
      "|    policy_std_loss     | 38.9      |\n",
      "|    std                 | 1.83e+05  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 2.1e+16   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 439       |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 308       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1440      |\n",
      "|    total_timesteps     | 97085     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.18e+16  |\n",
      "|    alpha_mean          | 10.5      |\n",
      "|    alpha_mean_loss     | -2.88e+09 |\n",
      "|    alpha_std           | 14.1      |\n",
      "|    alpha_std_loss      | -0.0266   |\n",
      "|    critic_loss         | 9.07e+31  |\n",
      "|    dual_loss           | 3.18e+16  |\n",
      "|    kl_loss             | 2.88e+09  |\n",
      "|    kl_mean_loss        | 2.88e+09  |\n",
      "|    kl_std_loss         | 0.0267    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 96979     |\n",
      "|    penalty_temperature | 28.4      |\n",
      "|    policy_loss         | 4.32e+08  |\n",
      "|    policy_mean_loss    | 4.32e+08  |\n",
      "|    policy_std_loss     | 39.8      |\n",
      "|    std                 | 2.82e+05  |\n",
      "|    temperature         | 6.63      |\n",
      "|    temperature_loss    | 3.18e+16  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 436      |\n",
      "|    ep_rew_mean         | -124     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 312      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 1461     |\n",
      "|    total_timesteps     | 98510    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.25e+16 |\n",
      "|    alpha_mean          | 10.7     |\n",
      "|    alpha_mean_loss     | -4.2e+09 |\n",
      "|    alpha_std           | 14.2     |\n",
      "|    alpha_std_loss      | -0.0252  |\n",
      "|    critic_loss         | 1.5e+32  |\n",
      "|    dual_loss           | 4.25e+16 |\n",
      "|    kl_loss             | 4.2e+09  |\n",
      "|    kl_mean_loss        | 4.2e+09  |\n",
      "|    kl_std_loss         | 0.0252   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 98357    |\n",
      "|    penalty_temperature | 28.9     |\n",
      "|    policy_loss         | 6.15e+08 |\n",
      "|    policy_mean_loss    | 6.15e+08 |\n",
      "|    policy_std_loss     | 40.4     |\n",
      "|    std                 | 3.47e+05 |\n",
      "|    temperature         | 6.63     |\n",
      "|    temperature_loss    | 4.25e+16 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 437       |\n",
      "|    ep_rew_mean         | -125      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 316       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1466      |\n",
      "|    total_timesteps     | 98840     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.51e+16  |\n",
      "|    alpha_mean          | 10.7      |\n",
      "|    alpha_mean_loss     | -3.52e+09 |\n",
      "|    alpha_std           | 14.2      |\n",
      "|    alpha_std_loss      | -0.024    |\n",
      "|    critic_loss         | 1.7e+32   |\n",
      "|    dual_loss           | 4.51e+16  |\n",
      "|    kl_loss             | 3.52e+09  |\n",
      "|    kl_mean_loss        | 3.52e+09  |\n",
      "|    kl_std_loss         | 0.0241    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 98735     |\n",
      "|    penalty_temperature | 29        |\n",
      "|    policy_loss         | 5.12e+08  |\n",
      "|    policy_mean_loss    | 5.12e+08  |\n",
      "|    policy_std_loss     | 40.5      |\n",
      "|    std                 | 3.66e+05  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 4.51e+16  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 440       |\n",
      "|    ep_rew_mean         | -125      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 320       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1473      |\n",
      "|    total_timesteps     | 99307     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.8e+16   |\n",
      "|    alpha_mean          | 10.7      |\n",
      "|    alpha_mean_loss     | -3.21e+09 |\n",
      "|    alpha_std           | 14.2      |\n",
      "|    alpha_std_loss      | -0.0242   |\n",
      "|    critic_loss         | 1.89e+32  |\n",
      "|    dual_loss           | 4.8e+16   |\n",
      "|    kl_loss             | 3.21e+09  |\n",
      "|    kl_mean_loss        | 3.21e+09  |\n",
      "|    kl_std_loss         | 0.0243    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 99182     |\n",
      "|    penalty_temperature | 29.1      |\n",
      "|    policy_loss         | 4.65e+08  |\n",
      "|    policy_mean_loss    | 4.65e+08  |\n",
      "|    policy_std_loss     | 40.6      |\n",
      "|    std                 | 3.9e+05   |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 4.8e+16   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 429      |\n",
      "|    ep_rew_mean         | -125     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 324      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 1482     |\n",
      "|    total_timesteps     | 99944    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.22e+16 |\n",
      "|    alpha_mean          | 10.7     |\n",
      "|    alpha_mean_loss     | -4.8e+09 |\n",
      "|    alpha_std           | 14.2     |\n",
      "|    alpha_std_loss      | -0.024   |\n",
      "|    critic_loss         | 2.23e+32 |\n",
      "|    dual_loss           | 5.22e+16 |\n",
      "|    kl_loss             | 4.8e+09  |\n",
      "|    kl_mean_loss        | 4.8e+09  |\n",
      "|    kl_std_loss         | 0.0241   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 99831    |\n",
      "|    penalty_temperature | 29.3     |\n",
      "|    policy_loss         | 6.9e+08  |\n",
      "|    policy_mean_loss    | 6.9e+08  |\n",
      "|    policy_std_loss     | 40.8     |\n",
      "|    std                 | 4.28e+05 |\n",
      "|    temperature         | 6.6      |\n",
      "|    temperature_loss    | 5.22e+16 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 398      |\n",
      "|    ep_rew_mean         | -124     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 328      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 1486     |\n",
      "|    total_timesteps     | 100175   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.42e+16 |\n",
      "|    alpha_mean          | 10.8     |\n",
      "|    alpha_mean_loss     | -3.4e+09 |\n",
      "|    alpha_std           | 14.3     |\n",
      "|    alpha_std_loss      | -0.0242  |\n",
      "|    critic_loss         | 2.37e+32 |\n",
      "|    dual_loss           | 5.42e+16 |\n",
      "|    kl_loss             | 3.4e+09  |\n",
      "|    kl_mean_loss        | 3.4e+09  |\n",
      "|    kl_std_loss         | 0.0243   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 100066   |\n",
      "|    penalty_temperature | 29.3     |\n",
      "|    policy_loss         | 4.88e+08 |\n",
      "|    policy_mean_loss    | 4.88e+08 |\n",
      "|    policy_std_loss     | 40.9     |\n",
      "|    std                 | 4.43e+05 |\n",
      "|    temperature         | 6.6      |\n",
      "|    temperature_loss    | 5.42e+16 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 377      |\n",
      "|    ep_rew_mean         | -124     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 332      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 1501     |\n",
      "|    total_timesteps     | 101400   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.1e+16  |\n",
      "|    alpha_mean          | 10.8     |\n",
      "|    alpha_mean_loss     | -6.1e+09 |\n",
      "|    alpha_std           | 14.3     |\n",
      "|    alpha_std_loss      | -0.0233  |\n",
      "|    critic_loss         | 2.92e+32 |\n",
      "|    dual_loss           | 6.1e+16  |\n",
      "|    kl_loss             | 6.1e+09  |\n",
      "|    kl_mean_loss        | 6.1e+09  |\n",
      "|    kl_std_loss         | 0.0234   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 101116   |\n",
      "|    penalty_temperature | 29.6     |\n",
      "|    policy_loss         | 8.67e+08 |\n",
      "|    policy_mean_loss    | 8.67e+08 |\n",
      "|    policy_std_loss     | 41.1     |\n",
      "|    std                 | 5.12e+05 |\n",
      "|    temperature         | 6.59     |\n",
      "|    temperature_loss    | 6.1e+16  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 390       |\n",
      "|    ep_rew_mean         | -125      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 336       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1513      |\n",
      "|    total_timesteps     | 102886    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 6.74e+16  |\n",
      "|    alpha_mean          | 10.9      |\n",
      "|    alpha_mean_loss     | -6.43e+09 |\n",
      "|    alpha_std           | 14.3      |\n",
      "|    alpha_std_loss      | -0.0231   |\n",
      "|    critic_loss         | 3.52e+32  |\n",
      "|    dual_loss           | 6.74e+16  |\n",
      "|    kl_loss             | 6.43e+09  |\n",
      "|    kl_mean_loss        | 6.43e+09  |\n",
      "|    kl_std_loss         | 0.0232    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 101896    |\n",
      "|    penalty_temperature | 29.8      |\n",
      "|    policy_loss         | 9.04e+08  |\n",
      "|    policy_mean_loss    | 9.04e+08  |\n",
      "|    policy_std_loss     | 41.3      |\n",
      "|    std                 | 5.71e+05  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 6.74e+16  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 392       |\n",
      "|    ep_rew_mean         | -125      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 340       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1533      |\n",
      "|    total_timesteps     | 103336    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 8.19e+16  |\n",
      "|    alpha_mean          | 11        |\n",
      "|    alpha_mean_loss     | -6.94e+09 |\n",
      "|    alpha_std           | 14.3      |\n",
      "|    alpha_std_loss      | -0.0217   |\n",
      "|    critic_loss         | 5.07e+32  |\n",
      "|    dual_loss           | 8.19e+16  |\n",
      "|    kl_loss             | 6.94e+09  |\n",
      "|    kl_mean_loss        | 6.94e+09  |\n",
      "|    kl_std_loss         | 0.0218    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 103227    |\n",
      "|    penalty_temperature | 30.2      |\n",
      "|    policy_loss         | 9.6e+08   |\n",
      "|    policy_mean_loss    | 9.6e+08   |\n",
      "|    policy_std_loss     | 41.7      |\n",
      "|    std                 | 6.83e+05  |\n",
      "|    temperature         | 6.58      |\n",
      "|    temperature_loss    | 8.19e+16  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 367       |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 344       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1544      |\n",
      "|    total_timesteps     | 104079    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 8.97e+16  |\n",
      "|    alpha_mean          | 11        |\n",
      "|    alpha_mean_loss     | -1.18e+10 |\n",
      "|    alpha_std           | 14.4      |\n",
      "|    alpha_std_loss      | -0.0224   |\n",
      "|    critic_loss         | 6.01e+32  |\n",
      "|    dual_loss           | 8.97e+16  |\n",
      "|    kl_loss             | 1.18e+10  |\n",
      "|    kl_mean_loss        | 1.18e+10  |\n",
      "|    kl_std_loss         | 0.0225    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 103921    |\n",
      "|    penalty_temperature | 30.3      |\n",
      "|    policy_loss         | 1.62e+09  |\n",
      "|    policy_mean_loss    | 1.62e+09  |\n",
      "|    policy_std_loss     | 41.9      |\n",
      "|    std                 | 7.5e+05   |\n",
      "|    temperature         | 6.57      |\n",
      "|    temperature_loss    | 8.97e+16  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 368       |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 348       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1550      |\n",
      "|    total_timesteps     | 104460    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 9.49e+16  |\n",
      "|    alpha_mean          | 11.1      |\n",
      "|    alpha_mean_loss     | -5.96e+09 |\n",
      "|    alpha_std           | 14.4      |\n",
      "|    alpha_std_loss      | -0.0224   |\n",
      "|    critic_loss         | 6.66e+32  |\n",
      "|    dual_loss           | 9.49e+16  |\n",
      "|    kl_loss             | 5.96e+09  |\n",
      "|    kl_mean_loss        | 5.96e+09  |\n",
      "|    kl_std_loss         | 0.0224    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 104324    |\n",
      "|    penalty_temperature | 30.5      |\n",
      "|    policy_loss         | 8.14e+08  |\n",
      "|    policy_mean_loss    | 8.14e+08  |\n",
      "|    policy_std_loss     | 42.1      |\n",
      "|    std                 | 7.91e+05  |\n",
      "|    temperature         | 6.57      |\n",
      "|    temperature_loss    | 9.49e+16  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 355       |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 352       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1557      |\n",
      "|    total_timesteps     | 104906    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.01e+17  |\n",
      "|    alpha_mean          | 11.1      |\n",
      "|    alpha_mean_loss     | -7.29e+09 |\n",
      "|    alpha_std           | 14.4      |\n",
      "|    alpha_std_loss      | -0.0222   |\n",
      "|    critic_loss         | 7.46e+32  |\n",
      "|    dual_loss           | 1.01e+17  |\n",
      "|    kl_loss             | 7.29e+09  |\n",
      "|    kl_mean_loss        | 7.29e+09  |\n",
      "|    kl_std_loss         | 0.0223    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 104783    |\n",
      "|    penalty_temperature | 30.6      |\n",
      "|    policy_loss         | 9.92e+08  |\n",
      "|    policy_mean_loss    | 9.92e+08  |\n",
      "|    policy_std_loss     | 42.1      |\n",
      "|    std                 | 8.42e+05  |\n",
      "|    temperature         | 6.58      |\n",
      "|    temperature_loss    | 1.01e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 310       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 356       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1560      |\n",
      "|    total_timesteps     | 105255    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.04e+17  |\n",
      "|    alpha_mean          | 11.1      |\n",
      "|    alpha_mean_loss     | -9.78e+09 |\n",
      "|    alpha_std           | 14.4      |\n",
      "|    alpha_std_loss      | -0.022    |\n",
      "|    critic_loss         | 7.88e+32  |\n",
      "|    dual_loss           | 1.04e+17  |\n",
      "|    kl_loss             | 9.78e+09  |\n",
      "|    kl_mean_loss        | 9.78e+09  |\n",
      "|    kl_std_loss         | 0.022     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 105029    |\n",
      "|    penalty_temperature | 30.7      |\n",
      "|    policy_loss         | 1.33e+09  |\n",
      "|    policy_mean_loss    | 1.33e+09  |\n",
      "|    policy_std_loss     | 42.2      |\n",
      "|    std                 | 8.69e+05  |\n",
      "|    temperature         | 6.58      |\n",
      "|    temperature_loss    | 1.04e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 312       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 360       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1568      |\n",
      "|    total_timesteps     | 105679    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.1e+17   |\n",
      "|    alpha_mean          | 11.2      |\n",
      "|    alpha_mean_loss     | -9.88e+09 |\n",
      "|    alpha_std           | 14.4      |\n",
      "|    alpha_std_loss      | -0.021    |\n",
      "|    critic_loss         | 8.86e+32  |\n",
      "|    dual_loss           | 1.1e+17   |\n",
      "|    kl_loss             | 9.88e+09  |\n",
      "|    kl_mean_loss        | 9.88e+09  |\n",
      "|    kl_std_loss         | 0.0211    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 105534    |\n",
      "|    penalty_temperature | 30.8      |\n",
      "|    policy_loss         | 1.33e+09  |\n",
      "|    policy_mean_loss    | 1.33e+09  |\n",
      "|    policy_std_loss     | 42.4      |\n",
      "|    std                 | 9.27e+05  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.1e+17   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 296       |\n",
      "|    ep_rew_mean         | -122      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 364       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1573      |\n",
      "|    total_timesteps     | 105965    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.14e+17  |\n",
      "|    alpha_mean          | 11.2      |\n",
      "|    alpha_mean_loss     | -1.03e+10 |\n",
      "|    alpha_std           | 14.4      |\n",
      "|    alpha_std_loss      | -0.0214   |\n",
      "|    critic_loss         | 9.51e+32  |\n",
      "|    dual_loss           | 1.14e+17  |\n",
      "|    kl_loss             | 1.03e+10  |\n",
      "|    kl_mean_loss        | 1.03e+10  |\n",
      "|    kl_std_loss         | 0.0214    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 105840    |\n",
      "|    penalty_temperature | 30.9      |\n",
      "|    policy_loss         | 1.38e+09  |\n",
      "|    policy_mean_loss    | 1.38e+09  |\n",
      "|    policy_std_loss     | 42.4      |\n",
      "|    std                 | 9.64e+05  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.14e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 279       |\n",
      "|    ep_rew_mean         | -122      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 368       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1576      |\n",
      "|    total_timesteps     | 106198    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.18e+17  |\n",
      "|    alpha_mean          | 11.2      |\n",
      "|    alpha_mean_loss     | -7.43e+09 |\n",
      "|    alpha_std           | 14.4      |\n",
      "|    alpha_std_loss      | -0.0212   |\n",
      "|    critic_loss         | 9.96e+32  |\n",
      "|    dual_loss           | 1.18e+17  |\n",
      "|    kl_loss             | 7.43e+09  |\n",
      "|    kl_mean_loss        | 7.43e+09  |\n",
      "|    kl_std_loss         | 0.0213    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 106080    |\n",
      "|    penalty_temperature | 30.9      |\n",
      "|    policy_loss         | 9.97e+08  |\n",
      "|    policy_mean_loss    | 9.97e+08  |\n",
      "|    policy_std_loss     | 42.4      |\n",
      "|    std                 | 9.96e+05  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.18e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 273       |\n",
      "|    ep_rew_mean         | -122      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 372       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1580      |\n",
      "|    total_timesteps     | 106422    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.21e+17  |\n",
      "|    alpha_mean          | 11.2      |\n",
      "|    alpha_mean_loss     | -8.47e+09 |\n",
      "|    alpha_std           | 14.4      |\n",
      "|    alpha_std_loss      | -0.0213   |\n",
      "|    critic_loss         | 1.03e+33  |\n",
      "|    dual_loss           | 1.21e+17  |\n",
      "|    kl_loss             | 8.47e+09  |\n",
      "|    kl_mean_loss        | 8.47e+09  |\n",
      "|    kl_std_loss         | 0.0214    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 106304    |\n",
      "|    penalty_temperature | 31        |\n",
      "|    policy_loss         | 1.13e+09  |\n",
      "|    policy_mean_loss    | 1.13e+09  |\n",
      "|    policy_std_loss     | 42.5      |\n",
      "|    std                 | 1.03e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.21e+17  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 275      |\n",
      "|    ep_rew_mean         | -121     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 376      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 1585     |\n",
      "|    total_timesteps     | 106822   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.26e+17 |\n",
      "|    alpha_mean          | 11.3     |\n",
      "|    alpha_mean_loss     | -1.1e+10 |\n",
      "|    alpha_std           | 14.4     |\n",
      "|    alpha_std_loss      | -0.0207  |\n",
      "|    critic_loss         | 1.12e+33 |\n",
      "|    dual_loss           | 1.26e+17 |\n",
      "|    kl_loss             | 1.1e+10  |\n",
      "|    kl_mean_loss        | 1.1e+10  |\n",
      "|    kl_std_loss         | 0.0208   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 106645   |\n",
      "|    penalty_temperature | 31.1     |\n",
      "|    policy_loss         | 1.46e+09 |\n",
      "|    policy_mean_loss    | 1.46e+09 |\n",
      "|    policy_std_loss     | 42.6     |\n",
      "|    std                 | 1.07e+06 |\n",
      "|    temperature         | 6.59     |\n",
      "|    temperature_loss    | 1.26e+17 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 275       |\n",
      "|    ep_rew_mean         | -122      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 380       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1590      |\n",
      "|    total_timesteps     | 107110    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.32e+17  |\n",
      "|    alpha_mean          | 11.3      |\n",
      "|    alpha_mean_loss     | -8.88e+09 |\n",
      "|    alpha_std           | 14.4      |\n",
      "|    alpha_std_loss      | -0.0213   |\n",
      "|    critic_loss         | 1.22e+33  |\n",
      "|    dual_loss           | 1.32e+17  |\n",
      "|    kl_loss             | 8.88e+09  |\n",
      "|    kl_mean_loss        | 8.88e+09  |\n",
      "|    kl_std_loss         | 0.0213    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 106988    |\n",
      "|    penalty_temperature | 31.2      |\n",
      "|    policy_loss         | 1.18e+09  |\n",
      "|    policy_mean_loss    | 1.18e+09  |\n",
      "|    policy_std_loss     | 42.7      |\n",
      "|    std                 | 1.12e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.32e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 266       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 384       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1595      |\n",
      "|    total_timesteps     | 107515    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.38e+17  |\n",
      "|    alpha_mean          | 11.3      |\n",
      "|    alpha_mean_loss     | -1.06e+10 |\n",
      "|    alpha_std           | 14.4      |\n",
      "|    alpha_std_loss      | -0.0209   |\n",
      "|    critic_loss         | 1.33e+33  |\n",
      "|    dual_loss           | 1.38e+17  |\n",
      "|    kl_loss             | 1.06e+10  |\n",
      "|    kl_mean_loss        | 1.06e+10  |\n",
      "|    kl_std_loss         | 0.0209    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 107352    |\n",
      "|    penalty_temperature | 31.3      |\n",
      "|    policy_loss         | 1.41e+09  |\n",
      "|    policy_mean_loss    | 1.41e+09  |\n",
      "|    policy_std_loss     | 42.8      |\n",
      "|    std                 | 1.17e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.38e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 267       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 388       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1600      |\n",
      "|    total_timesteps     | 107794    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.43e+17  |\n",
      "|    alpha_mean          | 11.4      |\n",
      "|    alpha_mean_loss     | -9.49e+09 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0207   |\n",
      "|    critic_loss         | 1.43e+33  |\n",
      "|    dual_loss           | 1.43e+17  |\n",
      "|    kl_loss             | 9.49e+09  |\n",
      "|    kl_mean_loss        | 9.49e+09  |\n",
      "|    kl_std_loss         | 0.0207    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 107648    |\n",
      "|    penalty_temperature | 31.4      |\n",
      "|    policy_loss         | 1.25e+09  |\n",
      "|    policy_mean_loss    | 1.25e+09  |\n",
      "|    policy_std_loss     | 42.9      |\n",
      "|    std                 | 1.22e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.43e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 265       |\n",
      "|    ep_rew_mean         | -120      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 392       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1604      |\n",
      "|    total_timesteps     | 108054    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.47e+17  |\n",
      "|    alpha_mean          | 11.4      |\n",
      "|    alpha_mean_loss     | -1.19e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0203   |\n",
      "|    critic_loss         | 1.53e+33  |\n",
      "|    dual_loss           | 1.47e+17  |\n",
      "|    kl_loss             | 1.19e+10  |\n",
      "|    kl_mean_loss        | 1.19e+10  |\n",
      "|    kl_std_loss         | 0.0204    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 107925    |\n",
      "|    penalty_temperature | 31.5      |\n",
      "|    policy_loss         | 1.56e+09  |\n",
      "|    policy_mean_loss    | 1.56e+09  |\n",
      "|    policy_std_loss     | 42.9      |\n",
      "|    std                 | 1.26e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.47e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 221       |\n",
      "|    ep_rew_mean         | -119      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 396       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1608      |\n",
      "|    total_timesteps     | 108307    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.53e+17  |\n",
      "|    alpha_mean          | 11.4      |\n",
      "|    alpha_mean_loss     | -1.29e+10 |\n",
      "|    alpha_std           | 14.4      |\n",
      "|    alpha_std_loss      | -0.0205   |\n",
      "|    critic_loss         | 1.6e+33   |\n",
      "|    dual_loss           | 1.53e+17  |\n",
      "|    kl_loss             | 1.29e+10  |\n",
      "|    kl_mean_loss        | 1.29e+10  |\n",
      "|    kl_std_loss         | 0.0206    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 108198    |\n",
      "|    penalty_temperature | 31.5      |\n",
      "|    policy_loss         | 1.69e+09  |\n",
      "|    policy_mean_loss    | 1.69e+09  |\n",
      "|    policy_std_loss     | 43        |\n",
      "|    std                 | 1.31e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.53e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 177       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 400       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1612      |\n",
      "|    total_timesteps     | 108588    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.57e+17  |\n",
      "|    alpha_mean          | 11.4      |\n",
      "|    alpha_mean_loss     | -1.44e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0204   |\n",
      "|    critic_loss         | 1.7e+33   |\n",
      "|    dual_loss           | 1.57e+17  |\n",
      "|    kl_loss             | 1.44e+10  |\n",
      "|    kl_mean_loss        | 1.44e+10  |\n",
      "|    kl_std_loss         | 0.0204    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 108457    |\n",
      "|    penalty_temperature | 31.6      |\n",
      "|    policy_loss         | 1.89e+09  |\n",
      "|    policy_mean_loss    | 1.89e+09  |\n",
      "|    policy_std_loss     | 43.1      |\n",
      "|    std                 | 1.35e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.57e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 136       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 404       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1617      |\n",
      "|    total_timesteps     | 108964    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.64e+17  |\n",
      "|    alpha_mean          | 11.5      |\n",
      "|    alpha_mean_loss     | -1.35e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0212   |\n",
      "|    critic_loss         | 1.84e+33  |\n",
      "|    dual_loss           | 1.64e+17  |\n",
      "|    kl_loss             | 1.35e+10  |\n",
      "|    kl_mean_loss        | 1.35e+10  |\n",
      "|    kl_std_loss         | 0.0212    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 108831    |\n",
      "|    penalty_temperature | 31.7      |\n",
      "|    policy_loss         | 1.76e+09  |\n",
      "|    policy_mean_loss    | 1.76e+09  |\n",
      "|    policy_std_loss     | 43.2      |\n",
      "|    std                 | 1.41e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.64e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 122       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 408       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1622      |\n",
      "|    total_timesteps     | 109325    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.7e+17   |\n",
      "|    alpha_mean          | 11.5      |\n",
      "|    alpha_mean_loss     | -2.06e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0205   |\n",
      "|    critic_loss         | 1.96e+33  |\n",
      "|    dual_loss           | 1.7e+17   |\n",
      "|    kl_loss             | 2.06e+10  |\n",
      "|    kl_mean_loss        | 2.06e+10  |\n",
      "|    kl_std_loss         | 0.0206    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 109128    |\n",
      "|    penalty_temperature | 31.8      |\n",
      "|    policy_loss         | 2.67e+09  |\n",
      "|    policy_mean_loss    | 2.67e+09  |\n",
      "|    policy_std_loss     | 43.2      |\n",
      "|    std                 | 1.47e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.7e+17   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 111       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 412       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1627      |\n",
      "|    total_timesteps     | 109576    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.76e+17  |\n",
      "|    alpha_mean          | 11.5      |\n",
      "|    alpha_mean_loss     | -8.99e+09 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0196   |\n",
      "|    critic_loss         | 2.1e+33   |\n",
      "|    dual_loss           | 1.76e+17  |\n",
      "|    kl_loss             | 8.99e+09  |\n",
      "|    kl_mean_loss        | 8.99e+09  |\n",
      "|    kl_std_loss         | 0.0196    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 109449    |\n",
      "|    penalty_temperature | 31.9      |\n",
      "|    policy_loss         | 1.16e+09  |\n",
      "|    policy_mean_loss    | 1.16e+09  |\n",
      "|    policy_std_loss     | 43.3      |\n",
      "|    std                 | 1.53e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.76e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 110       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 416       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1631      |\n",
      "|    total_timesteps     | 109833    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.83e+17  |\n",
      "|    alpha_mean          | 11.6      |\n",
      "|    alpha_mean_loss     | -1.43e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0203   |\n",
      "|    critic_loss         | 2.23e+33  |\n",
      "|    dual_loss           | 1.83e+17  |\n",
      "|    kl_loss             | 1.43e+10  |\n",
      "|    kl_mean_loss        | 1.43e+10  |\n",
      "|    kl_std_loss         | 0.0204    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 109719    |\n",
      "|    penalty_temperature | 32        |\n",
      "|    policy_loss         | 1.85e+09  |\n",
      "|    policy_mean_loss    | 1.85e+09  |\n",
      "|    policy_std_loss     | 43.4      |\n",
      "|    std                 | 1.58e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.83e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 108       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 420       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1634      |\n",
      "|    total_timesteps     | 110059    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.87e+17  |\n",
      "|    alpha_mean          | 11.6      |\n",
      "|    alpha_mean_loss     | -7.99e+09 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0202   |\n",
      "|    critic_loss         | 2.35e+33  |\n",
      "|    dual_loss           | 1.87e+17  |\n",
      "|    kl_loss             | 7.99e+09  |\n",
      "|    kl_mean_loss        | 7.99e+09  |\n",
      "|    kl_std_loss         | 0.0202    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 109944    |\n",
      "|    penalty_temperature | 32        |\n",
      "|    policy_loss         | 1.03e+09  |\n",
      "|    policy_mean_loss    | 1.03e+09  |\n",
      "|    policy_std_loss     | 43.4      |\n",
      "|    std                 | 1.62e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.87e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 103       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 424       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1638      |\n",
      "|    total_timesteps     | 110280    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.93e+17  |\n",
      "|    alpha_mean          | 11.6      |\n",
      "|    alpha_mean_loss     | -1.49e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0207   |\n",
      "|    critic_loss         | 2.46e+33  |\n",
      "|    dual_loss           | 1.93e+17  |\n",
      "|    kl_loss             | 1.49e+10  |\n",
      "|    kl_mean_loss        | 1.49e+10  |\n",
      "|    kl_std_loss         | 0.0208    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 110178    |\n",
      "|    penalty_temperature | 32.1      |\n",
      "|    policy_loss         | 1.92e+09  |\n",
      "|    policy_mean_loss    | 1.92e+09  |\n",
      "|    policy_std_loss     | 43.5      |\n",
      "|    std                 | 1.67e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 1.93e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 108       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 428       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1649      |\n",
      "|    total_timesteps     | 111012    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.04e+17  |\n",
      "|    alpha_mean          | 11.7      |\n",
      "|    alpha_mean_loss     | -1.55e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0197   |\n",
      "|    critic_loss         | 2.75e+33  |\n",
      "|    dual_loss           | 2.04e+17  |\n",
      "|    kl_loss             | 1.55e+10  |\n",
      "|    kl_mean_loss        | 1.55e+10  |\n",
      "|    kl_std_loss         | 0.0197    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 110880    |\n",
      "|    penalty_temperature | 32.3      |\n",
      "|    policy_loss         | 1.99e+09  |\n",
      "|    policy_mean_loss    | 1.99e+09  |\n",
      "|    policy_std_loss     | 43.6      |\n",
      "|    std                 | 1.82e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 2.04e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 102       |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 432       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1657      |\n",
      "|    total_timesteps     | 111598    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.23e+17  |\n",
      "|    alpha_mean          | 11.8      |\n",
      "|    alpha_mean_loss     | -1.36e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.019    |\n",
      "|    critic_loss         | 3.26e+33  |\n",
      "|    dual_loss           | 2.23e+17  |\n",
      "|    kl_loss             | 1.36e+10  |\n",
      "|    kl_mean_loss        | 1.36e+10  |\n",
      "|    kl_std_loss         | 0.0191    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 111454    |\n",
      "|    penalty_temperature | 32.5      |\n",
      "|    policy_loss         | 1.72e+09  |\n",
      "|    policy_mean_loss    | 1.72e+09  |\n",
      "|    policy_std_loss     | 43.8      |\n",
      "|    std                 | 1.95e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 2.23e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89.6      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 436       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1661      |\n",
      "|    total_timesteps     | 111848    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.3e+17   |\n",
      "|    alpha_mean          | 11.8      |\n",
      "|    alpha_mean_loss     | -1.87e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0194   |\n",
      "|    critic_loss         | 3.47e+33  |\n",
      "|    dual_loss           | 2.3e+17   |\n",
      "|    kl_loss             | 1.87e+10  |\n",
      "|    kl_mean_loss        | 1.87e+10  |\n",
      "|    kl_std_loss         | 0.0194    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 111717    |\n",
      "|    penalty_temperature | 32.5      |\n",
      "|    policy_loss         | 2.36e+09  |\n",
      "|    policy_mean_loss    | 2.36e+09  |\n",
      "|    policy_std_loss     | 43.9      |\n",
      "|    std                 | 2.01e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 2.3e+17   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 87.8      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 440       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1665      |\n",
      "|    total_timesteps     | 112119    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.39e+17  |\n",
      "|    alpha_mean          | 11.8      |\n",
      "|    alpha_mean_loss     | -1.26e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0201   |\n",
      "|    critic_loss         | 3.69e+33  |\n",
      "|    dual_loss           | 2.39e+17  |\n",
      "|    kl_loss             | 1.26e+10  |\n",
      "|    kl_mean_loss        | 1.26e+10  |\n",
      "|    kl_std_loss         | 0.0202    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 111992    |\n",
      "|    penalty_temperature | 32.6      |\n",
      "|    policy_loss         | 1.59e+09  |\n",
      "|    policy_mean_loss    | 1.59e+09  |\n",
      "|    policy_std_loss     | 44        |\n",
      "|    std                 | 2.08e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 2.39e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 83.2      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 444       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1670      |\n",
      "|    total_timesteps     | 112400    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.46e+17  |\n",
      "|    alpha_mean          | 11.8      |\n",
      "|    alpha_mean_loss     | -1.74e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0197   |\n",
      "|    critic_loss         | 3.91e+33  |\n",
      "|    dual_loss           | 2.46e+17  |\n",
      "|    kl_loss             | 1.74e+10  |\n",
      "|    kl_mean_loss        | 1.74e+10  |\n",
      "|    kl_std_loss         | 0.0197    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 112271    |\n",
      "|    penalty_temperature | 32.7      |\n",
      "|    policy_loss         | 2.19e+09  |\n",
      "|    policy_mean_loss    | 2.19e+09  |\n",
      "|    policy_std_loss     | 44        |\n",
      "|    std                 | 2.15e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 2.46e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 82.3      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 448       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1674      |\n",
      "|    total_timesteps     | 112690    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.54e+17  |\n",
      "|    alpha_mean          | 11.9      |\n",
      "|    alpha_mean_loss     | -1.48e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0196   |\n",
      "|    critic_loss         | 4.15e+33  |\n",
      "|    dual_loss           | 2.54e+17  |\n",
      "|    kl_loss             | 1.48e+10  |\n",
      "|    kl_mean_loss        | 1.48e+10  |\n",
      "|    kl_std_loss         | 0.0197    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 112551    |\n",
      "|    penalty_temperature | 32.8      |\n",
      "|    policy_loss         | 1.86e+09  |\n",
      "|    policy_mean_loss    | 1.86e+09  |\n",
      "|    policy_std_loss     | 44.1      |\n",
      "|    std                 | 2.23e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 2.54e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 80.1      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 452       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1678      |\n",
      "|    total_timesteps     | 112914    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.61e+17  |\n",
      "|    alpha_mean          | 11.9      |\n",
      "|    alpha_mean_loss     | -1.88e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0196   |\n",
      "|    critic_loss         | 4.33e+33  |\n",
      "|    dual_loss           | 2.61e+17  |\n",
      "|    kl_loss             | 1.88e+10  |\n",
      "|    kl_mean_loss        | 1.88e+10  |\n",
      "|    kl_std_loss         | 0.0196    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 112797    |\n",
      "|    penalty_temperature | 32.8      |\n",
      "|    policy_loss         | 2.35e+09  |\n",
      "|    policy_mean_loss    | 2.35e+09  |\n",
      "|    policy_std_loss     | 44.1      |\n",
      "|    std                 | 2.29e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 2.61e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 79.2      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 456       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1681      |\n",
      "|    total_timesteps     | 113176    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.68e+17  |\n",
      "|    alpha_mean          | 11.9      |\n",
      "|    alpha_mean_loss     | -1.72e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.019    |\n",
      "|    critic_loss         | 4.57e+33  |\n",
      "|    dual_loss           | 2.68e+17  |\n",
      "|    kl_loss             | 1.72e+10  |\n",
      "|    kl_mean_loss        | 1.72e+10  |\n",
      "|    kl_std_loss         | 0.0191    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 113022    |\n",
      "|    penalty_temperature | 32.9      |\n",
      "|    policy_loss         | 2.14e+09  |\n",
      "|    policy_mean_loss    | 2.14e+09  |\n",
      "|    policy_std_loss     | 44.2      |\n",
      "|    std                 | 2.35e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 2.68e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 77.7      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 460       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1685      |\n",
      "|    total_timesteps     | 113444    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.76e+17  |\n",
      "|    alpha_mean          | 12        |\n",
      "|    alpha_mean_loss     | -2.36e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.019    |\n",
      "|    critic_loss         | 4.91e+33  |\n",
      "|    dual_loss           | 2.76e+17  |\n",
      "|    kl_loss             | 2.36e+10  |\n",
      "|    kl_mean_loss        | 2.36e+10  |\n",
      "|    kl_std_loss         | 0.019     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 113301    |\n",
      "|    penalty_temperature | 33        |\n",
      "|    policy_loss         | 2.94e+09  |\n",
      "|    policy_mean_loss    | 2.94e+09  |\n",
      "|    policy_std_loss     | 44.3      |\n",
      "|    std                 | 2.43e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 2.76e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 77.8      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 464       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1690      |\n",
      "|    total_timesteps     | 113741    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.87e+17  |\n",
      "|    alpha_mean          | 12        |\n",
      "|    alpha_mean_loss     | -1.43e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0193   |\n",
      "|    critic_loss         | 5.27e+33  |\n",
      "|    dual_loss           | 2.87e+17  |\n",
      "|    kl_loss             | 1.43e+10  |\n",
      "|    kl_mean_loss        | 1.43e+10  |\n",
      "|    kl_std_loss         | 0.0194    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 113611    |\n",
      "|    penalty_temperature | 33.1      |\n",
      "|    policy_loss         | 1.77e+09  |\n",
      "|    policy_mean_loss    | 1.77e+09  |\n",
      "|    policy_std_loss     | 44.3      |\n",
      "|    std                 | 2.53e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 2.87e+17  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 79.4     |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 468      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 1694     |\n",
      "|    total_timesteps     | 114138   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.95e+17 |\n",
      "|    alpha_mean          | 12       |\n",
      "|    alpha_mean_loss     | -2.1e+10 |\n",
      "|    alpha_std           | 14.5     |\n",
      "|    alpha_std_loss      | -0.0188  |\n",
      "|    critic_loss         | 5.54e+33 |\n",
      "|    dual_loss           | 2.95e+17 |\n",
      "|    kl_loss             | 2.1e+10  |\n",
      "|    kl_mean_loss        | 2.1e+10  |\n",
      "|    kl_std_loss         | 0.0189   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 113870   |\n",
      "|    penalty_temperature | 33.1     |\n",
      "|    policy_loss         | 2.6e+09  |\n",
      "|    policy_mean_loss    | 2.6e+09  |\n",
      "|    policy_std_loss     | 44.4     |\n",
      "|    std                 | 2.6e+06  |\n",
      "|    temperature         | 6.59     |\n",
      "|    temperature_loss    | 2.95e+17 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 81.2      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 472       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1701      |\n",
      "|    total_timesteps     | 114543    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.11e+17  |\n",
      "|    alpha_mean          | 12.1      |\n",
      "|    alpha_mean_loss     | -2.05e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0187   |\n",
      "|    critic_loss         | 6.09e+33  |\n",
      "|    dual_loss           | 3.11e+17  |\n",
      "|    kl_loss             | 2.05e+10  |\n",
      "|    kl_mean_loss        | 2.05e+10  |\n",
      "|    kl_std_loss         | 0.0187    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 114343    |\n",
      "|    penalty_temperature | 33.3      |\n",
      "|    policy_loss         | 2.53e+09  |\n",
      "|    policy_mean_loss    | 2.53e+09  |\n",
      "|    policy_std_loss     | 44.5      |\n",
      "|    std                 | 2.75e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 3.11e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 79.5      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 476       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1706      |\n",
      "|    total_timesteps     | 114776    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.23e+17  |\n",
      "|    alpha_mean          | 12.1      |\n",
      "|    alpha_mean_loss     | -1.96e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0192   |\n",
      "|    critic_loss         | 6.52e+33  |\n",
      "|    dual_loss           | 3.23e+17  |\n",
      "|    kl_loss             | 1.96e+10  |\n",
      "|    kl_mean_loss        | 1.96e+10  |\n",
      "|    kl_std_loss         | 0.0192    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 114661    |\n",
      "|    penalty_temperature | 33.4      |\n",
      "|    policy_loss         | 2.41e+09  |\n",
      "|    policy_mean_loss    | 2.41e+09  |\n",
      "|    policy_std_loss     | 44.6      |\n",
      "|    std                 | 2.85e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 3.23e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 79.1      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 480       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1709      |\n",
      "|    total_timesteps     | 115018    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.3e+17   |\n",
      "|    alpha_mean          | 12.2      |\n",
      "|    alpha_mean_loss     | -1.72e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0182   |\n",
      "|    critic_loss         | 6.7e+33   |\n",
      "|    dual_loss           | 3.3e+17   |\n",
      "|    kl_loss             | 1.72e+10  |\n",
      "|    kl_mean_loss        | 1.72e+10  |\n",
      "|    kl_std_loss         | 0.0183    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 114892    |\n",
      "|    penalty_temperature | 33.4      |\n",
      "|    policy_loss         | 2.11e+09  |\n",
      "|    policy_mean_loss    | 2.11e+09  |\n",
      "|    policy_std_loss     | 44.6      |\n",
      "|    std                 | 2.93e+06  |\n",
      "|    temperature         | 6.59      |\n",
      "|    temperature_loss    | 3.3e+17   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 79.1      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 484       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1715      |\n",
      "|    total_timesteps     | 115428    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.47e+17  |\n",
      "|    alpha_mean          | 12.2      |\n",
      "|    alpha_mean_loss     | -2.06e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0188   |\n",
      "|    critic_loss         | 7.44e+33  |\n",
      "|    dual_loss           | 3.47e+17  |\n",
      "|    kl_loss             | 2.06e+10  |\n",
      "|    kl_mean_loss        | 2.06e+10  |\n",
      "|    kl_std_loss         | 0.0189    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 115290    |\n",
      "|    penalty_temperature | 33.5      |\n",
      "|    policy_loss         | 2.51e+09  |\n",
      "|    policy_mean_loss    | 2.51e+09  |\n",
      "|    policy_std_loss     | 44.7      |\n",
      "|    std                 | 3.08e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 3.47e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 78.4      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 488       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1719      |\n",
      "|    total_timesteps     | 115637    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.54e+17  |\n",
      "|    alpha_mean          | 12.2      |\n",
      "|    alpha_mean_loss     | -1.53e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0184   |\n",
      "|    critic_loss         | 7.85e+33  |\n",
      "|    dual_loss           | 3.54e+17  |\n",
      "|    kl_loss             | 1.53e+10  |\n",
      "|    kl_mean_loss        | 1.53e+10  |\n",
      "|    kl_std_loss         | 0.0184    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 115517    |\n",
      "|    penalty_temperature | 33.6      |\n",
      "|    policy_loss         | 1.86e+09  |\n",
      "|    policy_mean_loss    | 1.86e+09  |\n",
      "|    policy_std_loss     | 44.8      |\n",
      "|    std                 | 3.15e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 3.54e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 78        |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 492       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1722      |\n",
      "|    total_timesteps     | 115859    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.64e+17  |\n",
      "|    alpha_mean          | 12.3      |\n",
      "|    alpha_mean_loss     | -2.55e+10 |\n",
      "|    alpha_std           | 14.5      |\n",
      "|    alpha_std_loss      | -0.0182   |\n",
      "|    critic_loss         | 8.2e+33   |\n",
      "|    dual_loss           | 3.64e+17  |\n",
      "|    kl_loss             | 2.55e+10  |\n",
      "|    kl_mean_loss        | 2.55e+10  |\n",
      "|    kl_std_loss         | 0.0182    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 115752    |\n",
      "|    penalty_temperature | 33.7      |\n",
      "|    policy_loss         | 3.1e+09   |\n",
      "|    policy_mean_loss    | 3.1e+09   |\n",
      "|    policy_std_loss     | 44.8      |\n",
      "|    std                 | 3.24e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 3.64e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 78.2      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 496       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1726      |\n",
      "|    total_timesteps     | 116123    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.76e+17  |\n",
      "|    alpha_mean          | 12.3      |\n",
      "|    alpha_mean_loss     | -2.58e+10 |\n",
      "|    alpha_std           | 14.6      |\n",
      "|    alpha_std_loss      | -0.0186   |\n",
      "|    critic_loss         | 8.66e+33  |\n",
      "|    dual_loss           | 3.76e+17  |\n",
      "|    kl_loss             | 2.58e+10  |\n",
      "|    kl_mean_loss        | 2.58e+10  |\n",
      "|    kl_std_loss         | 0.0187    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 116007    |\n",
      "|    penalty_temperature | 33.7      |\n",
      "|    policy_loss         | 3.12e+09  |\n",
      "|    policy_mean_loss    | 3.12e+09  |\n",
      "|    policy_std_loss     | 44.9      |\n",
      "|    std                 | 3.34e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 3.76e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 78.1      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 500       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1730      |\n",
      "|    total_timesteps     | 116397    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.85e+17  |\n",
      "|    alpha_mean          | 12.3      |\n",
      "|    alpha_mean_loss     | -2.28e+10 |\n",
      "|    alpha_std           | 14.6      |\n",
      "|    alpha_std_loss      | -0.0178   |\n",
      "|    critic_loss         | 9.11e+33  |\n",
      "|    dual_loss           | 3.85e+17  |\n",
      "|    kl_loss             | 2.28e+10  |\n",
      "|    kl_mean_loss        | 2.28e+10  |\n",
      "|    kl_std_loss         | 0.0179    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 116256    |\n",
      "|    penalty_temperature | 33.8      |\n",
      "|    policy_loss         | 2.75e+09  |\n",
      "|    policy_mean_loss    | 2.75e+09  |\n",
      "|    policy_std_loss     | 44.9      |\n",
      "|    std                 | 3.44e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 3.85e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 77.8      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 504       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1735      |\n",
      "|    total_timesteps     | 116742    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.01e+17  |\n",
      "|    alpha_mean          | 12.4      |\n",
      "|    alpha_mean_loss     | -2.18e+10 |\n",
      "|    alpha_std           | 14.6      |\n",
      "|    alpha_std_loss      | -0.0186   |\n",
      "|    critic_loss         | 9.77e+33  |\n",
      "|    dual_loss           | 4.01e+17  |\n",
      "|    kl_loss             | 2.18e+10  |\n",
      "|    kl_mean_loss        | 2.18e+10  |\n",
      "|    kl_std_loss         | 0.0187    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 116627    |\n",
      "|    penalty_temperature | 33.9      |\n",
      "|    policy_loss         | 2.63e+09  |\n",
      "|    policy_mean_loss    | 2.63e+09  |\n",
      "|    policy_std_loss     | 45        |\n",
      "|    std                 | 3.59e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 4.01e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 76.5      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 508       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1739      |\n",
      "|    total_timesteps     | 116974    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.11e+17  |\n",
      "|    alpha_mean          | 12.4      |\n",
      "|    alpha_mean_loss     | -2.34e+10 |\n",
      "|    alpha_std           | 14.6      |\n",
      "|    alpha_std_loss      | -0.018    |\n",
      "|    critic_loss         | 1.04e+34  |\n",
      "|    dual_loss           | 4.11e+17  |\n",
      "|    kl_loss             | 2.34e+10  |\n",
      "|    kl_mean_loss        | 2.34e+10  |\n",
      "|    kl_std_loss         | 0.0181    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 116849    |\n",
      "|    penalty_temperature | 34        |\n",
      "|    policy_loss         | 2.81e+09  |\n",
      "|    policy_mean_loss    | 2.81e+09  |\n",
      "|    policy_std_loss     | 45.1      |\n",
      "|    std                 | 3.68e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 4.11e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 76.5      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 512       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1742      |\n",
      "|    total_timesteps     | 117226    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.23e+17  |\n",
      "|    alpha_mean          | 12.4      |\n",
      "|    alpha_mean_loss     | -1.55e+10 |\n",
      "|    alpha_std           | 14.6      |\n",
      "|    alpha_std_loss      | -0.0179   |\n",
      "|    critic_loss         | 1.09e+34  |\n",
      "|    dual_loss           | 4.23e+17  |\n",
      "|    kl_loss             | 1.55e+10  |\n",
      "|    kl_mean_loss        | 1.55e+10  |\n",
      "|    kl_std_loss         | 0.018     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 117073    |\n",
      "|    penalty_temperature | 34        |\n",
      "|    policy_loss         | 1.86e+09  |\n",
      "|    policy_mean_loss    | 1.86e+09  |\n",
      "|    policy_std_loss     | 45.1      |\n",
      "|    std                 | 3.78e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 4.23e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 76.4      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 516       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1746      |\n",
      "|    total_timesteps     | 117469    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.36e+17  |\n",
      "|    alpha_mean          | 12.4      |\n",
      "|    alpha_mean_loss     | -3.25e+10 |\n",
      "|    alpha_std           | 14.6      |\n",
      "|    alpha_std_loss      | -0.0185   |\n",
      "|    critic_loss         | 1.15e+34  |\n",
      "|    dual_loss           | 4.36e+17  |\n",
      "|    kl_loss             | 3.25e+10  |\n",
      "|    kl_mean_loss        | 3.25e+10  |\n",
      "|    kl_std_loss         | 0.0186    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 117353    |\n",
      "|    penalty_temperature | 34.1      |\n",
      "|    policy_loss         | 3.88e+09  |\n",
      "|    policy_mean_loss    | 3.88e+09  |\n",
      "|    policy_std_loss     | 45.2      |\n",
      "|    std                 | 3.9e+06   |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 4.36e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 76.3      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 520       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1749      |\n",
      "|    total_timesteps     | 117685    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.49e+17  |\n",
      "|    alpha_mean          | 12.5      |\n",
      "|    alpha_mean_loss     | -2.72e+10 |\n",
      "|    alpha_std           | 14.6      |\n",
      "|    alpha_std_loss      | -0.0191   |\n",
      "|    critic_loss         | 1.23e+34  |\n",
      "|    dual_loss           | 4.49e+17  |\n",
      "|    kl_loss             | 2.72e+10  |\n",
      "|    kl_mean_loss        | 2.72e+10  |\n",
      "|    kl_std_loss         | 0.0192    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 117562    |\n",
      "|    penalty_temperature | 34.1      |\n",
      "|    policy_loss         | 3.25e+09  |\n",
      "|    policy_mean_loss    | 3.25e+09  |\n",
      "|    policy_std_loss     | 45.2      |\n",
      "|    std                 | 3.99e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 4.49e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 77.2      |\n",
      "|    ep_rew_mean         | -115      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 524       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1754      |\n",
      "|    total_timesteps     | 118002    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.6e+17   |\n",
      "|    alpha_mean          | 12.5      |\n",
      "|    alpha_mean_loss     | -3.08e+10 |\n",
      "|    alpha_std           | 14.6      |\n",
      "|    alpha_std_loss      | -0.0182   |\n",
      "|    critic_loss         | 1.29e+34  |\n",
      "|    dual_loss           | 4.6e+17   |\n",
      "|    kl_loss             | 3.08e+10  |\n",
      "|    kl_mean_loss        | 3.08e+10  |\n",
      "|    kl_std_loss         | 0.0183    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 117872    |\n",
      "|    penalty_temperature | 34.2      |\n",
      "|    policy_loss         | 3.66e+09  |\n",
      "|    policy_mean_loss    | 3.66e+09  |\n",
      "|    policy_std_loss     | 45.3      |\n",
      "|    std                 | 4.13e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 4.6e+17   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 72.3      |\n",
      "|    ep_rew_mean         | -115      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 528       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1757      |\n",
      "|    total_timesteps     | 118238    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.74e+17  |\n",
      "|    alpha_mean          | 12.5      |\n",
      "|    alpha_mean_loss     | -4.84e+10 |\n",
      "|    alpha_std           | 14.6      |\n",
      "|    alpha_std_loss      | -0.0185   |\n",
      "|    critic_loss         | 1.35e+34  |\n",
      "|    dual_loss           | 4.74e+17  |\n",
      "|    kl_loss             | 4.84e+10  |\n",
      "|    kl_mean_loss        | 4.84e+10  |\n",
      "|    kl_std_loss         | 0.0186    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 118093    |\n",
      "|    penalty_temperature | 34.3      |\n",
      "|    policy_loss         | 5.74e+09  |\n",
      "|    policy_mean_loss    | 5.74e+09  |\n",
      "|    policy_std_loss     | 45.4      |\n",
      "|    std                 | 4.24e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 4.74e+17  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 69.2     |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 532      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 1762     |\n",
      "|    total_timesteps     | 118516   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.87e+17 |\n",
      "|    alpha_mean          | 12.6     |\n",
      "|    alpha_mean_loss     | -2.8e+10 |\n",
      "|    alpha_std           | 14.6     |\n",
      "|    alpha_std_loss      | -0.0177  |\n",
      "|    critic_loss         | 1.45e+34 |\n",
      "|    dual_loss           | 4.87e+17 |\n",
      "|    kl_loss             | 2.8e+10  |\n",
      "|    kl_mean_loss        | 2.8e+10  |\n",
      "|    kl_std_loss         | 0.0177   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 118395   |\n",
      "|    penalty_temperature | 34.3     |\n",
      "|    policy_loss         | 3.32e+09 |\n",
      "|    policy_mean_loss    | 3.32e+09 |\n",
      "|    policy_std_loss     | 45.4     |\n",
      "|    std                 | 4.38e+06 |\n",
      "|    temperature         | 6.6      |\n",
      "|    temperature_loss    | 4.87e+17 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 72        |\n",
      "|    ep_rew_mean         | -115      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 536       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1767      |\n",
      "|    total_timesteps     | 119049    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 5.06e+17  |\n",
      "|    alpha_mean          | 12.6      |\n",
      "|    alpha_mean_loss     | -2.74e+10 |\n",
      "|    alpha_std           | 14.6      |\n",
      "|    alpha_std_loss      | -0.018    |\n",
      "|    critic_loss         | 1.54e+34  |\n",
      "|    dual_loss           | 5.06e+17  |\n",
      "|    kl_loss             | 2.74e+10  |\n",
      "|    kl_mean_loss        | 2.74e+10  |\n",
      "|    kl_std_loss         | 0.0181    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 118735    |\n",
      "|    penalty_temperature | 34.4      |\n",
      "|    policy_loss         | 3.23e+09  |\n",
      "|    policy_mean_loss    | 3.23e+09  |\n",
      "|    policy_std_loss     | 45.5      |\n",
      "|    std                 | 4.56e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 5.06e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 75.3      |\n",
      "|    ep_rew_mean         | -115      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 540       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1777      |\n",
      "|    total_timesteps     | 119652    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 5.43e+17  |\n",
      "|    alpha_mean          | 12.7      |\n",
      "|    alpha_mean_loss     | -3.16e+10 |\n",
      "|    alpha_std           | 14.6      |\n",
      "|    alpha_std_loss      | -0.0179   |\n",
      "|    critic_loss         | 1.77e+34  |\n",
      "|    dual_loss           | 5.43e+17  |\n",
      "|    kl_loss             | 3.16e+10  |\n",
      "|    kl_mean_loss        | 3.16e+10  |\n",
      "|    kl_std_loss         | 0.0179    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 119456    |\n",
      "|    penalty_temperature | 34.6      |\n",
      "|    policy_loss         | 3.7e+09   |\n",
      "|    policy_mean_loss    | 3.7e+09   |\n",
      "|    policy_std_loss     | 45.6      |\n",
      "|    std                 | 4.94e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 5.43e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 82.2      |\n",
      "|    ep_rew_mean         | -115      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 544       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1791      |\n",
      "|    total_timesteps     | 120624    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 6.01e+17  |\n",
      "|    alpha_mean          | 12.8      |\n",
      "|    alpha_mean_loss     | -4.58e+10 |\n",
      "|    alpha_std           | 14.7      |\n",
      "|    alpha_std_loss      | -0.0174   |\n",
      "|    critic_loss         | 2.15e+34  |\n",
      "|    dual_loss           | 6.01e+17  |\n",
      "|    kl_loss             | 4.58e+10  |\n",
      "|    kl_mean_loss        | 4.58e+10  |\n",
      "|    kl_std_loss         | 0.0175    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 120380    |\n",
      "|    penalty_temperature | 34.9      |\n",
      "|    policy_loss         | 5.33e+09  |\n",
      "|    policy_mean_loss    | 5.33e+09  |\n",
      "|    policy_std_loss     | 45.8      |\n",
      "|    std                 | 5.48e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 6.01e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 82.7      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 548       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1798      |\n",
      "|    total_timesteps     | 120958    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 6.33e+17  |\n",
      "|    alpha_mean          | 12.9      |\n",
      "|    alpha_mean_loss     | -4.84e+10 |\n",
      "|    alpha_std           | 14.7      |\n",
      "|    alpha_std_loss      | -0.0176   |\n",
      "|    critic_loss         | 2.36e+34  |\n",
      "|    dual_loss           | 6.33e+17  |\n",
      "|    kl_loss             | 4.84e+10  |\n",
      "|    kl_mean_loss        | 4.84e+10  |\n",
      "|    kl_std_loss         | 0.0177    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 120824    |\n",
      "|    penalty_temperature | 35        |\n",
      "|    policy_loss         | 5.6e+09   |\n",
      "|    policy_mean_loss    | 5.6e+09   |\n",
      "|    policy_std_loss     | 45.9      |\n",
      "|    std                 | 5.76e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 6.33e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 85        |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 552       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1804      |\n",
      "|    total_timesteps     | 121410    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 6.59e+17  |\n",
      "|    alpha_mean          | 12.9      |\n",
      "|    alpha_mean_loss     | -5.06e+10 |\n",
      "|    alpha_std           | 14.7      |\n",
      "|    alpha_std_loss      | -0.0177   |\n",
      "|    critic_loss         | 2.55e+34  |\n",
      "|    dual_loss           | 6.59e+17  |\n",
      "|    kl_loss             | 5.06e+10  |\n",
      "|    kl_mean_loss        | 5.06e+10  |\n",
      "|    kl_std_loss         | 0.0177    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 121271    |\n",
      "|    penalty_temperature | 35.1      |\n",
      "|    policy_loss         | 5.83e+09  |\n",
      "|    policy_mean_loss    | 5.83e+09  |\n",
      "|    policy_std_loss     | 46        |\n",
      "|    std                 | 6.05e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 6.59e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 87.8      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 556       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1812      |\n",
      "|    total_timesteps     | 121954    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 7e+17     |\n",
      "|    alpha_mean          | 13        |\n",
      "|    alpha_mean_loss     | -3.68e+10 |\n",
      "|    alpha_std           | 14.8      |\n",
      "|    alpha_std_loss      | -0.0174   |\n",
      "|    critic_loss         | 2.84e+34  |\n",
      "|    dual_loss           | 7e+17     |\n",
      "|    kl_loss             | 3.68e+10  |\n",
      "|    kl_mean_loss        | 3.68e+10  |\n",
      "|    kl_std_loss         | 0.0175    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 121762    |\n",
      "|    penalty_temperature | 35.3      |\n",
      "|    policy_loss         | 4.21e+09  |\n",
      "|    policy_mean_loss    | 4.21e+09  |\n",
      "|    policy_std_loss     | 46.2      |\n",
      "|    std                 | 6.38e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 7e+17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89        |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 560       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1818      |\n",
      "|    total_timesteps     | 122341    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 7.31e+17  |\n",
      "|    alpha_mean          | 13        |\n",
      "|    alpha_mean_loss     | -4.14e+10 |\n",
      "|    alpha_std           | 14.8      |\n",
      "|    alpha_std_loss      | -0.0171   |\n",
      "|    critic_loss         | 3.12e+34  |\n",
      "|    dual_loss           | 7.31e+17  |\n",
      "|    kl_loss             | 4.14e+10  |\n",
      "|    kl_mean_loss        | 4.14e+10  |\n",
      "|    kl_std_loss         | 0.0172    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 122217    |\n",
      "|    penalty_temperature | 35.4      |\n",
      "|    policy_loss         | 4.73e+09  |\n",
      "|    policy_mean_loss    | 4.73e+09  |\n",
      "|    policy_std_loss     | 46.3      |\n",
      "|    std                 | 6.7e+06   |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 7.31e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 91        |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 564       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1823      |\n",
      "|    total_timesteps     | 122845    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 7.57e+17  |\n",
      "|    alpha_mean          | 13.1      |\n",
      "|    alpha_mean_loss     | -4.58e+10 |\n",
      "|    alpha_std           | 14.8      |\n",
      "|    alpha_std_loss      | -0.0171   |\n",
      "|    critic_loss         | 3.32e+34  |\n",
      "|    dual_loss           | 7.57e+17  |\n",
      "|    kl_loss             | 4.58e+10  |\n",
      "|    kl_mean_loss        | 4.58e+10  |\n",
      "|    kl_std_loss         | 0.0172    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 122516    |\n",
      "|    penalty_temperature | 35.5      |\n",
      "|    policy_loss         | 5.21e+09  |\n",
      "|    policy_mean_loss    | 5.21e+09  |\n",
      "|    policy_std_loss     | 46.3      |\n",
      "|    std                 | 6.93e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 7.57e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 90.4      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 568       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1830      |\n",
      "|    total_timesteps     | 123174    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 8.01e+17  |\n",
      "|    alpha_mean          | 13.1      |\n",
      "|    alpha_mean_loss     | -5.31e+10 |\n",
      "|    alpha_std           | 14.8      |\n",
      "|    alpha_std_loss      | -0.0174   |\n",
      "|    critic_loss         | 3.7e+34   |\n",
      "|    dual_loss           | 8.01e+17  |\n",
      "|    kl_loss             | 5.31e+10  |\n",
      "|    kl_mean_loss        | 5.31e+10  |\n",
      "|    kl_std_loss         | 0.0175    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 123028    |\n",
      "|    penalty_temperature | 35.6      |\n",
      "|    policy_loss         | 6.01e+09  |\n",
      "|    policy_mean_loss    | 6.01e+09  |\n",
      "|    policy_std_loss     | 46.4      |\n",
      "|    std                 | 7.32e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 8.01e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 88.9      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 572       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1834      |\n",
      "|    total_timesteps     | 123432    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 8.24e+17  |\n",
      "|    alpha_mean          | 13.2      |\n",
      "|    alpha_mean_loss     | -3.53e+10 |\n",
      "|    alpha_std           | 14.8      |\n",
      "|    alpha_std_loss      | -0.017    |\n",
      "|    critic_loss         | 3.89e+34  |\n",
      "|    dual_loss           | 8.24e+17  |\n",
      "|    kl_loss             | 3.53e+10  |\n",
      "|    kl_mean_loss        | 3.53e+10  |\n",
      "|    kl_std_loss         | 0.017     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 123302    |\n",
      "|    penalty_temperature | 35.7      |\n",
      "|    policy_loss         | 4e+09     |\n",
      "|    policy_mean_loss    | 4e+09     |\n",
      "|    policy_std_loss     | 46.5      |\n",
      "|    std                 | 7.54e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 8.24e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 90.2      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 576       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1839      |\n",
      "|    total_timesteps     | 123797    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 8.52e+17  |\n",
      "|    alpha_mean          | 13.2      |\n",
      "|    alpha_mean_loss     | -5.51e+10 |\n",
      "|    alpha_std           | 14.9      |\n",
      "|    alpha_std_loss      | -0.0173   |\n",
      "|    critic_loss         | 4.16e+34  |\n",
      "|    dual_loss           | 8.52e+17  |\n",
      "|    kl_loss             | 5.51e+10  |\n",
      "|    kl_mean_loss        | 5.51e+10  |\n",
      "|    kl_std_loss         | 0.0173    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 123645    |\n",
      "|    penalty_temperature | 35.8      |\n",
      "|    policy_loss         | 6.21e+09  |\n",
      "|    policy_mean_loss    | 6.21e+09  |\n",
      "|    policy_std_loss     | 46.6      |\n",
      "|    std                 | 7.83e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 8.52e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 90.9      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 580       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1844      |\n",
      "|    total_timesteps     | 124110    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 8.84e+17  |\n",
      "|    alpha_mean          | 13.3      |\n",
      "|    alpha_mean_loss     | -4.29e+10 |\n",
      "|    alpha_std           | 14.8      |\n",
      "|    alpha_std_loss      | -0.0172   |\n",
      "|    critic_loss         | 4.47e+34  |\n",
      "|    dual_loss           | 8.84e+17  |\n",
      "|    kl_loss             | 4.29e+10  |\n",
      "|    kl_mean_loss        | 4.29e+10  |\n",
      "|    kl_std_loss         | 0.0172    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 123969    |\n",
      "|    penalty_temperature | 35.9      |\n",
      "|    policy_loss         | 4.82e+09  |\n",
      "|    policy_mean_loss    | 4.82e+09  |\n",
      "|    policy_std_loss     | 46.6      |\n",
      "|    std                 | 8.11e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 8.84e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 90.7      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 584       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1850      |\n",
      "|    total_timesteps     | 124494    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 9.14e+17  |\n",
      "|    alpha_mean          | 13.3      |\n",
      "|    alpha_mean_loss     | -6.33e+10 |\n",
      "|    alpha_std           | 14.9      |\n",
      "|    alpha_std_loss      | -0.017    |\n",
      "|    critic_loss         | 4.75e+34  |\n",
      "|    dual_loss           | 9.14e+17  |\n",
      "|    kl_loss             | 6.33e+10  |\n",
      "|    kl_mean_loss        | 6.33e+10  |\n",
      "|    kl_std_loss         | 0.0171    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 124330    |\n",
      "|    penalty_temperature | 36        |\n",
      "|    policy_loss         | 7.09e+09  |\n",
      "|    policy_mean_loss    | 7.09e+09  |\n",
      "|    policy_std_loss     | 46.7      |\n",
      "|    std                 | 8.42e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 9.14e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 91.9      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 588       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1855      |\n",
      "|    total_timesteps     | 124827    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 9.49e+17  |\n",
      "|    alpha_mean          | 13.3      |\n",
      "|    alpha_mean_loss     | -9.39e+10 |\n",
      "|    alpha_std           | 14.9      |\n",
      "|    alpha_std_loss      | -0.0169   |\n",
      "|    critic_loss         | 5.1e+34   |\n",
      "|    dual_loss           | 9.49e+17  |\n",
      "|    kl_loss             | 9.39e+10  |\n",
      "|    kl_mean_loss        | 9.39e+10  |\n",
      "|    kl_std_loss         | 0.0169    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 124655    |\n",
      "|    penalty_temperature | 36.1      |\n",
      "|    policy_loss         | 1.05e+10  |\n",
      "|    policy_mean_loss    | 1.05e+10  |\n",
      "|    policy_std_loss     | 46.8      |\n",
      "|    std                 | 8.73e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 9.49e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 93.1      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 592       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1860      |\n",
      "|    total_timesteps     | 125167    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 9.87e+17  |\n",
      "|    alpha_mean          | 13.4      |\n",
      "|    alpha_mean_loss     | -7.06e+10 |\n",
      "|    alpha_std           | 14.9      |\n",
      "|    alpha_std_loss      | -0.017    |\n",
      "|    critic_loss         | 5.51e+34  |\n",
      "|    dual_loss           | 9.87e+17  |\n",
      "|    kl_loss             | 7.06e+10  |\n",
      "|    kl_mean_loss        | 7.06e+10  |\n",
      "|    kl_std_loss         | 0.0171    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 125041    |\n",
      "|    penalty_temperature | 36.2      |\n",
      "|    policy_loss         | 7.85e+09  |\n",
      "|    policy_mean_loss    | 7.85e+09  |\n",
      "|    policy_std_loss     | 46.9      |\n",
      "|    std                 | 9.1e+06   |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 9.87e+17  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 93.8      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 596       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1865      |\n",
      "|    total_timesteps     | 125498    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.02e+18  |\n",
      "|    alpha_mean          | 13.4      |\n",
      "|    alpha_mean_loss     | -6.02e+10 |\n",
      "|    alpha_std           | 14.9      |\n",
      "|    alpha_std_loss      | -0.0167   |\n",
      "|    critic_loss         | 5.86e+34  |\n",
      "|    dual_loss           | 1.02e+18  |\n",
      "|    kl_loss             | 6.02e+10  |\n",
      "|    kl_mean_loss        | 6.02e+10  |\n",
      "|    kl_std_loss         | 0.0168    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 125328    |\n",
      "|    penalty_temperature | 36.3      |\n",
      "|    policy_loss         | 6.68e+09  |\n",
      "|    policy_mean_loss    | 6.68e+09  |\n",
      "|    policy_std_loss     | 46.9      |\n",
      "|    std                 | 9.37e+06  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 1.02e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 93.8      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 600       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1869      |\n",
      "|    total_timesteps     | 125780    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.05e+18  |\n",
      "|    alpha_mean          | 13.5      |\n",
      "|    alpha_mean_loss     | -4.23e+10 |\n",
      "|    alpha_std           | 14.9      |\n",
      "|    alpha_std_loss      | -0.0172   |\n",
      "|    critic_loss         | 6.24e+34  |\n",
      "|    dual_loss           | 1.05e+18  |\n",
      "|    kl_loss             | 4.23e+10  |\n",
      "|    kl_mean_loss        | 4.23e+10  |\n",
      "|    kl_std_loss         | 0.0173    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 125636    |\n",
      "|    penalty_temperature | 36.4      |\n",
      "|    policy_loss         | 4.68e+09  |\n",
      "|    policy_mean_loss    | 4.68e+09  |\n",
      "|    policy_std_loss     | 47        |\n",
      "|    std                 | 9.68e+06  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 1.05e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 93.5      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 604       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1874      |\n",
      "|    total_timesteps     | 126097    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.09e+18  |\n",
      "|    alpha_mean          | 13.5      |\n",
      "|    alpha_mean_loss     | -4.91e+10 |\n",
      "|    alpha_std           | 14.9      |\n",
      "|    alpha_std_loss      | -0.0167   |\n",
      "|    critic_loss         | 6.69e+34  |\n",
      "|    dual_loss           | 1.09e+18  |\n",
      "|    kl_loss             | 4.91e+10  |\n",
      "|    kl_mean_loss        | 4.91e+10  |\n",
      "|    kl_std_loss         | 0.0167    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 125976    |\n",
      "|    penalty_temperature | 36.5      |\n",
      "|    policy_loss         | 5.42e+09  |\n",
      "|    policy_mean_loss    | 5.42e+09  |\n",
      "|    policy_std_loss     | 47.1      |\n",
      "|    std                 | 1e+07     |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 1.09e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 96.5      |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 608       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1878      |\n",
      "|    total_timesteps     | 126622    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.12e+18  |\n",
      "|    alpha_mean          | 13.5      |\n",
      "|    alpha_mean_loss     | -4.98e+10 |\n",
      "|    alpha_std           | 14.9      |\n",
      "|    alpha_std_loss      | -0.0169   |\n",
      "|    critic_loss         | 7.13e+34  |\n",
      "|    dual_loss           | 1.12e+18  |\n",
      "|    kl_loss             | 4.98e+10  |\n",
      "|    kl_mean_loss        | 4.98e+10  |\n",
      "|    kl_std_loss         | 0.0169    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 126259    |\n",
      "|    penalty_temperature | 36.6      |\n",
      "|    policy_loss         | 5.48e+09  |\n",
      "|    policy_mean_loss    | 5.48e+09  |\n",
      "|    policy_std_loss     | 47.1      |\n",
      "|    std                 | 1.03e+07  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 1.12e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 96.3      |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 612       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1886      |\n",
      "|    total_timesteps     | 126859    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.18e+18  |\n",
      "|    alpha_mean          | 13.6      |\n",
      "|    alpha_mean_loss     | -4.87e+10 |\n",
      "|    alpha_std           | 15        |\n",
      "|    alpha_std_loss      | -0.0166   |\n",
      "|    critic_loss         | 7.84e+34  |\n",
      "|    dual_loss           | 1.18e+18  |\n",
      "|    kl_loss             | 4.87e+10  |\n",
      "|    kl_mean_loss        | 4.87e+10  |\n",
      "|    kl_std_loss         | 0.0167    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 126741    |\n",
      "|    penalty_temperature | 36.7      |\n",
      "|    policy_loss         | 5.34e+09  |\n",
      "|    policy_mean_loss    | 5.34e+09  |\n",
      "|    policy_std_loss     | 47.2      |\n",
      "|    std                 | 1.09e+07  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 1.18e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 99.2      |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 616       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1890      |\n",
      "|    total_timesteps     | 127390    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.21e+18  |\n",
      "|    alpha_mean          | 13.6      |\n",
      "|    alpha_mean_loss     | -6.83e+10 |\n",
      "|    alpha_std           | 15        |\n",
      "|    alpha_std_loss      | -0.0161   |\n",
      "|    critic_loss         | 8.14e+34  |\n",
      "|    dual_loss           | 1.21e+18  |\n",
      "|    kl_loss             | 6.83e+10  |\n",
      "|    kl_mean_loss        | 6.83e+10  |\n",
      "|    kl_std_loss         | 0.0161    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 127018    |\n",
      "|    penalty_temperature | 36.8      |\n",
      "|    policy_loss         | 7.47e+09  |\n",
      "|    policy_mean_loss    | 7.47e+09  |\n",
      "|    policy_std_loss     | 47.3      |\n",
      "|    std                 | 1.12e+07  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 1.21e+18  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 102      |\n",
      "|    ep_rew_mean         | -118     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 620      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 1900     |\n",
      "|    total_timesteps     | 127858   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.29e+18 |\n",
      "|    alpha_mean          | 13.7     |\n",
      "|    alpha_mean_loss     | -7.2e+10 |\n",
      "|    alpha_std           | 15.1     |\n",
      "|    alpha_std_loss      | -0.0167  |\n",
      "|    critic_loss         | 9.23e+34 |\n",
      "|    dual_loss           | 1.29e+18 |\n",
      "|    kl_loss             | 7.2e+10  |\n",
      "|    kl_mean_loss        | 7.2e+10  |\n",
      "|    kl_std_loss         | 0.0167   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 127720   |\n",
      "|    penalty_temperature | 37       |\n",
      "|    policy_loss         | 7.83e+09 |\n",
      "|    policy_mean_loss    | 7.83e+09 |\n",
      "|    policy_std_loss     | 47.4     |\n",
      "|    std                 | 1.21e+07 |\n",
      "|    temperature         | 6.61     |\n",
      "|    temperature_loss    | 1.29e+18 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 103       |\n",
      "|    ep_rew_mean         | -119      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 624       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1907      |\n",
      "|    total_timesteps     | 128295    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.36e+18  |\n",
      "|    alpha_mean          | 13.7      |\n",
      "|    alpha_mean_loss     | -6.56e+10 |\n",
      "|    alpha_std           | 15.1      |\n",
      "|    alpha_std_loss      | -0.0165   |\n",
      "|    critic_loss         | 1.02e+35  |\n",
      "|    dual_loss           | 1.36e+18  |\n",
      "|    kl_loss             | 6.56e+10  |\n",
      "|    kl_mean_loss        | 6.56e+10  |\n",
      "|    kl_std_loss         | 0.0166    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 128184    |\n",
      "|    penalty_temperature | 37.1      |\n",
      "|    policy_loss         | 7.1e+09   |\n",
      "|    policy_mean_loss    | 7.1e+09   |\n",
      "|    policy_std_loss     | 47.5      |\n",
      "|    std                 | 1.27e+07  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 1.36e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 103       |\n",
      "|    ep_rew_mean         | -119      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 628       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1911      |\n",
      "|    total_timesteps     | 128547    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.39e+18  |\n",
      "|    alpha_mean          | 13.8      |\n",
      "|    alpha_mean_loss     | -7.61e+10 |\n",
      "|    alpha_std           | 15.1      |\n",
      "|    alpha_std_loss      | -0.0161   |\n",
      "|    critic_loss         | 1.08e+35  |\n",
      "|    dual_loss           | 1.39e+18  |\n",
      "|    kl_loss             | 7.61e+10  |\n",
      "|    kl_mean_loss        | 7.61e+10  |\n",
      "|    kl_std_loss         | 0.0162    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 128426    |\n",
      "|    penalty_temperature | 37.2      |\n",
      "|    policy_loss         | 8.22e+09  |\n",
      "|    policy_mean_loss    | 8.22e+09  |\n",
      "|    policy_std_loss     | 47.5      |\n",
      "|    std                 | 1.3e+07   |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 1.39e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 103       |\n",
      "|    ep_rew_mean         | -119      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 632       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1915      |\n",
      "|    total_timesteps     | 128852    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.44e+18  |\n",
      "|    alpha_mean          | 13.8      |\n",
      "|    alpha_mean_loss     | -7.61e+10 |\n",
      "|    alpha_std           | 15.1      |\n",
      "|    alpha_std_loss      | -0.0163   |\n",
      "|    critic_loss         | 1.13e+35  |\n",
      "|    dual_loss           | 1.44e+18  |\n",
      "|    kl_loss             | 7.61e+10  |\n",
      "|    kl_mean_loss        | 7.61e+10  |\n",
      "|    kl_std_loss         | 0.0163    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 128703    |\n",
      "|    penalty_temperature | 37.3      |\n",
      "|    policy_loss         | 8.21e+09  |\n",
      "|    policy_mean_loss    | 8.21e+09  |\n",
      "|    policy_std_loss     | 47.6      |\n",
      "|    std                 | 1.34e+07  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 1.44e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 102       |\n",
      "|    ep_rew_mean         | -119      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 636       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1921      |\n",
      "|    total_timesteps     | 129245    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.5e+18   |\n",
      "|    alpha_mean          | 13.9      |\n",
      "|    alpha_mean_loss     | -9.85e+10 |\n",
      "|    alpha_std           | 15.1      |\n",
      "|    alpha_std_loss      | -0.0165   |\n",
      "|    critic_loss         | 1.22e+35  |\n",
      "|    dual_loss           | 1.5e+18   |\n",
      "|    kl_loss             | 9.85e+10  |\n",
      "|    kl_mean_loss        | 9.85e+10  |\n",
      "|    kl_std_loss         | 0.0165    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 129107    |\n",
      "|    penalty_temperature | 37.4      |\n",
      "|    policy_loss         | 1.06e+10  |\n",
      "|    policy_mean_loss    | 1.06e+10  |\n",
      "|    policy_std_loss     | 47.7      |\n",
      "|    std                 | 1.39e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.5e+18   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 99.7      |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 640       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1927      |\n",
      "|    total_timesteps     | 129626    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.56e+18  |\n",
      "|    alpha_mean          | 13.9      |\n",
      "|    alpha_mean_loss     | -5.85e+10 |\n",
      "|    alpha_std           | 15.1      |\n",
      "|    alpha_std_loss      | -0.0166   |\n",
      "|    critic_loss         | 1.32e+35  |\n",
      "|    dual_loss           | 1.56e+18  |\n",
      "|    kl_loss             | 5.85e+10  |\n",
      "|    kl_mean_loss        | 5.85e+10  |\n",
      "|    kl_std_loss         | 0.0167    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 129502    |\n",
      "|    penalty_temperature | 37.5      |\n",
      "|    policy_loss         | 6.26e+09  |\n",
      "|    policy_mean_loss    | 6.26e+09  |\n",
      "|    policy_std_loss     | 47.8      |\n",
      "|    std                 | 1.45e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.56e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 93.8      |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 644       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1933      |\n",
      "|    total_timesteps     | 130009    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.63e+18  |\n",
      "|    alpha_mean          | 14        |\n",
      "|    alpha_mean_loss     | -1.12e+11 |\n",
      "|    alpha_std           | 15.2      |\n",
      "|    alpha_std_loss      | -0.0166   |\n",
      "|    critic_loss         | 1.44e+35  |\n",
      "|    dual_loss           | 1.63e+18  |\n",
      "|    kl_loss             | 1.12e+11  |\n",
      "|    kl_mean_loss        | 1.12e+11  |\n",
      "|    kl_std_loss         | 0.0166    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 129906    |\n",
      "|    penalty_temperature | 37.6      |\n",
      "|    policy_loss         | 1.2e+10   |\n",
      "|    policy_mean_loss    | 1.2e+10   |\n",
      "|    policy_std_loss     | 47.9      |\n",
      "|    std                 | 1.51e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.63e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 94        |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 648       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1937      |\n",
      "|    total_timesteps     | 130358    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.68e+18  |\n",
      "|    alpha_mean          | 14        |\n",
      "|    alpha_mean_loss     | -6.98e+10 |\n",
      "|    alpha_std           | 15.2      |\n",
      "|    alpha_std_loss      | -0.0166   |\n",
      "|    critic_loss         | 1.52e+35  |\n",
      "|    dual_loss           | 1.68e+18  |\n",
      "|    kl_loss             | 6.98e+10  |\n",
      "|    kl_mean_loss        | 6.98e+10  |\n",
      "|    kl_std_loss         | 0.0166    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 130215    |\n",
      "|    penalty_temperature | 37.7      |\n",
      "|    policy_loss         | 7.43e+09  |\n",
      "|    policy_mean_loss    | 7.43e+09  |\n",
      "|    policy_std_loss     | 48        |\n",
      "|    std                 | 1.56e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.68e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 94.5      |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 652       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1944      |\n",
      "|    total_timesteps     | 130856    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.75e+18  |\n",
      "|    alpha_mean          | 14.1      |\n",
      "|    alpha_mean_loss     | -9.41e+10 |\n",
      "|    alpha_std           | 15.2      |\n",
      "|    alpha_std_loss      | -0.0164   |\n",
      "|    critic_loss         | 1.66e+35  |\n",
      "|    dual_loss           | 1.75e+18  |\n",
      "|    kl_loss             | 9.41e+10  |\n",
      "|    kl_mean_loss        | 9.41e+10  |\n",
      "|    kl_std_loss         | 0.0164    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 130690    |\n",
      "|    penalty_temperature | 37.9      |\n",
      "|    policy_loss         | 9.96e+09  |\n",
      "|    policy_mean_loss    | 9.96e+09  |\n",
      "|    policy_std_loss     | 48        |\n",
      "|    std                 | 1.64e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.75e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 92        |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 656       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1949      |\n",
      "|    total_timesteps     | 131156    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.81e+18  |\n",
      "|    alpha_mean          | 14.1      |\n",
      "|    alpha_mean_loss     | -6.19e+10 |\n",
      "|    alpha_std           | 15.2      |\n",
      "|    alpha_std_loss      | -0.0156   |\n",
      "|    critic_loss         | 1.78e+35  |\n",
      "|    dual_loss           | 1.81e+18  |\n",
      "|    kl_loss             | 6.19e+10  |\n",
      "|    kl_mean_loss        | 6.19e+10  |\n",
      "|    kl_std_loss         | 0.0156    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 131019    |\n",
      "|    penalty_temperature | 38        |\n",
      "|    policy_loss         | 6.54e+09  |\n",
      "|    policy_mean_loss    | 6.54e+09  |\n",
      "|    policy_std_loss     | 48.1      |\n",
      "|    std                 | 1.69e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.81e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 91.1      |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 660       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1954      |\n",
      "|    total_timesteps     | 131454    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.87e+18  |\n",
      "|    alpha_mean          | 14.1      |\n",
      "|    alpha_mean_loss     | -9.46e+10 |\n",
      "|    alpha_std           | 15.2      |\n",
      "|    alpha_std_loss      | -0.0164   |\n",
      "|    critic_loss         | 1.91e+35  |\n",
      "|    dual_loss           | 1.87e+18  |\n",
      "|    kl_loss             | 9.46e+10  |\n",
      "|    kl_mean_loss        | 9.46e+10  |\n",
      "|    kl_std_loss         | 0.0165    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 131322    |\n",
      "|    penalty_temperature | 38.1      |\n",
      "|    policy_loss         | 9.95e+09  |\n",
      "|    policy_mean_loss    | 9.95e+09  |\n",
      "|    policy_std_loss     | 48.2      |\n",
      "|    std                 | 1.75e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.87e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 90.2      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 664       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1960      |\n",
      "|    total_timesteps     | 131866    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.94e+18  |\n",
      "|    alpha_mean          | 14.2      |\n",
      "|    alpha_mean_loss     | -9.59e+10 |\n",
      "|    alpha_std           | 15.2      |\n",
      "|    alpha_std_loss      | -0.0163   |\n",
      "|    critic_loss         | 2.04e+35  |\n",
      "|    dual_loss           | 1.94e+18  |\n",
      "|    kl_loss             | 9.59e+10  |\n",
      "|    kl_mean_loss        | 9.59e+10  |\n",
      "|    kl_std_loss         | 0.0164    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 131728    |\n",
      "|    penalty_temperature | 38.2      |\n",
      "|    policy_loss         | 1.01e+10  |\n",
      "|    policy_mean_loss    | 1.01e+10  |\n",
      "|    policy_std_loss     | 48.2      |\n",
      "|    std                 | 1.82e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.94e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89.9      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 668       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1964      |\n",
      "|    total_timesteps     | 132162    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.01e+18  |\n",
      "|    alpha_mean          | 14.2      |\n",
      "|    alpha_mean_loss     | -9.78e+10 |\n",
      "|    alpha_std           | 15.3      |\n",
      "|    alpha_std_loss      | -0.0159   |\n",
      "|    critic_loss         | 2.2e+35   |\n",
      "|    dual_loss           | 2.01e+18  |\n",
      "|    kl_loss             | 9.78e+10  |\n",
      "|    kl_mean_loss        | 9.78e+10  |\n",
      "|    kl_std_loss         | 0.0159    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 132035    |\n",
      "|    penalty_temperature | 38.3      |\n",
      "|    policy_loss         | 1.02e+10  |\n",
      "|    policy_mean_loss    | 1.02e+10  |\n",
      "|    policy_std_loss     | 48.3      |\n",
      "|    std                 | 1.88e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 2.01e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 90.8      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 672       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1969      |\n",
      "|    total_timesteps     | 132511    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.07e+18  |\n",
      "|    alpha_mean          | 14.3      |\n",
      "|    alpha_mean_loss     | -1.43e+11 |\n",
      "|    alpha_std           | 15.3      |\n",
      "|    alpha_std_loss      | -0.0157   |\n",
      "|    critic_loss         | 2.29e+35  |\n",
      "|    dual_loss           | 2.07e+18  |\n",
      "|    kl_loss             | 1.43e+11  |\n",
      "|    kl_mean_loss        | 1.43e+11  |\n",
      "|    kl_std_loss         | 0.0158    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 132386    |\n",
      "|    penalty_temperature | 38.4      |\n",
      "|    policy_loss         | 1.49e+10  |\n",
      "|    policy_mean_loss    | 1.49e+10  |\n",
      "|    policy_std_loss     | 48.4      |\n",
      "|    std                 | 1.95e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 2.07e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89.9      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 676       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1973      |\n",
      "|    total_timesteps     | 132785    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.13e+18  |\n",
      "|    alpha_mean          | 14.3      |\n",
      "|    alpha_mean_loss     | -1.19e+11 |\n",
      "|    alpha_std           | 15.3      |\n",
      "|    alpha_std_loss      | -0.0163   |\n",
      "|    critic_loss         | 2.45e+35  |\n",
      "|    dual_loss           | 2.13e+18  |\n",
      "|    kl_loss             | 1.19e+11  |\n",
      "|    kl_mean_loss        | 1.19e+11  |\n",
      "|    kl_std_loss         | 0.0163    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 132634    |\n",
      "|    penalty_temperature | 38.4      |\n",
      "|    policy_loss         | 1.24e+10  |\n",
      "|    policy_mean_loss    | 1.24e+10  |\n",
      "|    policy_std_loss     | 48.4      |\n",
      "|    std                 | 2e+07     |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 2.13e+18  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 89.9     |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 680      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 1978     |\n",
      "|    total_timesteps     | 133101   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.2e+18  |\n",
      "|    alpha_mean          | 14.4     |\n",
      "|    alpha_mean_loss     | -1.3e+11 |\n",
      "|    alpha_std           | 15.3     |\n",
      "|    alpha_std_loss      | -0.016   |\n",
      "|    critic_loss         | 2.59e+35 |\n",
      "|    dual_loss           | 2.2e+18  |\n",
      "|    kl_loss             | 1.3e+11  |\n",
      "|    kl_mean_loss        | 1.3e+11  |\n",
      "|    kl_std_loss         | 0.0161   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 132962   |\n",
      "|    penalty_temperature | 38.5     |\n",
      "|    policy_loss         | 1.34e+10 |\n",
      "|    policy_mean_loss    | 1.34e+10 |\n",
      "|    policy_std_loss     | 48.5     |\n",
      "|    std                 | 2.06e+07 |\n",
      "|    temperature         | 6.62     |\n",
      "|    temperature_loss    | 2.2e+18  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 88.8      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 684       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1983      |\n",
      "|    total_timesteps     | 133371    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.26e+18  |\n",
      "|    alpha_mean          | 14.4      |\n",
      "|    alpha_mean_loss     | -1.23e+11 |\n",
      "|    alpha_std           | 15.3      |\n",
      "|    alpha_std_loss      | -0.0158   |\n",
      "|    critic_loss         | 2.73e+35  |\n",
      "|    dual_loss           | 2.26e+18  |\n",
      "|    kl_loss             | 1.23e+11  |\n",
      "|    kl_mean_loss        | 1.23e+11  |\n",
      "|    kl_std_loss         | 0.0158    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 133262    |\n",
      "|    penalty_temperature | 38.6      |\n",
      "|    policy_loss         | 1.27e+10  |\n",
      "|    policy_mean_loss    | 1.27e+10  |\n",
      "|    policy_std_loss     | 48.6      |\n",
      "|    std                 | 2.13e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 2.26e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 88.5      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 688       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1987      |\n",
      "|    total_timesteps     | 133677    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.33e+18  |\n",
      "|    alpha_mean          | 14.4      |\n",
      "|    alpha_mean_loss     | -1.18e+11 |\n",
      "|    alpha_std           | 15.4      |\n",
      "|    alpha_std_loss      | -0.0161   |\n",
      "|    critic_loss         | 2.91e+35  |\n",
      "|    dual_loss           | 2.33e+18  |\n",
      "|    kl_loss             | 1.18e+11  |\n",
      "|    kl_mean_loss        | 1.18e+11  |\n",
      "|    kl_std_loss         | 0.0162    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 133560    |\n",
      "|    penalty_temperature | 38.7      |\n",
      "|    policy_loss         | 1.22e+10  |\n",
      "|    policy_mean_loss    | 1.22e+10  |\n",
      "|    policy_std_loss     | 48.6      |\n",
      "|    std                 | 2.19e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 2.33e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 88        |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 692       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1991      |\n",
      "|    total_timesteps     | 133964    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.39e+18  |\n",
      "|    alpha_mean          | 14.5      |\n",
      "|    alpha_mean_loss     | -1.18e+11 |\n",
      "|    alpha_std           | 15.4      |\n",
      "|    alpha_std_loss      | -0.0155   |\n",
      "|    critic_loss         | 3.07e+35  |\n",
      "|    dual_loss           | 2.39e+18  |\n",
      "|    kl_loss             | 1.18e+11  |\n",
      "|    kl_mean_loss        | 1.18e+11  |\n",
      "|    kl_std_loss         | 0.0156    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 133844    |\n",
      "|    penalty_temperature | 38.8      |\n",
      "|    policy_loss         | 1.22e+10  |\n",
      "|    policy_mean_loss    | 1.22e+10  |\n",
      "|    policy_std_loss     | 48.7      |\n",
      "|    std                 | 2.25e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 2.39e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 87.5      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 696       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 1995      |\n",
      "|    total_timesteps     | 134248    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.45e+18  |\n",
      "|    alpha_mean          | 14.5      |\n",
      "|    alpha_mean_loss     | -1.51e+11 |\n",
      "|    alpha_std           | 15.4      |\n",
      "|    alpha_std_loss      | -0.0159   |\n",
      "|    critic_loss         | 3.28e+35  |\n",
      "|    dual_loss           | 2.45e+18  |\n",
      "|    kl_loss             | 1.51e+11  |\n",
      "|    kl_mean_loss        | 1.51e+11  |\n",
      "|    kl_std_loss         | 0.0159    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 134096    |\n",
      "|    penalty_temperature | 38.9      |\n",
      "|    policy_loss         | 1.55e+10  |\n",
      "|    policy_mean_loss    | 1.55e+10  |\n",
      "|    policy_std_loss     | 48.7      |\n",
      "|    std                 | 2.31e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 2.45e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 90        |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 700       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2003      |\n",
      "|    total_timesteps     | 134780    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.57e+18  |\n",
      "|    alpha_mean          | 14.6      |\n",
      "|    alpha_mean_loss     | -1.21e+11 |\n",
      "|    alpha_std           | 15.5      |\n",
      "|    alpha_std_loss      | -0.0155   |\n",
      "|    critic_loss         | 3.52e+35  |\n",
      "|    dual_loss           | 2.57e+18  |\n",
      "|    kl_loss             | 1.21e+11  |\n",
      "|    kl_mean_loss        | 1.21e+11  |\n",
      "|    kl_std_loss         | 0.0155    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 134665    |\n",
      "|    penalty_temperature | 39        |\n",
      "|    policy_loss         | 1.23e+10  |\n",
      "|    policy_mean_loss    | 1.23e+10  |\n",
      "|    policy_std_loss     | 48.8      |\n",
      "|    std                 | 2.45e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 2.57e+18  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 89.5     |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 704      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 2007     |\n",
      "|    total_timesteps     | 135049   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.65e+18 |\n",
      "|    alpha_mean          | 14.6     |\n",
      "|    alpha_mean_loss     | -9.8e+10 |\n",
      "|    alpha_std           | 15.5     |\n",
      "|    alpha_std_loss      | -0.0155  |\n",
      "|    critic_loss         | 3.78e+35 |\n",
      "|    dual_loss           | 2.65e+18 |\n",
      "|    kl_loss             | 9.8e+10  |\n",
      "|    kl_mean_loss        | 9.8e+10  |\n",
      "|    kl_std_loss         | 0.0156   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 134896   |\n",
      "|    penalty_temperature | 39.1     |\n",
      "|    policy_loss         | 1e+10    |\n",
      "|    policy_mean_loss    | 1e+10    |\n",
      "|    policy_std_loss     | 48.9     |\n",
      "|    std                 | 2.5e+07  |\n",
      "|    temperature         | 6.62     |\n",
      "|    temperature_loss    | 2.65e+18 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 86.7      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 708       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2011      |\n",
      "|    total_timesteps     | 135292    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.73e+18  |\n",
      "|    alpha_mean          | 14.6      |\n",
      "|    alpha_mean_loss     | -1.66e+11 |\n",
      "|    alpha_std           | 15.5      |\n",
      "|    alpha_std_loss      | -0.0162   |\n",
      "|    critic_loss         | 3.99e+35  |\n",
      "|    dual_loss           | 2.73e+18  |\n",
      "|    kl_loss             | 1.66e+11  |\n",
      "|    kl_mean_loss        | 1.66e+11  |\n",
      "|    kl_std_loss         | 0.0163    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 135163    |\n",
      "|    penalty_temperature | 39.2      |\n",
      "|    policy_loss         | 1.69e+10  |\n",
      "|    policy_mean_loss    | 1.69e+10  |\n",
      "|    policy_std_loss     | 48.9      |\n",
      "|    std                 | 2.57e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 2.73e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 86.8      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 712       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2014      |\n",
      "|    total_timesteps     | 135540    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.79e+18  |\n",
      "|    alpha_mean          | 14.7      |\n",
      "|    alpha_mean_loss     | -9.57e+10 |\n",
      "|    alpha_std           | 15.5      |\n",
      "|    alpha_std_loss      | -0.0156   |\n",
      "|    critic_loss         | 4.14e+35  |\n",
      "|    dual_loss           | 2.79e+18  |\n",
      "|    kl_loss             | 9.57e+10  |\n",
      "|    kl_mean_loss        | 9.57e+10  |\n",
      "|    kl_std_loss         | 0.0157    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 135410    |\n",
      "|    penalty_temperature | 39.3      |\n",
      "|    policy_loss         | 9.72e+09  |\n",
      "|    policy_mean_loss    | 9.72e+09  |\n",
      "|    policy_std_loss     | 49        |\n",
      "|    std                 | 2.63e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 2.79e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 84.8      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 716       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2019      |\n",
      "|    total_timesteps     | 135867    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 2.87e+18  |\n",
      "|    alpha_mean          | 14.7      |\n",
      "|    alpha_mean_loss     | -1.31e+11 |\n",
      "|    alpha_std           | 15.5      |\n",
      "|    alpha_std_loss      | -0.0156   |\n",
      "|    critic_loss         | 4.38e+35  |\n",
      "|    dual_loss           | 2.87e+18  |\n",
      "|    kl_loss             | 1.31e+11  |\n",
      "|    kl_mean_loss        | 1.31e+11  |\n",
      "|    kl_std_loss         | 0.0156    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 135685    |\n",
      "|    penalty_temperature | 39.3      |\n",
      "|    policy_loss         | 1.33e+10  |\n",
      "|    policy_mean_loss    | 1.33e+10  |\n",
      "|    policy_std_loss     | 49.1      |\n",
      "|    std                 | 2.7e+07   |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 2.87e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 86        |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 720       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2027      |\n",
      "|    total_timesteps     | 136462    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.01e+18  |\n",
      "|    alpha_mean          | 14.8      |\n",
      "|    alpha_mean_loss     | -1.44e+11 |\n",
      "|    alpha_std           | 15.6      |\n",
      "|    alpha_std_loss      | -0.0155   |\n",
      "|    critic_loss         | 4.83e+35  |\n",
      "|    dual_loss           | 3.01e+18  |\n",
      "|    kl_loss             | 1.44e+11  |\n",
      "|    kl_mean_loss        | 1.44e+11  |\n",
      "|    kl_std_loss         | 0.0155    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 136272    |\n",
      "|    penalty_temperature | 39.5      |\n",
      "|    policy_loss         | 1.45e+10  |\n",
      "|    policy_mean_loss    | 1.45e+10  |\n",
      "|    policy_std_loss     | 49.2      |\n",
      "|    std                 | 2.86e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 3.01e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 84.8      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 724       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2033      |\n",
      "|    total_timesteps     | 136771    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.13e+18  |\n",
      "|    alpha_mean          | 14.8      |\n",
      "|    alpha_mean_loss     | -1.37e+11 |\n",
      "|    alpha_std           | 15.6      |\n",
      "|    alpha_std_loss      | -0.015    |\n",
      "|    critic_loss         | 5.21e+35  |\n",
      "|    dual_loss           | 3.13e+18  |\n",
      "|    kl_loss             | 1.37e+11  |\n",
      "|    kl_mean_loss        | 1.37e+11  |\n",
      "|    kl_std_loss         | 0.015     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 136646    |\n",
      "|    penalty_temperature | 39.6      |\n",
      "|    policy_loss         | 1.38e+10  |\n",
      "|    policy_mean_loss    | 1.38e+10  |\n",
      "|    policy_std_loss     | 49.2      |\n",
      "|    std                 | 2.97e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 3.13e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 84.7      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 728       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2037      |\n",
      "|    total_timesteps     | 137018    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.22e+18  |\n",
      "|    alpha_mean          | 14.9      |\n",
      "|    alpha_mean_loss     | -1.46e+11 |\n",
      "|    alpha_std           | 15.6      |\n",
      "|    alpha_std_loss      | -0.0155   |\n",
      "|    critic_loss         | 5.5e+35   |\n",
      "|    dual_loss           | 3.22e+18  |\n",
      "|    kl_loss             | 1.46e+11  |\n",
      "|    kl_mean_loss        | 1.46e+11  |\n",
      "|    kl_std_loss         | 0.0156    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 136890    |\n",
      "|    penalty_temperature | 39.6      |\n",
      "|    policy_loss         | 1.46e+10  |\n",
      "|    policy_mean_loss    | 1.46e+10  |\n",
      "|    policy_std_loss     | 49.3      |\n",
      "|    std                 | 3.04e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 3.22e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 84.5      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 732       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2040      |\n",
      "|    total_timesteps     | 137306    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.3e+18   |\n",
      "|    alpha_mean          | 14.9      |\n",
      "|    alpha_mean_loss     | -1.83e+11 |\n",
      "|    alpha_std           | 15.6      |\n",
      "|    alpha_std_loss      | -0.0154   |\n",
      "|    critic_loss         | 5.78e+35  |\n",
      "|    dual_loss           | 3.3e+18   |\n",
      "|    kl_loss             | 1.83e+11  |\n",
      "|    kl_mean_loss        | 1.83e+11  |\n",
      "|    kl_std_loss         | 0.0154    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 137145    |\n",
      "|    penalty_temperature | 39.7      |\n",
      "|    policy_loss         | 1.83e+10  |\n",
      "|    policy_mean_loss    | 1.83e+10  |\n",
      "|    policy_std_loss     | 49.3      |\n",
      "|    std                 | 3.12e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 3.3e+18   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 83.8      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 736       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2046      |\n",
      "|    total_timesteps     | 137621    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.42e+18  |\n",
      "|    alpha_mean          | 14.9      |\n",
      "|    alpha_mean_loss     | -1.85e+11 |\n",
      "|    alpha_std           | 15.6      |\n",
      "|    alpha_std_loss      | -0.0154   |\n",
      "|    critic_loss         | 6.15e+35  |\n",
      "|    dual_loss           | 3.42e+18  |\n",
      "|    kl_loss             | 1.85e+11  |\n",
      "|    kl_mean_loss        | 1.85e+11  |\n",
      "|    kl_std_loss         | 0.0154    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 137497    |\n",
      "|    penalty_temperature | 39.8      |\n",
      "|    policy_loss         | 1.85e+10  |\n",
      "|    policy_mean_loss    | 1.85e+10  |\n",
      "|    policy_std_loss     | 49.4      |\n",
      "|    std                 | 3.23e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 3.42e+18  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 83.1     |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 740      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 2050     |\n",
      "|    total_timesteps     | 137934   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.52e+18 |\n",
      "|    alpha_mean          | 15       |\n",
      "|    alpha_mean_loss     | -1.1e+11 |\n",
      "|    alpha_std           | 15.7     |\n",
      "|    alpha_std_loss      | -0.0156  |\n",
      "|    critic_loss         | 6.51e+35 |\n",
      "|    dual_loss           | 3.52e+18 |\n",
      "|    kl_loss             | 1.1e+11  |\n",
      "|    kl_mean_loss        | 1.1e+11  |\n",
      "|    kl_std_loss         | 0.0156   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 137818   |\n",
      "|    penalty_temperature | 39.9     |\n",
      "|    policy_loss         | 1.09e+10 |\n",
      "|    policy_mean_loss    | 1.09e+10 |\n",
      "|    policy_std_loss     | 49.5     |\n",
      "|    std                 | 3.33e+07 |\n",
      "|    temperature         | 6.62     |\n",
      "|    temperature_loss    | 3.52e+18 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 81.5      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 744       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2054      |\n",
      "|    total_timesteps     | 138164    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.6e+18   |\n",
      "|    alpha_mean          | 15        |\n",
      "|    alpha_mean_loss     | -1.73e+11 |\n",
      "|    alpha_std           | 15.7      |\n",
      "|    alpha_std_loss      | -0.0154   |\n",
      "|    critic_loss         | 6.74e+35  |\n",
      "|    dual_loss           | 3.6e+18   |\n",
      "|    kl_loss             | 1.73e+11  |\n",
      "|    kl_mean_loss        | 1.73e+11  |\n",
      "|    kl_std_loss         | 0.0155    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 138050    |\n",
      "|    penalty_temperature | 39.9      |\n",
      "|    policy_loss         | 1.72e+10  |\n",
      "|    policy_mean_loss    | 1.72e+10  |\n",
      "|    policy_std_loss     | 49.5      |\n",
      "|    std                 | 3.41e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 3.6e+18   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 81.4      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 748       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2059      |\n",
      "|    total_timesteps     | 138502    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.7e+18   |\n",
      "|    alpha_mean          | 15        |\n",
      "|    alpha_mean_loss     | -1.45e+11 |\n",
      "|    alpha_std           | 15.7      |\n",
      "|    alpha_std_loss      | -0.0153   |\n",
      "|    critic_loss         | 7.19e+35  |\n",
      "|    dual_loss           | 3.7e+18   |\n",
      "|    kl_loss             | 1.45e+11  |\n",
      "|    kl_mean_loss        | 1.45e+11  |\n",
      "|    kl_std_loss         | 0.0154    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 138377    |\n",
      "|    penalty_temperature | 40        |\n",
      "|    policy_loss         | 1.44e+10  |\n",
      "|    policy_mean_loss    | 1.44e+10  |\n",
      "|    policy_std_loss     | 49.5      |\n",
      "|    std                 | 3.51e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 3.7e+18   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 80.4      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 752       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2064      |\n",
      "|    total_timesteps     | 138900    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.85e+18  |\n",
      "|    alpha_mean          | 15.1      |\n",
      "|    alpha_mean_loss     | -1.87e+11 |\n",
      "|    alpha_std           | 15.7      |\n",
      "|    alpha_std_loss      | -0.0154   |\n",
      "|    critic_loss         | 7.69e+35  |\n",
      "|    dual_loss           | 3.85e+18  |\n",
      "|    kl_loss             | 1.87e+11  |\n",
      "|    kl_mean_loss        | 1.87e+11  |\n",
      "|    kl_std_loss         | 0.0154    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 138749    |\n",
      "|    penalty_temperature | 40.1      |\n",
      "|    policy_loss         | 1.84e+10  |\n",
      "|    policy_mean_loss    | 1.84e+10  |\n",
      "|    policy_std_loss     | 49.6      |\n",
      "|    std                 | 3.65e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 3.85e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 81.9      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 756       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2070      |\n",
      "|    total_timesteps     | 139346    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 3.99e+18  |\n",
      "|    alpha_mean          | 15.1      |\n",
      "|    alpha_mean_loss     | -1.44e+11 |\n",
      "|    alpha_std           | 15.7      |\n",
      "|    alpha_std_loss      | -0.0154   |\n",
      "|    critic_loss         | 8.28e+35  |\n",
      "|    dual_loss           | 3.99e+18  |\n",
      "|    kl_loss             | 1.44e+11  |\n",
      "|    kl_mean_loss        | 1.44e+11  |\n",
      "|    kl_std_loss         | 0.0155    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 139160    |\n",
      "|    penalty_temperature | 40.2      |\n",
      "|    policy_loss         | 1.42e+10  |\n",
      "|    policy_mean_loss    | 1.42e+10  |\n",
      "|    policy_std_loss     | 49.7      |\n",
      "|    std                 | 3.79e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 3.99e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 83.1      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 760       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2075      |\n",
      "|    total_timesteps     | 139766    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.1e+18   |\n",
      "|    alpha_mean          | 15.2      |\n",
      "|    alpha_mean_loss     | -1.66e+11 |\n",
      "|    alpha_std           | 15.8      |\n",
      "|    alpha_std_loss      | -0.0151   |\n",
      "|    critic_loss         | 8.8e+35   |\n",
      "|    dual_loss           | 4.1e+18   |\n",
      "|    kl_loss             | 1.66e+11  |\n",
      "|    kl_mean_loss        | 1.66e+11  |\n",
      "|    kl_std_loss         | 0.0151    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 139462    |\n",
      "|    penalty_temperature | 40.3      |\n",
      "|    policy_loss         | 1.62e+10  |\n",
      "|    policy_mean_loss    | 1.62e+10  |\n",
      "|    policy_std_loss     | 49.8      |\n",
      "|    std                 | 3.9e+07   |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 4.1e+18   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 83        |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 764       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2083      |\n",
      "|    total_timesteps     | 140162    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.31e+18  |\n",
      "|    alpha_mean          | 15.2      |\n",
      "|    alpha_mean_loss     | -1.93e+11 |\n",
      "|    alpha_std           | 15.8      |\n",
      "|    alpha_std_loss      | -0.0152   |\n",
      "|    critic_loss         | 9.75e+35  |\n",
      "|    dual_loss           | 4.31e+18  |\n",
      "|    kl_loss             | 1.93e+11  |\n",
      "|    kl_mean_loss        | 1.93e+11  |\n",
      "|    kl_std_loss         | 0.0153    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 139988    |\n",
      "|    penalty_temperature | 40.4      |\n",
      "|    policy_loss         | 1.89e+10  |\n",
      "|    policy_mean_loss    | 1.89e+10  |\n",
      "|    policy_std_loss     | 49.9      |\n",
      "|    std                 | 4.1e+07   |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 4.31e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 82.7      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 768       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2088      |\n",
      "|    total_timesteps     | 140436    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.46e+18  |\n",
      "|    alpha_mean          | 15.3      |\n",
      "|    alpha_mean_loss     | -1.69e+11 |\n",
      "|    alpha_std           | 15.8      |\n",
      "|    alpha_std_loss      | -0.015    |\n",
      "|    critic_loss         | 1.04e+36  |\n",
      "|    dual_loss           | 4.46e+18  |\n",
      "|    kl_loss             | 1.69e+11  |\n",
      "|    kl_mean_loss        | 1.69e+11  |\n",
      "|    kl_std_loss         | 0.0151    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 140334    |\n",
      "|    penalty_temperature | 40.5      |\n",
      "|    policy_loss         | 1.65e+10  |\n",
      "|    policy_mean_loss    | 1.65e+10  |\n",
      "|    policy_std_loss     | 50        |\n",
      "|    std                 | 4.24e+07  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 4.46e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 83.9      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 772       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2094      |\n",
      "|    total_timesteps     | 140902    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.65e+18  |\n",
      "|    alpha_mean          | 15.3      |\n",
      "|    alpha_mean_loss     | -1.38e+11 |\n",
      "|    alpha_std           | 15.8      |\n",
      "|    alpha_std_loss      | -0.0154   |\n",
      "|    critic_loss         | 1.13e+36  |\n",
      "|    dual_loss           | 4.65e+18  |\n",
      "|    kl_loss             | 1.38e+11  |\n",
      "|    kl_mean_loss        | 1.38e+11  |\n",
      "|    kl_std_loss         | 0.0155    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 140746    |\n",
      "|    penalty_temperature | 40.6      |\n",
      "|    policy_loss         | 1.34e+10  |\n",
      "|    policy_mean_loss    | 1.34e+10  |\n",
      "|    policy_std_loss     | 50        |\n",
      "|    std                 | 4.41e+07  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 4.65e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 83.3      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 776       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2097      |\n",
      "|    total_timesteps     | 141114    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.75e+18  |\n",
      "|    alpha_mean          | 15.4      |\n",
      "|    alpha_mean_loss     | -2.36e+11 |\n",
      "|    alpha_std           | 15.8      |\n",
      "|    alpha_std_loss      | -0.015    |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 4.75e+18  |\n",
      "|    kl_loss             | 2.36e+11  |\n",
      "|    kl_mean_loss        | 2.36e+11  |\n",
      "|    kl_std_loss         | 0.0151    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 140993    |\n",
      "|    penalty_temperature | 40.6      |\n",
      "|    policy_loss         | 2.29e+10  |\n",
      "|    policy_mean_loss    | 2.29e+10  |\n",
      "|    policy_std_loss     | 50.1      |\n",
      "|    std                 | 4.52e+07  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 4.75e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 83.8      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 780       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2102      |\n",
      "|    total_timesteps     | 141482    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 4.89e+18  |\n",
      "|    alpha_mean          | 15.4      |\n",
      "|    alpha_mean_loss     | -1.59e+11 |\n",
      "|    alpha_std           | 15.9      |\n",
      "|    alpha_std_loss      | -0.015    |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 4.89e+18  |\n",
      "|    kl_loss             | 1.59e+11  |\n",
      "|    kl_mean_loss        | 1.59e+11  |\n",
      "|    kl_std_loss         | 0.015     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 141291    |\n",
      "|    penalty_temperature | 40.7      |\n",
      "|    policy_loss         | 1.54e+10  |\n",
      "|    policy_mean_loss    | 1.54e+10  |\n",
      "|    policy_std_loss     | 50.1      |\n",
      "|    std                 | 4.65e+07  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 4.89e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 84.7      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 784       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2107      |\n",
      "|    total_timesteps     | 141840    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 5.03e+18  |\n",
      "|    alpha_mean          | 15.5      |\n",
      "|    alpha_mean_loss     | -2.13e+11 |\n",
      "|    alpha_std           | 15.9      |\n",
      "|    alpha_std_loss      | -0.015    |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 5.03e+18  |\n",
      "|    kl_loss             | 2.13e+11  |\n",
      "|    kl_mean_loss        | 2.13e+11  |\n",
      "|    kl_std_loss         | 0.015     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 141665    |\n",
      "|    penalty_temperature | 40.7      |\n",
      "|    policy_loss         | 2.06e+10  |\n",
      "|    policy_mean_loss    | 2.06e+10  |\n",
      "|    policy_std_loss     | 50.2      |\n",
      "|    std                 | 4.81e+07  |\n",
      "|    temperature         | 6.6       |\n",
      "|    temperature_loss    | 5.03e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 85        |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 788       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2113      |\n",
      "|    total_timesteps     | 142173    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 5.21e+18  |\n",
      "|    alpha_mean          | 15.5      |\n",
      "|    alpha_mean_loss     | -1.94e+11 |\n",
      "|    alpha_std           | 15.9      |\n",
      "|    alpha_std_loss      | -0.0149   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 5.21e+18  |\n",
      "|    kl_loss             | 1.94e+11  |\n",
      "|    kl_mean_loss        | 1.94e+11  |\n",
      "|    kl_std_loss         | 0.015     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 142017    |\n",
      "|    penalty_temperature | 40.8      |\n",
      "|    policy_loss         | 1.86e+10  |\n",
      "|    policy_mean_loss    | 1.86e+10  |\n",
      "|    policy_std_loss     | 50.3      |\n",
      "|    std                 | 4.98e+07  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 5.21e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 87.6      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 792       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2121      |\n",
      "|    total_timesteps     | 142724    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 5.46e+18  |\n",
      "|    alpha_mean          | 15.6      |\n",
      "|    alpha_mean_loss     | -2.13e+11 |\n",
      "|    alpha_std           | 15.9      |\n",
      "|    alpha_std_loss      | -0.0147   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 5.46e+18  |\n",
      "|    kl_loss             | 2.13e+11  |\n",
      "|    kl_mean_loss        | 2.13e+11  |\n",
      "|    kl_std_loss         | 0.0148    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 142546    |\n",
      "|    penalty_temperature | 40.9      |\n",
      "|    policy_loss         | 2.04e+10  |\n",
      "|    policy_mean_loss    | 2.04e+10  |\n",
      "|    policy_std_loss     | 50.3      |\n",
      "|    std                 | 5.23e+07  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 5.46e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 88.6      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 796       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2127      |\n",
      "|    total_timesteps     | 143105    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 5.73e+18  |\n",
      "|    alpha_mean          | 15.6      |\n",
      "|    alpha_mean_loss     | -2.07e+11 |\n",
      "|    alpha_std           | 15.9      |\n",
      "|    alpha_std_loss      | -0.015    |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 5.73e+18  |\n",
      "|    kl_loss             | 2.07e+11  |\n",
      "|    kl_mean_loss        | 2.07e+11  |\n",
      "|    kl_std_loss         | 0.0151    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 142988    |\n",
      "|    penalty_temperature | 41        |\n",
      "|    policy_loss         | 1.98e+10  |\n",
      "|    policy_mean_loss    | 1.98e+10  |\n",
      "|    policy_std_loss     | 50.5      |\n",
      "|    std                 | 5.45e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 5.73e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 86.3      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 800       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2132      |\n",
      "|    total_timesteps     | 143414    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 5.89e+18  |\n",
      "|    alpha_mean          | 15.7      |\n",
      "|    alpha_mean_loss     | -2.04e+11 |\n",
      "|    alpha_std           | 15.9      |\n",
      "|    alpha_std_loss      | -0.0152   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 5.89e+18  |\n",
      "|    kl_loss             | 2.04e+11  |\n",
      "|    kl_mean_loss        | 2.04e+11  |\n",
      "|    kl_std_loss         | 0.0153    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 143292    |\n",
      "|    penalty_temperature | 41.1      |\n",
      "|    policy_loss         | 1.94e+10  |\n",
      "|    policy_mean_loss    | 1.94e+10  |\n",
      "|    policy_std_loss     | 50.5      |\n",
      "|    std                 | 5.61e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 5.89e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 86.5      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 804       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2136      |\n",
      "|    total_timesteps     | 143704    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 6.02e+18  |\n",
      "|    alpha_mean          | 15.7      |\n",
      "|    alpha_mean_loss     | -2.78e+11 |\n",
      "|    alpha_std           | 16        |\n",
      "|    alpha_std_loss      | -0.0147   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 6.02e+18  |\n",
      "|    kl_loss             | 2.78e+11  |\n",
      "|    kl_mean_loss        | 2.78e+11  |\n",
      "|    kl_std_loss         | 0.0147    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 143581    |\n",
      "|    penalty_temperature | 41.2      |\n",
      "|    policy_loss         | 2.64e+10  |\n",
      "|    policy_mean_loss    | 2.64e+10  |\n",
      "|    policy_std_loss     | 50.6      |\n",
      "|    std                 | 5.76e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 6.02e+18  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 86.9     |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 808      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 2140     |\n",
      "|    total_timesteps     | 143984   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.18e+18 |\n",
      "|    alpha_mean          | 15.7     |\n",
      "|    alpha_mean_loss     | -2.5e+11 |\n",
      "|    alpha_std           | 16       |\n",
      "|    alpha_std_loss      | -0.0147  |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 6.18e+18 |\n",
      "|    kl_loss             | 2.5e+11  |\n",
      "|    kl_mean_loss        | 2.5e+11  |\n",
      "|    kl_std_loss         | 0.0147   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 143872   |\n",
      "|    penalty_temperature | 41.2     |\n",
      "|    policy_loss         | 2.37e+10 |\n",
      "|    policy_mean_loss    | 2.37e+10 |\n",
      "|    policy_std_loss     | 50.6     |\n",
      "|    std                 | 5.92e+07 |\n",
      "|    temperature         | 6.62     |\n",
      "|    temperature_loss    | 6.18e+18 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 87.3     |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 812      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 2144     |\n",
      "|    total_timesteps     | 144268   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.31e+18 |\n",
      "|    alpha_mean          | 15.8     |\n",
      "|    alpha_mean_loss     | -2.9e+11 |\n",
      "|    alpha_std           | 16       |\n",
      "|    alpha_std_loss      | -0.0143  |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 6.31e+18 |\n",
      "|    kl_loss             | 2.9e+11  |\n",
      "|    kl_mean_loss        | 2.9e+11  |\n",
      "|    kl_std_loss         | 0.0144   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 144106   |\n",
      "|    penalty_temperature | 41.3     |\n",
      "|    policy_loss         | 2.74e+10 |\n",
      "|    policy_mean_loss    | 2.74e+10 |\n",
      "|    policy_std_loss     | 50.7     |\n",
      "|    std                 | 6.05e+07 |\n",
      "|    temperature         | 6.61     |\n",
      "|    temperature_loss    | 6.31e+18 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 86.8      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 816       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2148      |\n",
      "|    total_timesteps     | 144551    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 6.52e+18  |\n",
      "|    alpha_mean          | 15.8      |\n",
      "|    alpha_mean_loss     | -2.61e+11 |\n",
      "|    alpha_std           | 16        |\n",
      "|    alpha_std_loss      | -0.0148   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 6.52e+18  |\n",
      "|    kl_loss             | 2.61e+11  |\n",
      "|    kl_mean_loss        | 2.61e+11  |\n",
      "|    kl_std_loss         | 0.0148    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 144407    |\n",
      "|    penalty_temperature | 41.4      |\n",
      "|    policy_loss         | 2.46e+10  |\n",
      "|    policy_mean_loss    | 2.46e+10  |\n",
      "|    policy_std_loss     | 50.7      |\n",
      "|    std                 | 6.23e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 6.52e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 85.6      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 820       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2155      |\n",
      "|    total_timesteps     | 145020    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 6.78e+18  |\n",
      "|    alpha_mean          | 15.9      |\n",
      "|    alpha_mean_loss     | -1.35e+11 |\n",
      "|    alpha_std           | 16        |\n",
      "|    alpha_std_loss      | -0.0149   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 6.78e+18  |\n",
      "|    kl_loss             | 1.35e+11  |\n",
      "|    kl_mean_loss        | 1.35e+11  |\n",
      "|    kl_std_loss         | 0.0149    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 144862    |\n",
      "|    penalty_temperature | 41.5      |\n",
      "|    policy_loss         | 1.27e+10  |\n",
      "|    policy_mean_loss    | 1.27e+10  |\n",
      "|    policy_std_loss     | 50.8      |\n",
      "|    std                 | 6.49e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 6.78e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 85.5      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 824       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2160      |\n",
      "|    total_timesteps     | 145320    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 6.98e+18  |\n",
      "|    alpha_mean          | 15.9      |\n",
      "|    alpha_mean_loss     | -2.47e+11 |\n",
      "|    alpha_std           | 16        |\n",
      "|    alpha_std_loss      | -0.0147   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 6.98e+18  |\n",
      "|    kl_loss             | 2.47e+11  |\n",
      "|    kl_mean_loss        | 2.47e+11  |\n",
      "|    kl_std_loss         | 0.0148    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 145194    |\n",
      "|    penalty_temperature | 41.5      |\n",
      "|    policy_loss         | 2.32e+10  |\n",
      "|    policy_mean_loss    | 2.32e+10  |\n",
      "|    policy_std_loss     | 50.9      |\n",
      "|    std                 | 6.7e+07   |\n",
      "|    temperature         | 6.63      |\n",
      "|    temperature_loss    | 6.98e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 87.2      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 828       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2166      |\n",
      "|    total_timesteps     | 145738    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 7.24e+18  |\n",
      "|    alpha_mean          | 15.9      |\n",
      "|    alpha_mean_loss     | -1.69e+11 |\n",
      "|    alpha_std           | 16        |\n",
      "|    alpha_std_loss      | -0.0147   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 7.24e+18  |\n",
      "|    kl_loss             | 1.69e+11  |\n",
      "|    kl_mean_loss        | 1.69e+11  |\n",
      "|    kl_std_loss         | 0.0147    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 145584    |\n",
      "|    penalty_temperature | 41.6      |\n",
      "|    policy_loss         | 1.58e+10  |\n",
      "|    policy_mean_loss    | 1.58e+10  |\n",
      "|    policy_std_loss     | 50.9      |\n",
      "|    std                 | 6.94e+07  |\n",
      "|    temperature         | 6.63      |\n",
      "|    temperature_loss    | 7.24e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 88        |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 832       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2171      |\n",
      "|    total_timesteps     | 146109    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 7.5e+18   |\n",
      "|    alpha_mean          | 16        |\n",
      "|    alpha_mean_loss     | -2.77e+11 |\n",
      "|    alpha_std           | 16.1      |\n",
      "|    alpha_std_loss      | -0.0146   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 7.5e+18   |\n",
      "|    kl_loss             | 2.77e+11  |\n",
      "|    kl_mean_loss        | 2.77e+11  |\n",
      "|    kl_std_loss         | 0.0147    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 145965    |\n",
      "|    penalty_temperature | 41.7      |\n",
      "|    policy_loss         | 2.58e+10  |\n",
      "|    policy_mean_loss    | 2.58e+10  |\n",
      "|    policy_std_loss     | 51        |\n",
      "|    std                 | 7.19e+07  |\n",
      "|    temperature         | 6.63      |\n",
      "|    temperature_loss    | 7.5e+18   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 88.5      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 836       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2177      |\n",
      "|    total_timesteps     | 146468    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 7.74e+18  |\n",
      "|    alpha_mean          | 16        |\n",
      "|    alpha_mean_loss     | -2.81e+11 |\n",
      "|    alpha_std           | 16.1      |\n",
      "|    alpha_std_loss      | -0.0144   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 7.74e+18  |\n",
      "|    kl_loss             | 2.81e+11  |\n",
      "|    kl_mean_loss        | 2.81e+11  |\n",
      "|    kl_std_loss         | 0.0145    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 146336    |\n",
      "|    penalty_temperature | 41.8      |\n",
      "|    policy_loss         | 2.61e+10  |\n",
      "|    policy_mean_loss    | 2.61e+10  |\n",
      "|    policy_std_loss     | 51.1      |\n",
      "|    std                 | 7.44e+07  |\n",
      "|    temperature         | 6.63      |\n",
      "|    temperature_loss    | 7.74e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 88.8      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 840       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2182      |\n",
      "|    total_timesteps     | 146816    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 8e+18     |\n",
      "|    alpha_mean          | 16.1      |\n",
      "|    alpha_mean_loss     | -2.18e+11 |\n",
      "|    alpha_std           | 16.1      |\n",
      "|    alpha_std_loss      | -0.0149   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 8e+18     |\n",
      "|    kl_loss             | 2.18e+11  |\n",
      "|    kl_mean_loss        | 2.18e+11  |\n",
      "|    kl_std_loss         | 0.0149    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 146675    |\n",
      "|    penalty_temperature | 41.9      |\n",
      "|    policy_loss         | 2.02e+10  |\n",
      "|    policy_mean_loss    | 2.02e+10  |\n",
      "|    policy_std_loss     | 51.2      |\n",
      "|    std                 | 7.67e+07  |\n",
      "|    temperature         | 6.64      |\n",
      "|    temperature_loss    | 8e+18     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89.5      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 844       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2186      |\n",
      "|    total_timesteps     | 147114    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 8.24e+18  |\n",
      "|    alpha_mean          | 16.1      |\n",
      "|    alpha_mean_loss     | -4.26e+11 |\n",
      "|    alpha_std           | 16.1      |\n",
      "|    alpha_std_loss      | -0.0149   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 8.24e+18  |\n",
      "|    kl_loss             | 4.26e+11  |\n",
      "|    kl_mean_loss        | 4.26e+11  |\n",
      "|    kl_std_loss         | 0.015     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 146947    |\n",
      "|    penalty_temperature | 42        |\n",
      "|    policy_loss         | 3.94e+10  |\n",
      "|    policy_mean_loss    | 3.94e+10  |\n",
      "|    policy_std_loss     | 51.2      |\n",
      "|    std                 | 7.87e+07  |\n",
      "|    temperature         | 6.63      |\n",
      "|    temperature_loss    | 8.24e+18  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 89.6     |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 848      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 2192     |\n",
      "|    total_timesteps     | 147461   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 8.49e+18 |\n",
      "|    alpha_mean          | 16.2     |\n",
      "|    alpha_mean_loss     | -2.4e+11 |\n",
      "|    alpha_std           | 16.1     |\n",
      "|    alpha_std_loss      | -0.0145  |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 8.49e+18 |\n",
      "|    kl_loss             | 2.4e+11  |\n",
      "|    kl_mean_loss        | 2.4e+11  |\n",
      "|    kl_std_loss         | 0.0145   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 147334   |\n",
      "|    penalty_temperature | 42.1     |\n",
      "|    policy_loss         | 2.21e+10 |\n",
      "|    policy_mean_loss    | 2.21e+10 |\n",
      "|    policy_std_loss     | 51.3     |\n",
      "|    std                 | 8.15e+07 |\n",
      "|    temperature         | 6.63     |\n",
      "|    temperature_loss    | 8.49e+18 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89        |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 852       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2196      |\n",
      "|    total_timesteps     | 147802    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 8.72e+18  |\n",
      "|    alpha_mean          | 16.2      |\n",
      "|    alpha_mean_loss     | -1.56e+11 |\n",
      "|    alpha_std           | 16.1      |\n",
      "|    alpha_std_loss      | -0.0145   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 8.72e+18  |\n",
      "|    kl_loss             | 1.56e+11  |\n",
      "|    kl_mean_loss        | 1.56e+11  |\n",
      "|    kl_std_loss         | 0.0145    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 147624    |\n",
      "|    penalty_temperature | 42.2      |\n",
      "|    policy_loss         | 1.44e+10  |\n",
      "|    policy_mean_loss    | 1.44e+10  |\n",
      "|    policy_std_loss     | 51.3      |\n",
      "|    std                 | 8.37e+07  |\n",
      "|    temperature         | 6.63      |\n",
      "|    temperature_loss    | 8.72e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89.4      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 856       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2204      |\n",
      "|    total_timesteps     | 148283    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 9.18e+18  |\n",
      "|    alpha_mean          | 16.3      |\n",
      "|    alpha_mean_loss     | -3.64e+11 |\n",
      "|    alpha_std           | 16.2      |\n",
      "|    alpha_std_loss      | -0.0147   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 9.18e+18  |\n",
      "|    kl_loss             | 3.64e+11  |\n",
      "|    kl_mean_loss        | 3.64e+11  |\n",
      "|    kl_std_loss         | 0.0147    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 148170    |\n",
      "|    penalty_temperature | 42.2      |\n",
      "|    policy_loss         | 3.33e+10  |\n",
      "|    policy_mean_loss    | 3.33e+10  |\n",
      "|    policy_std_loss     | 51.4      |\n",
      "|    std                 | 8.8e+07   |\n",
      "|    temperature         | 6.64      |\n",
      "|    temperature_loss    | 9.18e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89.5      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 860       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2209      |\n",
      "|    total_timesteps     | 148719    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 9.43e+18  |\n",
      "|    alpha_mean          | 16.3      |\n",
      "|    alpha_mean_loss     | -2.54e+11 |\n",
      "|    alpha_std           | 16.2      |\n",
      "|    alpha_std_loss      | -0.0144   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 9.43e+18  |\n",
      "|    kl_loss             | 2.54e+11  |\n",
      "|    kl_mean_loss        | 2.54e+11  |\n",
      "|    kl_std_loss         | 0.0144    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 148507    |\n",
      "|    penalty_temperature | 42.3      |\n",
      "|    policy_loss         | 2.32e+10  |\n",
      "|    policy_mean_loss    | 2.32e+10  |\n",
      "|    policy_std_loss     | 51.5      |\n",
      "|    std                 | 9.08e+07  |\n",
      "|    temperature         | 6.64      |\n",
      "|    temperature_loss    | 9.43e+18  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 90.2      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 864       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2216      |\n",
      "|    total_timesteps     | 149181    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 9.9e+18   |\n",
      "|    alpha_mean          | 16.4      |\n",
      "|    alpha_mean_loss     | -1.76e+11 |\n",
      "|    alpha_std           | 16.2      |\n",
      "|    alpha_std_loss      | -0.0146   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 9.9e+18   |\n",
      "|    kl_loss             | 1.76e+11  |\n",
      "|    kl_mean_loss        | 1.76e+11  |\n",
      "|    kl_std_loss         | 0.0146    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 148986    |\n",
      "|    penalty_temperature | 42.3      |\n",
      "|    policy_loss         | 1.6e+10   |\n",
      "|    policy_mean_loss    | 1.6e+10   |\n",
      "|    policy_std_loss     | 51.6      |\n",
      "|    std                 | 9.48e+07  |\n",
      "|    temperature         | 6.63      |\n",
      "|    temperature_loss    | 9.9e+18   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 92.2      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 868       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2224      |\n",
      "|    total_timesteps     | 149654    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.03e+19  |\n",
      "|    alpha_mean          | 16.4      |\n",
      "|    alpha_mean_loss     | -3.05e+11 |\n",
      "|    alpha_std           | 16.3      |\n",
      "|    alpha_std_loss      | -0.014    |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 1.03e+19  |\n",
      "|    kl_loss             | 3.05e+11  |\n",
      "|    kl_mean_loss        | 3.05e+11  |\n",
      "|    kl_std_loss         | 0.0141    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 149518    |\n",
      "|    penalty_temperature | 42.4      |\n",
      "|    policy_loss         | 2.76e+10  |\n",
      "|    policy_mean_loss    | 2.76e+10  |\n",
      "|    policy_std_loss     | 51.6      |\n",
      "|    std                 | 9.94e+07  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.03e+19  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 91        |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 872       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2229      |\n",
      "|    total_timesteps     | 149999    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.06e+19  |\n",
      "|    alpha_mean          | 16.5      |\n",
      "|    alpha_mean_loss     | -3.32e+11 |\n",
      "|    alpha_std           | 16.3      |\n",
      "|    alpha_std_loss      | -0.0143   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 1.06e+19  |\n",
      "|    kl_loss             | 3.32e+11  |\n",
      "|    kl_mean_loss        | 3.32e+11  |\n",
      "|    kl_std_loss         | 0.0144    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 149824    |\n",
      "|    penalty_temperature | 42.5      |\n",
      "|    policy_loss         | 3.01e+10  |\n",
      "|    policy_mean_loss    | 3.01e+10  |\n",
      "|    policy_std_loss     | 51.7      |\n",
      "|    std                 | 1.02e+08  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.06e+19  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 91.8      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 876       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2234      |\n",
      "|    total_timesteps     | 150295    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.09e+19  |\n",
      "|    alpha_mean          | 16.5      |\n",
      "|    alpha_mean_loss     | -4.27e+11 |\n",
      "|    alpha_std           | 16.3      |\n",
      "|    alpha_std_loss      | -0.0143   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 1.09e+19  |\n",
      "|    kl_loss             | 4.27e+11  |\n",
      "|    kl_mean_loss        | 4.27e+11  |\n",
      "|    kl_std_loss         | 0.0143    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 150170    |\n",
      "|    penalty_temperature | 42.5      |\n",
      "|    policy_loss         | 3.85e+10  |\n",
      "|    policy_mean_loss    | 3.85e+10  |\n",
      "|    policy_std_loss     | 51.8      |\n",
      "|    std                 | 1.05e+08  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.09e+19  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 93.4      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 880       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2242      |\n",
      "|    total_timesteps     | 150821    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.15e+19  |\n",
      "|    alpha_mean          | 16.6      |\n",
      "|    alpha_mean_loss     | -2.96e+11 |\n",
      "|    alpha_std           | 16.3      |\n",
      "|    alpha_std_loss      | -0.014    |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 1.15e+19  |\n",
      "|    kl_loss             | 2.96e+11  |\n",
      "|    kl_mean_loss        | 2.96e+11  |\n",
      "|    kl_std_loss         | 0.0141    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 150704    |\n",
      "|    penalty_temperature | 42.6      |\n",
      "|    policy_loss         | 2.66e+10  |\n",
      "|    policy_mean_loss    | 2.66e+10  |\n",
      "|    policy_std_loss     | 51.9      |\n",
      "|    std                 | 1.11e+08  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.15e+19  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 94.2      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 884       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2248      |\n",
      "|    total_timesteps     | 151255    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.18e+19  |\n",
      "|    alpha_mean          | 16.6      |\n",
      "|    alpha_mean_loss     | -3.21e+11 |\n",
      "|    alpha_std           | 16.4      |\n",
      "|    alpha_std_loss      | -0.014    |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 1.18e+19  |\n",
      "|    kl_loss             | 3.21e+11  |\n",
      "|    kl_mean_loss        | 3.21e+11  |\n",
      "|    kl_std_loss         | 0.0141    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 151116    |\n",
      "|    penalty_temperature | 42.7      |\n",
      "|    policy_loss         | 2.88e+10  |\n",
      "|    policy_mean_loss    | 2.88e+10  |\n",
      "|    policy_std_loss     | 51.9      |\n",
      "|    std                 | 1.15e+08  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.18e+19  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 93.3      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 888       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2252      |\n",
      "|    total_timesteps     | 151507    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.22e+19  |\n",
      "|    alpha_mean          | 16.7      |\n",
      "|    alpha_mean_loss     | -4.13e+11 |\n",
      "|    alpha_std           | 16.4      |\n",
      "|    alpha_std_loss      | -0.0146   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 1.22e+19  |\n",
      "|    kl_loss             | 4.13e+11  |\n",
      "|    kl_mean_loss        | 4.13e+11  |\n",
      "|    kl_std_loss         | 0.0147    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 151372    |\n",
      "|    penalty_temperature | 42.8      |\n",
      "|    policy_loss         | 3.7e+10   |\n",
      "|    policy_mean_loss    | 3.7e+10   |\n",
      "|    policy_std_loss     | 52        |\n",
      "|    std                 | 1.17e+08  |\n",
      "|    temperature         | 6.61      |\n",
      "|    temperature_loss    | 1.22e+19  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 91.9      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 892       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2257      |\n",
      "|    total_timesteps     | 151917    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.26e+19  |\n",
      "|    alpha_mean          | 16.7      |\n",
      "|    alpha_mean_loss     | -3.61e+11 |\n",
      "|    alpha_std           | 16.4      |\n",
      "|    alpha_std_loss      | -0.0146   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 1.26e+19  |\n",
      "|    kl_loss             | 3.61e+11  |\n",
      "|    kl_mean_loss        | 3.61e+11  |\n",
      "|    kl_std_loss         | 0.0147    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 151700    |\n",
      "|    penalty_temperature | 42.9      |\n",
      "|    policy_loss         | 3.22e+10  |\n",
      "|    policy_mean_loss    | 3.22e+10  |\n",
      "|    policy_std_loss     | 52        |\n",
      "|    std                 | 1.21e+08  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.26e+19  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 90.9      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 896       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2262      |\n",
      "|    total_timesteps     | 152198    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.3e+19   |\n",
      "|    alpha_mean          | 16.7      |\n",
      "|    alpha_mean_loss     | -3.79e+11 |\n",
      "|    alpha_std           | 16.4      |\n",
      "|    alpha_std_loss      | -0.0143   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 1.3e+19   |\n",
      "|    kl_loss             | 3.79e+11  |\n",
      "|    kl_mean_loss        | 3.79e+11  |\n",
      "|    kl_std_loss         | 0.0143    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 152067    |\n",
      "|    penalty_temperature | 42.9      |\n",
      "|    policy_loss         | 3.37e+10  |\n",
      "|    policy_mean_loss    | 3.37e+10  |\n",
      "|    policy_std_loss     | 52.1      |\n",
      "|    std                 | 1.25e+08  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.3e+19   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 92.9      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 900       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2270      |\n",
      "|    total_timesteps     | 152703    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.35e+19  |\n",
      "|    alpha_mean          | 16.8      |\n",
      "|    alpha_mean_loss     | -3.52e+11 |\n",
      "|    alpha_std           | 16.4      |\n",
      "|    alpha_std_loss      | -0.0144   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 1.35e+19  |\n",
      "|    kl_loss             | 3.52e+11  |\n",
      "|    kl_mean_loss        | 3.52e+11  |\n",
      "|    kl_std_loss         | 0.0145    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 152572    |\n",
      "|    penalty_temperature | 43        |\n",
      "|    policy_loss         | 3.12e+10  |\n",
      "|    policy_mean_loss    | 3.12e+10  |\n",
      "|    policy_std_loss     | 52.2      |\n",
      "|    std                 | 1.31e+08  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.35e+19  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 94.6      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 904       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2276      |\n",
      "|    total_timesteps     | 153168    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.41e+19  |\n",
      "|    alpha_mean          | 16.9      |\n",
      "|    alpha_mean_loss     | -3.66e+11 |\n",
      "|    alpha_std           | 16.5      |\n",
      "|    alpha_std_loss      | -0.0144   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 1.41e+19  |\n",
      "|    kl_loss             | 3.66e+11  |\n",
      "|    kl_mean_loss        | 3.66e+11  |\n",
      "|    kl_std_loss         | 0.0144    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 153022    |\n",
      "|    penalty_temperature | 43.2      |\n",
      "|    policy_loss         | 3.24e+10  |\n",
      "|    policy_mean_loss    | 3.24e+10  |\n",
      "|    policy_std_loss     | 52.3      |\n",
      "|    std                 | 1.36e+08  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.41e+19  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 95.1     |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 908      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 2281     |\n",
      "|    total_timesteps     | 153495   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.45e+19 |\n",
      "|    alpha_mean          | 16.9     |\n",
      "|    alpha_mean_loss     | -4.4e+11 |\n",
      "|    alpha_std           | 16.5     |\n",
      "|    alpha_std_loss      | -0.0142  |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.45e+19 |\n",
      "|    kl_loss             | 4.4e+11  |\n",
      "|    kl_mean_loss        | 4.4e+11  |\n",
      "|    kl_std_loss         | 0.0143   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 153359   |\n",
      "|    penalty_temperature | 43.2     |\n",
      "|    policy_loss         | 3.88e+10 |\n",
      "|    policy_mean_loss    | 3.88e+10 |\n",
      "|    policy_std_loss     | 52.3     |\n",
      "|    std                 | 1.4e+08  |\n",
      "|    temperature         | 6.62     |\n",
      "|    temperature_loss    | 1.45e+19 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 98        |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 912       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2289      |\n",
      "|    total_timesteps     | 154067    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.52e+19  |\n",
      "|    alpha_mean          | 17        |\n",
      "|    alpha_mean_loss     | -4.69e+11 |\n",
      "|    alpha_std           | 16.5      |\n",
      "|    alpha_std_loss      | -0.0142   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 1.52e+19  |\n",
      "|    kl_loss             | 4.69e+11  |\n",
      "|    kl_mean_loss        | 4.69e+11  |\n",
      "|    kl_std_loss         | 0.0142    |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 153871    |\n",
      "|    penalty_temperature | 43.3      |\n",
      "|    policy_loss         | 4.12e+10  |\n",
      "|    policy_mean_loss    | 4.12e+10  |\n",
      "|    policy_std_loss     | 52.4      |\n",
      "|    std                 | 1.46e+08  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.52e+19  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 98.5      |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 916       |\n",
      "|    fps                 | 67        |\n",
      "|    time_elapsed        | 2294      |\n",
      "|    total_timesteps     | 154402    |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | 1.56e+19  |\n",
      "|    alpha_mean          | 17        |\n",
      "|    alpha_mean_loss     | -4.39e+11 |\n",
      "|    alpha_std           | 16.6      |\n",
      "|    alpha_std_loss      | -0.0139   |\n",
      "|    critic_loss         | inf       |\n",
      "|    dual_loss           | 1.56e+19  |\n",
      "|    kl_loss             | 4.39e+11  |\n",
      "|    kl_mean_loss        | 4.39e+11  |\n",
      "|    kl_std_loss         | 0.014     |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 154231    |\n",
      "|    penalty_temperature | 43.4      |\n",
      "|    policy_loss         | 3.84e+10  |\n",
      "|    policy_mean_loss    | 3.84e+10  |\n",
      "|    policy_std_loss     | 52.5      |\n",
      "|    std                 | 1.51e+08  |\n",
      "|    temperature         | 6.62      |\n",
      "|    temperature_loss    | 1.56e+19  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 99.5     |\n",
      "|    ep_rew_mean         | -118     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 920      |\n",
      "|    fps                 | 67       |\n",
      "|    time_elapsed        | 2302     |\n",
      "|    total_timesteps     | 154974   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.63e+19 |\n",
      "|    alpha_mean          | 17.1     |\n",
      "|    alpha_mean_loss     | -3.3e+11 |\n",
      "|    alpha_std           | 16.6     |\n",
      "|    alpha_std_loss      | -0.0137  |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.63e+19 |\n",
      "|    kl_loss             | 3.3e+11  |\n",
      "|    kl_mean_loss        | 3.3e+11  |\n",
      "|    kl_std_loss         | 0.0137   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 154742   |\n",
      "|    penalty_temperature | 43.5     |\n",
      "|    policy_loss         | 2.88e+10 |\n",
      "|    policy_mean_loss    | 2.88e+10 |\n",
      "|    policy_std_loss     | 52.6     |\n",
      "|    std                 | 1.58e+08 |\n",
      "|    temperature         | 6.62     |\n",
      "|    temperature_loss    | 1.63e+19 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m MPO(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     policy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMlpPolicy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     env\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBipedalWalker-v3\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     num_samples\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m2_000_000\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/DESY/stable-baselines3-contrib/sb3_contrib/mpo/mpo.py:373\u001b[0m, in \u001b[0;36mMPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m: SelfMPO,\n\u001b[1;32m    366\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    372\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfMPO:\n\u001b[0;32m--> 373\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    374\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    375\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    376\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    377\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    378\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    379\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m    380\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/stable-baselines3-contrib/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:331\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[39m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    330\u001b[0m         \u001b[39mif\u001b[39;00m gradient_steps \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size, gradient_steps\u001b[39m=\u001b[39;49mgradient_steps)\n\u001b[1;32m    333\u001b[0m callback\u001b[39m.\u001b[39mon_training_end()\n\u001b[1;32m    335\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/DESY/stable-baselines3-contrib/sb3_contrib/mpo/mpo.py:238\u001b[0m, in \u001b[0;36mMPO.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    235\u001b[0m flat_actions \u001b[39m=\u001b[39m merge_first_two_dims(next_action_samples)\n\u001b[1;32m    237\u001b[0m \u001b[39m# Use q1_forward because MPO defaults to using only one critic\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m flat_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcritic_target\u001b[39m.\u001b[39;49mq1_forward(flat_observations, flat_actions)\n\u001b[1;32m    239\u001b[0m flat_next_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic_target\u001b[39m.\u001b[39mq1_forward(flat_next_observations, flat_actions)\n\u001b[1;32m    241\u001b[0m \u001b[39m# Restore sample and batch dimensions\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/stable-baselines3-contrib/lib/python3.9/site-packages/stable_baselines3/common/policies.py:947\u001b[0m, in \u001b[0;36mContinuousCritic.q1_forward\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    946\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_features(obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_extractor)\n\u001b[0;32m--> 947\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_networks[\u001b[39m0\u001b[39;49m](th\u001b[39m.\u001b[39;49mcat([features, actions], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/stable-baselines3-contrib/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/stable-baselines3-contrib/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/stable-baselines3-contrib/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/stable-baselines3-contrib/lib/python3.9/site-packages/torch/nn/modules/activation.py:103\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/stable-baselines3-contrib/lib/python3.9/site-packages/torch/nn/functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[1;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m   1458\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MPO(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=\"BipedalWalker-v3\",\n",
    "    verbose=2,\n",
    "    tensorboard_log=\"./logs\",\n",
    "    epsilon_mean=0.01,\n",
    "    policy_kwargs={\"net_arch\": [256, 256, 256], \"log_std_init\": np.log(0.5)},\n",
    "    batch_size=256,\n",
    "    learning_rate=3e-4,\n",
    "    gamma=0.99,\n",
    "    learning_starts=1_000,\n",
    "    buffer_size=1_000_000,\n",
    "    num_samples=20,\n",
    ")\n",
    "model.learn(total_timesteps=2_000_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable-baselines3-contrib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
