{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sb3_contrib import MPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Creating environment from the given name 'BipedalWalker-v3'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/MPO_11\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 456      |\n",
      "|    ep_rew_mean     | -100     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 6019     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 1825     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 459      |\n",
      "|    ep_rew_mean     | -101     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 6067     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 3671     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 324      |\n",
      "|    ep_rew_mean     | -105     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 6001     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 3892     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 265      |\n",
      "|    ep_rew_mean     | -108     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 5960     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 4237     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 304      |\n",
      "|    ep_rew_mean     | -108     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 5953     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 6080     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 393      |\n",
      "|    ep_rew_mean     | -106     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 6007     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 9430     |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 456      |\n",
      "|    ep_rew_mean         | -107     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 28       |\n",
      "|    fps                 | 472      |\n",
      "|    time_elapsed        | 27       |\n",
      "|    total_timesteps     | 12764    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 16.7     |\n",
      "|    alpha_mean          | 1.42     |\n",
      "|    alpha_std           | 10.7     |\n",
      "|    critic_loss         | 4.66     |\n",
      "|    dual_loss           | -3.28    |\n",
      "|    kl_loss             | 0.0128   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 2750     |\n",
      "|    penalty_temperature | 1.86     |\n",
      "|    policy_loss         | 20       |\n",
      "|    std                 | 0.872    |\n",
      "|    temperature         | 1.22     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 428      |\n",
      "|    ep_rew_mean         | -110     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 32       |\n",
      "|    fps                 | 389      |\n",
      "|    time_elapsed        | 35       |\n",
      "|    total_timesteps     | 13698    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 16.5     |\n",
      "|    alpha_mean          | 1.61     |\n",
      "|    alpha_std           | 10.9     |\n",
      "|    critic_loss         | 11.6     |\n",
      "|    dual_loss           | -3.19    |\n",
      "|    kl_loss             | 0.0152   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 3650     |\n",
      "|    penalty_temperature | 2.04     |\n",
      "|    policy_loss         | 19.7     |\n",
      "|    std                 | 0.851    |\n",
      "|    temperature         | 1.22     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 436      |\n",
      "|    ep_rew_mean         | -111     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 36       |\n",
      "|    fps                 | 293      |\n",
      "|    time_elapsed        | 53       |\n",
      "|    total_timesteps     | 15683    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 15.8     |\n",
      "|    alpha_mean          | 2.1      |\n",
      "|    alpha_std           | 11.2     |\n",
      "|    critic_loss         | 2.35     |\n",
      "|    dual_loss           | -3.28    |\n",
      "|    kl_loss             | 0.0189   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 5650     |\n",
      "|    penalty_temperature | 2.47     |\n",
      "|    policy_loss         | 19.1     |\n",
      "|    std                 | 0.813    |\n",
      "|    temperature         | 1.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 438      |\n",
      "|    ep_rew_mean         | -111     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 40       |\n",
      "|    fps                 | 249      |\n",
      "|    time_elapsed        | 70       |\n",
      "|    total_timesteps     | 17505    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 15.2     |\n",
      "|    alpha_mean          | 2.5      |\n",
      "|    alpha_std           | 11.5     |\n",
      "|    critic_loss         | 2.38     |\n",
      "|    dual_loss           | -3.42    |\n",
      "|    kl_loss             | 0.0206   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 7500     |\n",
      "|    penalty_temperature | 2.86     |\n",
      "|    policy_loss         | 18.6     |\n",
      "|    std                 | 0.787    |\n",
      "|    temperature         | 1.21     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 441      |\n",
      "|    ep_rew_mean         | -110     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 44       |\n",
      "|    fps                 | 222      |\n",
      "|    time_elapsed        | 87       |\n",
      "|    total_timesteps     | 19388    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 15.3     |\n",
      "|    alpha_mean          | 2.89     |\n",
      "|    alpha_std           | 11.7     |\n",
      "|    critic_loss         | 1.11     |\n",
      "|    dual_loss           | -3.06    |\n",
      "|    kl_loss             | 0.0237   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 9350     |\n",
      "|    penalty_temperature | 3.29     |\n",
      "|    policy_loss         | 18.4     |\n",
      "|    std                 | 0.771    |\n",
      "|    temperature         | 1.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 474      |\n",
      "|    ep_rew_mean         | -108     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 48       |\n",
      "|    fps                 | 192      |\n",
      "|    time_elapsed        | 118      |\n",
      "|    total_timesteps     | 22758    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 15.5     |\n",
      "|    alpha_mean          | 3.74     |\n",
      "|    alpha_std           | 11.9     |\n",
      "|    critic_loss         | 2.57     |\n",
      "|    dual_loss           | -2.49    |\n",
      "|    kl_loss             | 0.0348   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 12750    |\n",
      "|    penalty_temperature | 4.13     |\n",
      "|    policy_loss         | 18       |\n",
      "|    std                 | 0.752    |\n",
      "|    temperature         | 1.17     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 511      |\n",
      "|    ep_rew_mean         | -107     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 52       |\n",
      "|    fps                 | 174      |\n",
      "|    time_elapsed        | 152      |\n",
      "|    total_timesteps     | 26578    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 15.7     |\n",
      "|    alpha_mean          | 4.85     |\n",
      "|    alpha_std           | 12.1     |\n",
      "|    critic_loss         | 1.3      |\n",
      "|    dual_loss           | -2.1     |\n",
      "|    kl_loss             | 0.0808   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 16550    |\n",
      "|    penalty_temperature | 5.08     |\n",
      "|    policy_loss         | 17.7     |\n",
      "|    std                 | 0.736    |\n",
      "|    temperature         | 1.12     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 483      |\n",
      "|    ep_rew_mean         | -108     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 56       |\n",
      "|    fps                 | 172      |\n",
      "|    time_elapsed        | 156      |\n",
      "|    total_timesteps     | 27050    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 15.5     |\n",
      "|    alpha_mean          | 4.98     |\n",
      "|    alpha_std           | 12.1     |\n",
      "|    critic_loss         | 4.11     |\n",
      "|    dual_loss           | -2.3     |\n",
      "|    kl_loss             | 0.0929   |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 17000    |\n",
      "|    penalty_temperature | 5.2      |\n",
      "|    policy_loss         | 17.7     |\n",
      "|    std                 | 0.735    |\n",
      "|    temperature         | 1.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 458      |\n",
      "|    ep_rew_mean         | -108     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 60       |\n",
      "|    fps                 | 170      |\n",
      "|    time_elapsed        | 160      |\n",
      "|    total_timesteps     | 27486    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 14.7     |\n",
      "|    alpha_mean          | 5.12     |\n",
      "|    alpha_std           | 12.1     |\n",
      "|    critic_loss         | 10.3     |\n",
      "|    dual_loss           | -3.05    |\n",
      "|    kl_loss             | 0.106    |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 17450    |\n",
      "|    penalty_temperature | 5.31     |\n",
      "|    policy_loss         | 17.7     |\n",
      "|    std                 | 0.733    |\n",
      "|    temperature         | 1.21     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 435      |\n",
      "|    ep_rew_mean         | -108     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 64       |\n",
      "|    fps                 | 169      |\n",
      "|    time_elapsed        | 164      |\n",
      "|    total_timesteps     | 27814    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 14.2     |\n",
      "|    alpha_mean          | 5.24     |\n",
      "|    alpha_std           | 12.1     |\n",
      "|    critic_loss         | 16.8     |\n",
      "|    dual_loss           | -3.56    |\n",
      "|    kl_loss             | 0.109    |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 17800    |\n",
      "|    penalty_temperature | 5.4      |\n",
      "|    policy_loss         | 17.6     |\n",
      "|    std                 | 0.732    |\n",
      "|    temperature         | 1.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 428      |\n",
      "|    ep_rew_mean         | -108     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 68       |\n",
      "|    fps                 | 165      |\n",
      "|    time_elapsed        | 175      |\n",
      "|    total_timesteps     | 29094    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.38     |\n",
      "|    alpha_mean          | 5.61     |\n",
      "|    alpha_std           | 12.3     |\n",
      "|    critic_loss         | 796      |\n",
      "|    dual_loss           | -13.8    |\n",
      "|    kl_loss             | 0.174    |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 19050    |\n",
      "|    penalty_temperature | 5.72     |\n",
      "|    policy_loss         | 18       |\n",
      "|    std                 | 0.737    |\n",
      "|    temperature         | 1.82     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 430      |\n",
      "|    ep_rew_mean         | -108     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 72       |\n",
      "|    fps                 | 160      |\n",
      "|    time_elapsed        | 192      |\n",
      "|    total_timesteps     | 30987    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -33      |\n",
      "|    alpha_mean          | 6.25     |\n",
      "|    alpha_std           | 13.2     |\n",
      "|    critic_loss         | 5.84e+04 |\n",
      "|    dual_loss           | -53.2    |\n",
      "|    kl_loss             | 0.389    |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 20950    |\n",
      "|    penalty_temperature | 6.27     |\n",
      "|    policy_loss         | 19.8     |\n",
      "|    std                 | 0.781    |\n",
      "|    temperature         | 2.71     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 435      |\n",
      "|    ep_rew_mean         | -108     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 76       |\n",
      "|    fps                 | 156      |\n",
      "|    time_elapsed        | 211      |\n",
      "|    total_timesteps     | 33053    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -147     |\n",
      "|    alpha_mean          | 6.9      |\n",
      "|    alpha_std           | 13.9     |\n",
      "|    critic_loss         | 5.77e+07 |\n",
      "|    dual_loss           | -168     |\n",
      "|    kl_loss             | 0.443    |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 23050    |\n",
      "|    penalty_temperature | 7.04     |\n",
      "|    policy_loss         | 21.3     |\n",
      "|    std                 | 0.861    |\n",
      "|    temperature         | 3.52     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 417      |\n",
      "|    ep_rew_mean         | -108     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 80       |\n",
      "|    fps                 | 155      |\n",
      "|    time_elapsed        | 213      |\n",
      "|    total_timesteps     | 33345    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -7.75    |\n",
      "|    alpha_mean          | 6.96     |\n",
      "|    alpha_std           | 13.9     |\n",
      "|    critic_loss         | 9.67e+07 |\n",
      "|    dual_loss           | -29.9    |\n",
      "|    kl_loss             | 0.521    |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 23300    |\n",
      "|    penalty_temperature | 7.14     |\n",
      "|    policy_loss         | 21.6     |\n",
      "|    std                 | 0.873    |\n",
      "|    temperature         | 3.61     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 401      |\n",
      "|    ep_rew_mean         | -108     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 84       |\n",
      "|    fps                 | 155      |\n",
      "|    time_elapsed        | 217      |\n",
      "|    total_timesteps     | 33668    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -14      |\n",
      "|    alpha_mean          | 7.08     |\n",
      "|    alpha_std           | 14       |\n",
      "|    critic_loss         | 2.42e+08 |\n",
      "|    dual_loss           | -36.8    |\n",
      "|    kl_loss             | 0.819    |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 23650    |\n",
      "|    penalty_temperature | 7.27     |\n",
      "|    policy_loss         | 21.9     |\n",
      "|    std                 | 0.888    |\n",
      "|    temperature         | 3.72     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 387      |\n",
      "|    ep_rew_mean         | -108     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 88       |\n",
      "|    fps                 | 154      |\n",
      "|    time_elapsed        | 220      |\n",
      "|    total_timesteps     | 34059    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.24e+03 |\n",
      "|    alpha_mean          | 7.2      |\n",
      "|    alpha_std           | 14.2     |\n",
      "|    critic_loss         | 2.42e+08 |\n",
      "|    dual_loss           | 1.21e+03 |\n",
      "|    kl_loss             | 0.778    |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 24050    |\n",
      "|    penalty_temperature | 7.41     |\n",
      "|    policy_loss         | 22.6     |\n",
      "|    std                 | 0.91     |\n",
      "|    temperature         | 3.85     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 374      |\n",
      "|    ep_rew_mean         | -109     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 92       |\n",
      "|    fps                 | 153      |\n",
      "|    time_elapsed        | 223      |\n",
      "|    total_timesteps     | 34371    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.73e+03 |\n",
      "|    alpha_mean          | 7.29     |\n",
      "|    alpha_std           | 14.2     |\n",
      "|    critic_loss         | 6.24e+08 |\n",
      "|    dual_loss           | 1.71e+03 |\n",
      "|    kl_loss             | 0.71     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 24350    |\n",
      "|    penalty_temperature | 7.52     |\n",
      "|    policy_loss         | 23       |\n",
      "|    std                 | 0.928    |\n",
      "|    temperature         | 3.94     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 362      |\n",
      "|    ep_rew_mean         | -108     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 96       |\n",
      "|    fps                 | 153      |\n",
      "|    time_elapsed        | 226      |\n",
      "|    total_timesteps     | 34769    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.77e+03 |\n",
      "|    alpha_mean          | 7.41     |\n",
      "|    alpha_std           | 14.4     |\n",
      "|    critic_loss         | 4.51e+08 |\n",
      "|    dual_loss           | 4.74e+03 |\n",
      "|    kl_loss             | 0.896    |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 24750    |\n",
      "|    penalty_temperature | 7.66     |\n",
      "|    policy_loss         | 23.4     |\n",
      "|    std                 | 0.952    |\n",
      "|    temperature         | 4.07     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 351      |\n",
      "|    ep_rew_mean         | -108     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 100      |\n",
      "|    fps                 | 152      |\n",
      "|    time_elapsed        | 229      |\n",
      "|    total_timesteps     | 35072    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 7.26e+03 |\n",
      "|    alpha_mean          | 7.5      |\n",
      "|    alpha_std           | 14.4     |\n",
      "|    critic_loss         | 5.38e+08 |\n",
      "|    dual_loss           | 7.23e+03 |\n",
      "|    kl_loss             | 1.34     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 25050    |\n",
      "|    penalty_temperature | 7.76     |\n",
      "|    policy_loss         | 23.8     |\n",
      "|    std                 | 0.97     |\n",
      "|    temperature         | 4.16     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 337      |\n",
      "|    ep_rew_mean         | -109     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 104      |\n",
      "|    fps                 | 152      |\n",
      "|    time_elapsed        | 233      |\n",
      "|    total_timesteps     | 35494    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.05e+04 |\n",
      "|    alpha_mean          | 7.61     |\n",
      "|    alpha_std           | 14.6     |\n",
      "|    critic_loss         | 1.06e+09 |\n",
      "|    dual_loss           | 1.05e+04 |\n",
      "|    kl_loss             | 1.06     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 25450    |\n",
      "|    penalty_temperature | 7.9      |\n",
      "|    policy_loss         | 24.6     |\n",
      "|    std                 | 1        |\n",
      "|    temperature         | 4.28     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 321      |\n",
      "|    ep_rew_mean         | -109     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 108      |\n",
      "|    fps                 | 151      |\n",
      "|    time_elapsed        | 235      |\n",
      "|    total_timesteps     | 35778    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.42e+04 |\n",
      "|    alpha_mean          | 7.68     |\n",
      "|    alpha_std           | 14.7     |\n",
      "|    critic_loss         | 9.14e+08 |\n",
      "|    dual_loss           | 1.41e+04 |\n",
      "|    kl_loss             | 1.64     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 25750    |\n",
      "|    penalty_temperature | 8        |\n",
      "|    policy_loss         | 25.1     |\n",
      "|    std                 | 1.02     |\n",
      "|    temperature         | 4.37     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 321      |\n",
      "|    ep_rew_mean         | -109     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 112      |\n",
      "|    fps                 | 151      |\n",
      "|    time_elapsed        | 238      |\n",
      "|    total_timesteps     | 36039    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.74e+04 |\n",
      "|    alpha_mean          | 7.76     |\n",
      "|    alpha_std           | 14.8     |\n",
      "|    critic_loss         | 1.65e+09 |\n",
      "|    dual_loss           | 1.74e+04 |\n",
      "|    kl_loss             | 1.31     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 26000    |\n",
      "|    penalty_temperature | 8.09     |\n",
      "|    policy_loss         | 25.3     |\n",
      "|    std                 | 1.04     |\n",
      "|    temperature         | 4.45     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 322      |\n",
      "|    ep_rew_mean         | -109     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 116      |\n",
      "|    fps                 | 150      |\n",
      "|    time_elapsed        | 241      |\n",
      "|    total_timesteps     | 36410    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.79e+04 |\n",
      "|    alpha_mean          | 7.85     |\n",
      "|    alpha_std           | 14.9     |\n",
      "|    critic_loss         | 7.42e+09 |\n",
      "|    dual_loss           | 1.79e+04 |\n",
      "|    kl_loss             | 2.41     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 26400    |\n",
      "|    penalty_temperature | 8.22     |\n",
      "|    policy_loss         | 26.1     |\n",
      "|    std                 | 1.08     |\n",
      "|    temperature         | 4.57     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 306      |\n",
      "|    ep_rew_mean         | -109     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 120      |\n",
      "|    fps                 | 150      |\n",
      "|    time_elapsed        | 243      |\n",
      "|    total_timesteps     | 36646    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.29e+04 |\n",
      "|    alpha_mean          | 7.9      |\n",
      "|    alpha_std           | 15       |\n",
      "|    critic_loss         | 8.66e+09 |\n",
      "|    dual_loss           | 2.29e+04 |\n",
      "|    kl_loss             | 1.34     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 26600    |\n",
      "|    penalty_temperature | 8.29     |\n",
      "|    policy_loss         | 26.2     |\n",
      "|    std                 | 1.09     |\n",
      "|    temperature         | 4.63     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 274      |\n",
      "|    ep_rew_mean         | -110     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 124      |\n",
      "|    fps                 | 149      |\n",
      "|    time_elapsed        | 245      |\n",
      "|    total_timesteps     | 36872    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.75e+04 |\n",
      "|    alpha_mean          | 7.95     |\n",
      "|    alpha_std           | 15.1     |\n",
      "|    critic_loss         | 1.21e+10 |\n",
      "|    dual_loss           | 2.75e+04 |\n",
      "|    kl_loss             | 1.55     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 26850    |\n",
      "|    penalty_temperature | 8.37     |\n",
      "|    policy_loss         | 26.3     |\n",
      "|    std                 | 1.11     |\n",
      "|    temperature         | 4.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 244      |\n",
      "|    ep_rew_mean         | -110     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 128      |\n",
      "|    fps                 | 149      |\n",
      "|    time_elapsed        | 248      |\n",
      "|    total_timesteps     | 37144    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.61e+04 |\n",
      "|    alpha_mean          | 8        |\n",
      "|    alpha_std           | 15.1     |\n",
      "|    critic_loss         | 2.21e+10 |\n",
      "|    dual_loss           | 3.61e+04 |\n",
      "|    kl_loss             | 1.82     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 27100    |\n",
      "|    penalty_temperature | 8.45     |\n",
      "|    policy_loss         | 26.8     |\n",
      "|    std                 | 1.14     |\n",
      "|    temperature         | 4.77     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 237      |\n",
      "|    ep_rew_mean         | -109     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 132      |\n",
      "|    fps                 | 149      |\n",
      "|    time_elapsed        | 250      |\n",
      "|    total_timesteps     | 37378    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.37e+04 |\n",
      "|    alpha_mean          | 8.06     |\n",
      "|    alpha_std           | 15.2     |\n",
      "|    critic_loss         | 4.46e+10 |\n",
      "|    dual_loss           | 4.37e+04 |\n",
      "|    kl_loss             | 3.01     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 27350    |\n",
      "|    penalty_temperature | 8.53     |\n",
      "|    policy_loss         | 27.4     |\n",
      "|    std                 | 1.16     |\n",
      "|    temperature         | 4.85     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 219      |\n",
      "|    ep_rew_mean         | -109     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 136      |\n",
      "|    fps                 | 148      |\n",
      "|    time_elapsed        | 252      |\n",
      "|    total_timesteps     | 37632    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.65e+04 |\n",
      "|    alpha_mean          | 8.11     |\n",
      "|    alpha_std           | 15.2     |\n",
      "|    critic_loss         | 3.53e+10 |\n",
      "|    dual_loss           | 4.64e+04 |\n",
      "|    kl_loss             | 2.24     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 27600    |\n",
      "|    penalty_temperature | 8.61     |\n",
      "|    policy_loss         | 27.4     |\n",
      "|    std                 | 1.18     |\n",
      "|    temperature         | 4.92     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 204      |\n",
      "|    ep_rew_mean         | -109     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 140      |\n",
      "|    fps                 | 148      |\n",
      "|    time_elapsed        | 254      |\n",
      "|    total_timesteps     | 37855    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.7e+04  |\n",
      "|    alpha_mean          | 8.17     |\n",
      "|    alpha_std           | 15.3     |\n",
      "|    critic_loss         | 6.7e+10  |\n",
      "|    dual_loss           | 4.69e+04 |\n",
      "|    kl_loss             | 2.84     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 27850    |\n",
      "|    penalty_temperature | 8.69     |\n",
      "|    policy_loss         | 27.7     |\n",
      "|    std                 | 1.2      |\n",
      "|    temperature         | 5        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 187      |\n",
      "|    ep_rew_mean         | -110     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 144      |\n",
      "|    fps                 | 148      |\n",
      "|    time_elapsed        | 256      |\n",
      "|    total_timesteps     | 38045    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.43e+04 |\n",
      "|    alpha_mean          | 8.21     |\n",
      "|    alpha_std           | 15.3     |\n",
      "|    critic_loss         | 6.73e+10 |\n",
      "|    dual_loss           | 5.43e+04 |\n",
      "|    kl_loss             | 2.78     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 28000    |\n",
      "|    penalty_temperature | 8.74     |\n",
      "|    policy_loss         | 27.9     |\n",
      "|    std                 | 1.21     |\n",
      "|    temperature         | 5.04     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 156      |\n",
      "|    ep_rew_mean         | -111     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 148      |\n",
      "|    fps                 | 148      |\n",
      "|    time_elapsed        | 258      |\n",
      "|    total_timesteps     | 38325    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.19e+04 |\n",
      "|    alpha_mean          | 8.27     |\n",
      "|    alpha_std           | 15.4     |\n",
      "|    critic_loss         | 8.94e+10 |\n",
      "|    dual_loss           | 6.18e+04 |\n",
      "|    kl_loss             | 2.53     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 28300    |\n",
      "|    penalty_temperature | 8.84     |\n",
      "|    policy_loss         | 28.1     |\n",
      "|    std                 | 1.24     |\n",
      "|    temperature         | 5.12     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 120      |\n",
      "|    ep_rew_mean         | -112     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 152      |\n",
      "|    fps                 | 147      |\n",
      "|    time_elapsed        | 261      |\n",
      "|    total_timesteps     | 38591    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 7.5e+04  |\n",
      "|    alpha_mean          | 8.31     |\n",
      "|    alpha_std           | 15.4     |\n",
      "|    critic_loss         | 1.13e+11 |\n",
      "|    dual_loss           | 7.49e+04 |\n",
      "|    kl_loss             | 2.71     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 28550    |\n",
      "|    penalty_temperature | 8.92     |\n",
      "|    policy_loss         | 28.4     |\n",
      "|    std                 | 1.26     |\n",
      "|    temperature         | 5.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 117      |\n",
      "|    ep_rew_mean         | -112     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 156      |\n",
      "|    fps                 | 147      |\n",
      "|    time_elapsed        | 263      |\n",
      "|    total_timesteps     | 38794    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 8.08e+04 |\n",
      "|    alpha_mean          | 8.35     |\n",
      "|    alpha_std           | 15.5     |\n",
      "|    critic_loss         | 1.71e+11 |\n",
      "|    dual_loss           | 8.08e+04 |\n",
      "|    kl_loss             | 5.55     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 28750    |\n",
      "|    penalty_temperature | 8.98     |\n",
      "|    policy_loss         | 29.4     |\n",
      "|    std                 | 1.28     |\n",
      "|    temperature         | 5.25     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 115      |\n",
      "|    ep_rew_mean         | -112     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 160      |\n",
      "|    fps                 | 147      |\n",
      "|    time_elapsed        | 264      |\n",
      "|    total_timesteps     | 38971    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.04e+05 |\n",
      "|    alpha_mean          | 8.39     |\n",
      "|    alpha_std           | 15.5     |\n",
      "|    critic_loss         | 2.2e+11  |\n",
      "|    dual_loss           | 1.04e+05 |\n",
      "|    kl_loss             | 8.81     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 28950    |\n",
      "|    penalty_temperature | 9.05     |\n",
      "|    policy_loss         | 30.3     |\n",
      "|    std                 | 1.3      |\n",
      "|    temperature         | 5.31     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 114      |\n",
      "|    ep_rew_mean         | -112     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 164      |\n",
      "|    fps                 | 146      |\n",
      "|    time_elapsed        | 266      |\n",
      "|    total_timesteps     | 39176    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.27e+05 |\n",
      "|    alpha_mean          | 8.44     |\n",
      "|    alpha_std           | 15.6     |\n",
      "|    critic_loss         | 1.68e+11 |\n",
      "|    dual_loss           | 1.27e+05 |\n",
      "|    kl_loss             | 4.21     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 29150    |\n",
      "|    penalty_temperature | 9.11     |\n",
      "|    policy_loss         | 29.5     |\n",
      "|    std                 | 1.32     |\n",
      "|    temperature         | 5.37     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 103      |\n",
      "|    ep_rew_mean         | -112     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 168      |\n",
      "|    fps                 | 146      |\n",
      "|    time_elapsed        | 268      |\n",
      "|    total_timesteps     | 39392    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.31e+05 |\n",
      "|    alpha_mean          | 8.47     |\n",
      "|    alpha_std           | 15.6     |\n",
      "|    critic_loss         | 2.62e+11 |\n",
      "|    dual_loss           | 1.31e+05 |\n",
      "|    kl_loss             | 5.29     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 29350    |\n",
      "|    penalty_temperature | 9.18     |\n",
      "|    policy_loss         | 29.9     |\n",
      "|    std                 | 1.34     |\n",
      "|    temperature         | 5.42     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 87.2     |\n",
      "|    ep_rew_mean         | -113     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 172      |\n",
      "|    fps                 | 146      |\n",
      "|    time_elapsed        | 271      |\n",
      "|    total_timesteps     | 39702    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.51e+05 |\n",
      "|    alpha_mean          | 8.52     |\n",
      "|    alpha_std           | 15.7     |\n",
      "|    critic_loss         | 4.23e+11 |\n",
      "|    dual_loss           | 1.51e+05 |\n",
      "|    kl_loss             | 4.9      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 29700    |\n",
      "|    penalty_temperature | 9.29     |\n",
      "|    policy_loss         | 30.1     |\n",
      "|    std                 | 1.37     |\n",
      "|    temperature         | 5.51     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 69.4     |\n",
      "|    ep_rew_mean         | -113     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 176      |\n",
      "|    fps                 | 146      |\n",
      "|    time_elapsed        | 273      |\n",
      "|    total_timesteps     | 39991    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.9e+05  |\n",
      "|    alpha_mean          | 8.56     |\n",
      "|    alpha_std           | 15.8     |\n",
      "|    critic_loss         | 4.61e+11 |\n",
      "|    dual_loss           | 1.9e+05  |\n",
      "|    kl_loss             | 6.49     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 29950    |\n",
      "|    penalty_temperature | 9.37     |\n",
      "|    policy_loss         | 30.7     |\n",
      "|    std                 | 1.39     |\n",
      "|    temperature         | 5.57     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 71.7     |\n",
      "|    ep_rew_mean         | -114     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 180      |\n",
      "|    fps                 | 145      |\n",
      "|    time_elapsed        | 278      |\n",
      "|    total_timesteps     | 40510    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.79e+05 |\n",
      "|    alpha_mean          | 8.66     |\n",
      "|    alpha_std           | 15.9     |\n",
      "|    critic_loss         | 9.97e+11 |\n",
      "|    dual_loss           | 1.79e+05 |\n",
      "|    kl_loss             | 11       |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 30500    |\n",
      "|    penalty_temperature | 9.55     |\n",
      "|    policy_loss         | 32.1     |\n",
      "|    std                 | 1.44     |\n",
      "|    temperature         | 5.64     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 72.6     |\n",
      "|    ep_rew_mean         | -114     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 184      |\n",
      "|    fps                 | 144      |\n",
      "|    time_elapsed        | 282      |\n",
      "|    total_timesteps     | 40930    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.5e+05  |\n",
      "|    alpha_mean          | 8.74     |\n",
      "|    alpha_std           | 16       |\n",
      "|    critic_loss         | 1.44e+12 |\n",
      "|    dual_loss           | 2.5e+05  |\n",
      "|    kl_loss             | 6.9      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 30900    |\n",
      "|    penalty_temperature | 9.68     |\n",
      "|    policy_loss         | 31.4     |\n",
      "|    std                 | 1.46     |\n",
      "|    temperature         | 5.65     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 73.4     |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 188      |\n",
      "|    fps                 | 144      |\n",
      "|    time_elapsed        | 286      |\n",
      "|    total_timesteps     | 41401    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.84e+05 |\n",
      "|    alpha_mean          | 8.83     |\n",
      "|    alpha_std           | 16.1     |\n",
      "|    critic_loss         | 2.32e+12 |\n",
      "|    dual_loss           | 2.84e+05 |\n",
      "|    kl_loss             | 8.69     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 31400    |\n",
      "|    penalty_temperature | 9.83     |\n",
      "|    policy_loss         | 32       |\n",
      "|    std                 | 1.49     |\n",
      "|    temperature         | 5.66     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 74.8     |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 192      |\n",
      "|    fps                 | 143      |\n",
      "|    time_elapsed        | 290      |\n",
      "|    total_timesteps     | 41851    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.68e+05 |\n",
      "|    alpha_mean          | 8.92     |\n",
      "|    alpha_std           | 16.2     |\n",
      "|    critic_loss         | 4.72e+12 |\n",
      "|    dual_loss           | 2.68e+05 |\n",
      "|    kl_loss             | 7.9      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 31850    |\n",
      "|    penalty_temperature | 9.97     |\n",
      "|    policy_loss         | 31.9     |\n",
      "|    std                 | 1.52     |\n",
      "|    temperature         | 5.67     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 74.8     |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 196      |\n",
      "|    fps                 | 143      |\n",
      "|    time_elapsed        | 294      |\n",
      "|    total_timesteps     | 42244    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.47e+05 |\n",
      "|    alpha_mean          | 8.99     |\n",
      "|    alpha_std           | 16.2     |\n",
      "|    critic_loss         | 8.1e+12  |\n",
      "|    dual_loss           | 2.47e+05 |\n",
      "|    kl_loss             | 8.68     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 32200    |\n",
      "|    penalty_temperature | 10.1     |\n",
      "|    policy_loss         | 32.2     |\n",
      "|    std                 | 1.54     |\n",
      "|    temperature         | 5.68     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 75.9     |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 200      |\n",
      "|    fps                 | 143      |\n",
      "|    time_elapsed        | 298      |\n",
      "|    total_timesteps     | 42665    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.31e+05 |\n",
      "|    alpha_mean          | 9.08     |\n",
      "|    alpha_std           | 16.3     |\n",
      "|    critic_loss         | 1.13e+13 |\n",
      "|    dual_loss           | 3.31e+05 |\n",
      "|    kl_loss             | 7.05     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 32650    |\n",
      "|    penalty_temperature | 10.2     |\n",
      "|    policy_loss         | 32       |\n",
      "|    std                 | 1.56     |\n",
      "|    temperature         | 5.69     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 74.2      |\n",
      "|    ep_rew_mean         | -116      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 204       |\n",
      "|    fps                 | 142       |\n",
      "|    time_elapsed        | 300       |\n",
      "|    total_timesteps     | 42916     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -6.65e+03 |\n",
      "|    alpha_mean          | 9.13      |\n",
      "|    alpha_std           | 16.3      |\n",
      "|    critic_loss         | 2.35e+13  |\n",
      "|    dual_loss           | -6.69e+03 |\n",
      "|    kl_loss             | 12.1      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 32900     |\n",
      "|    penalty_temperature | 10.3      |\n",
      "|    policy_loss         | 33.2      |\n",
      "|    std                 | 1.57      |\n",
      "|    temperature         | 5.68      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 75.2     |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 208      |\n",
      "|    fps                 | 142      |\n",
      "|    time_elapsed        | 303      |\n",
      "|    total_timesteps     | 43301    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.14e+04 |\n",
      "|    alpha_mean          | 9.22     |\n",
      "|    alpha_std           | 16.4     |\n",
      "|    critic_loss         | 3.01e+13 |\n",
      "|    dual_loss           | 3.14e+04 |\n",
      "|    kl_loss             | 13.5     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 33300    |\n",
      "|    penalty_temperature | 10.4     |\n",
      "|    policy_loss         | 33.9     |\n",
      "|    std                 | 1.6      |\n",
      "|    temperature         | 5.68     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 75.5     |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 212      |\n",
      "|    fps                 | 142      |\n",
      "|    time_elapsed        | 306      |\n",
      "|    total_timesteps     | 43592    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.08e+05 |\n",
      "|    alpha_mean          | 9.27     |\n",
      "|    alpha_std           | 16.4     |\n",
      "|    critic_loss         | 3.81e+13 |\n",
      "|    dual_loss           | 1.07e+05 |\n",
      "|    kl_loss             | 12.9     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 33550    |\n",
      "|    penalty_temperature | 10.5     |\n",
      "|    policy_loss         | 33.8     |\n",
      "|    std                 | 1.61     |\n",
      "|    temperature         | 5.68     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 74.4      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 216       |\n",
      "|    fps                 | 142       |\n",
      "|    time_elapsed        | 308       |\n",
      "|    total_timesteps     | 43850     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.89e+05 |\n",
      "|    alpha_mean          | 9.33      |\n",
      "|    alpha_std           | 16.5      |\n",
      "|    critic_loss         | 5.36e+13  |\n",
      "|    dual_loss           | -1.89e+05 |\n",
      "|    kl_loss             | 11.5      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 33800     |\n",
      "|    penalty_temperature | 10.5      |\n",
      "|    policy_loss         | 33.7      |\n",
      "|    std                 | 1.63      |\n",
      "|    temperature         | 5.68      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 74.6      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 220       |\n",
      "|    fps                 | 141       |\n",
      "|    time_elapsed        | 311       |\n",
      "|    total_timesteps     | 44108     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.26e+05 |\n",
      "|    alpha_mean          | 9.39      |\n",
      "|    alpha_std           | 16.5      |\n",
      "|    critic_loss         | 7.03e+13  |\n",
      "|    dual_loss           | -2.26e+05 |\n",
      "|    kl_loss             | 10.7      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 34100     |\n",
      "|    penalty_temperature | 10.6      |\n",
      "|    policy_loss         | 33.7      |\n",
      "|    std                 | 1.64      |\n",
      "|    temperature         | 5.69      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 76.3      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 224       |\n",
      "|    fps                 | 141       |\n",
      "|    time_elapsed        | 314       |\n",
      "|    total_timesteps     | 44503     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -3.05e+05 |\n",
      "|    alpha_mean          | 9.48      |\n",
      "|    alpha_std           | 16.6      |\n",
      "|    critic_loss         | 1.09e+14  |\n",
      "|    dual_loss           | -3.05e+05 |\n",
      "|    kl_loss             | 15.7      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 34500     |\n",
      "|    penalty_temperature | 10.8      |\n",
      "|    policy_loss         | 35.1      |\n",
      "|    std                 | 1.67      |\n",
      "|    temperature         | 5.69      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 79.2      |\n",
      "|    ep_rew_mean         | -117      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 228       |\n",
      "|    fps                 | 140       |\n",
      "|    time_elapsed        | 319       |\n",
      "|    total_timesteps     | 45059     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.09e+06 |\n",
      "|    alpha_mean          | 9.61      |\n",
      "|    alpha_std           | 16.8      |\n",
      "|    critic_loss         | 1.82e+14  |\n",
      "|    dual_loss           | -1.09e+06 |\n",
      "|    kl_loss             | 14.6      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 35050     |\n",
      "|    penalty_temperature | 10.9      |\n",
      "|    policy_loss         | 35.3      |\n",
      "|    std                 | 1.71      |\n",
      "|    temperature         | 5.69      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 81.5      |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 232       |\n",
      "|    fps                 | 140       |\n",
      "|    time_elapsed        | 323       |\n",
      "|    total_timesteps     | 45525     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.53e+06 |\n",
      "|    alpha_mean          | 9.72      |\n",
      "|    alpha_std           | 16.9      |\n",
      "|    critic_loss         | 2.87e+14  |\n",
      "|    dual_loss           | -1.53e+06 |\n",
      "|    kl_loss             | 20.6      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 35500     |\n",
      "|    penalty_temperature | 11        |\n",
      "|    policy_loss         | 36.9      |\n",
      "|    std                 | 1.74      |\n",
      "|    temperature         | 5.69      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 82.8      |\n",
      "|    ep_rew_mean         | -118      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 236       |\n",
      "|    fps                 | 140       |\n",
      "|    time_elapsed        | 327       |\n",
      "|    total_timesteps     | 45911     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -3.22e+06 |\n",
      "|    alpha_mean          | 9.83      |\n",
      "|    alpha_std           | 17        |\n",
      "|    critic_loss         | 4.71e+14  |\n",
      "|    dual_loss           | -3.22e+06 |\n",
      "|    kl_loss             | 25.4      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 35900     |\n",
      "|    penalty_temperature | 11.2      |\n",
      "|    policy_loss         | 38.3      |\n",
      "|    std                 | 1.78      |\n",
      "|    temperature         | 5.69      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 84.4      |\n",
      "|    ep_rew_mean         | -119      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 240       |\n",
      "|    fps                 | 140       |\n",
      "|    time_elapsed        | 330       |\n",
      "|    total_timesteps     | 46292     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -4.36e+06 |\n",
      "|    alpha_mean          | 9.92      |\n",
      "|    alpha_std           | 17.1      |\n",
      "|    critic_loss         | 6.05e+14  |\n",
      "|    dual_loss           | -4.36e+06 |\n",
      "|    kl_loss             | 26.6      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 36250     |\n",
      "|    penalty_temperature | 11.3      |\n",
      "|    policy_loss         | 38.8      |\n",
      "|    std                 | 1.81      |\n",
      "|    temperature         | 5.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 87.5      |\n",
      "|    ep_rew_mean         | -119      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 244       |\n",
      "|    fps                 | 139       |\n",
      "|    time_elapsed        | 334       |\n",
      "|    total_timesteps     | 46797     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -5.59e+06 |\n",
      "|    alpha_mean          | 10        |\n",
      "|    alpha_std           | 17.2      |\n",
      "|    critic_loss         | 7.71e+14  |\n",
      "|    dual_loss           | -5.59e+06 |\n",
      "|    kl_loss             | 20.3      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 36750     |\n",
      "|    penalty_temperature | 11.4      |\n",
      "|    policy_loss         | 37.9      |\n",
      "|    std                 | 1.85      |\n",
      "|    temperature         | 5.71      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 103       |\n",
      "|    ep_rew_mean         | -120      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 248       |\n",
      "|    fps                 | 138       |\n",
      "|    time_elapsed        | 351       |\n",
      "|    total_timesteps     | 48647     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.15e+07 |\n",
      "|    alpha_mean          | 10.5      |\n",
      "|    alpha_std           | 17.7      |\n",
      "|    critic_loss         | 2.96e+15  |\n",
      "|    dual_loss           | -1.15e+07 |\n",
      "|    kl_loss             | 25.9      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 38600     |\n",
      "|    penalty_temperature | 12        |\n",
      "|    policy_loss         | 40.4      |\n",
      "|    std                 | 2.04      |\n",
      "|    temperature         | 5.71      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 103      |\n",
      "|    ep_rew_mean         | -120     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 252      |\n",
      "|    fps                 | 138      |\n",
      "|    time_elapsed        | 354      |\n",
      "|    total_timesteps     | 48886    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -1.2e+07 |\n",
      "|    alpha_mean          | 10.5     |\n",
      "|    alpha_std           | 17.8     |\n",
      "|    critic_loss         | 3.18e+15 |\n",
      "|    dual_loss           | -1.2e+07 |\n",
      "|    kl_loss             | 25.7     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 38850    |\n",
      "|    penalty_temperature | 12.1     |\n",
      "|    policy_loss         | 40.6     |\n",
      "|    std                 | 2.07     |\n",
      "|    temperature         | 5.71     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 134       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 256       |\n",
      "|    fps                 | 135       |\n",
      "|    time_elapsed        | 384       |\n",
      "|    total_timesteps     | 52205     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -4.66e+07 |\n",
      "|    alpha_mean          | 11.4      |\n",
      "|    alpha_std           | 18.4      |\n",
      "|    critic_loss         | 3.03e+16  |\n",
      "|    dual_loss           | -4.66e+07 |\n",
      "|    kl_loss             | 36        |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 42200     |\n",
      "|    penalty_temperature | 13.2      |\n",
      "|    policy_loss         | 44.3      |\n",
      "|    std                 | 2.43      |\n",
      "|    temperature         | 5.71      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 135       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 260       |\n",
      "|    fps                 | 135       |\n",
      "|    time_elapsed        | 386       |\n",
      "|    total_timesteps     | 52474     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -5.36e+07 |\n",
      "|    alpha_mean          | 11.4      |\n",
      "|    alpha_std           | 18.5      |\n",
      "|    critic_loss         | 3.57e+16  |\n",
      "|    dual_loss           | -5.36e+07 |\n",
      "|    kl_loss             | 41.5      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 42450     |\n",
      "|    penalty_temperature | 13.2      |\n",
      "|    policy_loss         | 45.3      |\n",
      "|    std                 | 2.45      |\n",
      "|    temperature         | 5.71      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 136       |\n",
      "|    ep_rew_mean         | -121      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 264       |\n",
      "|    fps                 | 135       |\n",
      "|    time_elapsed        | 389       |\n",
      "|    total_timesteps     | 52787     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -5.58e+07 |\n",
      "|    alpha_mean          | 11.5      |\n",
      "|    alpha_std           | 18.5      |\n",
      "|    critic_loss         | 4.03e+16  |\n",
      "|    dual_loss           | -5.58e+07 |\n",
      "|    kl_loss             | 44.8      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 42750     |\n",
      "|    penalty_temperature | 13.3      |\n",
      "|    policy_loss         | 46        |\n",
      "|    std                 | 2.48      |\n",
      "|    temperature         | 5.71      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 138       |\n",
      "|    ep_rew_mean         | -122      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 268       |\n",
      "|    fps                 | 135       |\n",
      "|    time_elapsed        | 392       |\n",
      "|    total_timesteps     | 53145     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -7.05e+07 |\n",
      "|    alpha_mean          | 11.6      |\n",
      "|    alpha_std           | 18.6      |\n",
      "|    critic_loss         | 4.86e+16  |\n",
      "|    dual_loss           | -7.05e+07 |\n",
      "|    kl_loss             | 40.5      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 43100     |\n",
      "|    penalty_temperature | 13.5      |\n",
      "|    policy_loss         | 45.3      |\n",
      "|    std                 | 2.52      |\n",
      "|    temperature         | 5.71      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 153       |\n",
      "|    ep_rew_mean         | -122      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 272       |\n",
      "|    fps                 | 134       |\n",
      "|    time_elapsed        | 409       |\n",
      "|    total_timesteps     | 54995     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.06e+08 |\n",
      "|    alpha_mean          | 12.1      |\n",
      "|    alpha_std           | 19        |\n",
      "|    critic_loss         | 9.51e+16  |\n",
      "|    dual_loss           | -1.06e+08 |\n",
      "|    kl_loss             | 51.2      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 44950     |\n",
      "|    penalty_temperature | 14.1      |\n",
      "|    policy_loss         | 47.8      |\n",
      "|    std                 | 2.71      |\n",
      "|    temperature         | 5.71      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 154       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 276       |\n",
      "|    fps                 | 134       |\n",
      "|    time_elapsed        | 412       |\n",
      "|    total_timesteps     | 55351     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.14e+08 |\n",
      "|    alpha_mean          | 12.2      |\n",
      "|    alpha_std           | 19.2      |\n",
      "|    critic_loss         | 1.24e+17  |\n",
      "|    dual_loss           | -1.14e+08 |\n",
      "|    kl_loss             | 49.6      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 45350     |\n",
      "|    penalty_temperature | 14.2      |\n",
      "|    policy_loss         | 47.8      |\n",
      "|    std                 | 2.75      |\n",
      "|    temperature         | 5.71      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 152       |\n",
      "|    ep_rew_mean         | -122      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 280       |\n",
      "|    fps                 | 133       |\n",
      "|    time_elapsed        | 416       |\n",
      "|    total_timesteps     | 55757     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.48e+08 |\n",
      "|    alpha_mean          | 12.3      |\n",
      "|    alpha_std           | 19.3      |\n",
      "|    critic_loss         | 1.64e+17  |\n",
      "|    dual_loss           | -1.48e+08 |\n",
      "|    kl_loss             | 59.3      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 45750     |\n",
      "|    penalty_temperature | 14.3      |\n",
      "|    policy_loss         | 49.5      |\n",
      "|    std                 | 2.79      |\n",
      "|    temperature         | 5.71      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 152       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 284       |\n",
      "|    fps                 | 133       |\n",
      "|    time_elapsed        | 419       |\n",
      "|    total_timesteps     | 56115     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.37e+08 |\n",
      "|    alpha_mean          | 12.4      |\n",
      "|    alpha_std           | 19.4      |\n",
      "|    critic_loss         | 1.61e+17  |\n",
      "|    dual_loss           | -1.37e+08 |\n",
      "|    kl_loss             | 55.9      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 46100     |\n",
      "|    penalty_temperature | 14.4      |\n",
      "|    policy_loss         | 49        |\n",
      "|    std                 | 2.83      |\n",
      "|    temperature         | 5.71      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 151       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 288       |\n",
      "|    fps                 | 133       |\n",
      "|    time_elapsed        | 422       |\n",
      "|    total_timesteps     | 56464     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.54e+08 |\n",
      "|    alpha_mean          | 12.5      |\n",
      "|    alpha_std           | 19.5      |\n",
      "|    critic_loss         | 1.96e+17  |\n",
      "|    dual_loss           | -1.54e+08 |\n",
      "|    kl_loss             | 65.9      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 46450     |\n",
      "|    penalty_temperature | 14.5      |\n",
      "|    policy_loss         | 50.8      |\n",
      "|    std                 | 2.86      |\n",
      "|    temperature         | 5.71      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 151       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 292       |\n",
      "|    fps                 | 133       |\n",
      "|    time_elapsed        | 426       |\n",
      "|    total_timesteps     | 56911     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.66e+08 |\n",
      "|    alpha_mean          | 12.6      |\n",
      "|    alpha_std           | 19.6      |\n",
      "|    critic_loss         | 2.23e+17  |\n",
      "|    dual_loss           | -1.66e+08 |\n",
      "|    kl_loss             | 58.6      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 46900     |\n",
      "|    penalty_temperature | 14.7      |\n",
      "|    policy_loss         | 49.8      |\n",
      "|    std                 | 2.91      |\n",
      "|    temperature         | 5.72      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 150       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 296       |\n",
      "|    fps                 | 133       |\n",
      "|    time_elapsed        | 429       |\n",
      "|    total_timesteps     | 57254     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.75e+08 |\n",
      "|    alpha_mean          | 12.7      |\n",
      "|    alpha_std           | 19.7      |\n",
      "|    critic_loss         | 2.18e+17  |\n",
      "|    dual_loss           | -1.75e+08 |\n",
      "|    kl_loss             | 66.4      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 47250     |\n",
      "|    penalty_temperature | 14.8      |\n",
      "|    policy_loss         | 51.1      |\n",
      "|    std                 | 2.95      |\n",
      "|    temperature         | 5.72      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 150      |\n",
      "|    ep_rew_mean         | -123     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 300      |\n",
      "|    fps                 | 133      |\n",
      "|    time_elapsed        | 432      |\n",
      "|    total_timesteps     | 57620    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -1.9e+08 |\n",
      "|    alpha_mean          | 12.8     |\n",
      "|    alpha_std           | 19.8     |\n",
      "|    critic_loss         | 2.72e+17 |\n",
      "|    dual_loss           | -1.9e+08 |\n",
      "|    kl_loss             | 67.2     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 47600    |\n",
      "|    penalty_temperature | 14.9     |\n",
      "|    policy_loss         | 51.3     |\n",
      "|    std                 | 2.98     |\n",
      "|    temperature         | 5.72     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 151       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 304       |\n",
      "|    fps                 | 133       |\n",
      "|    time_elapsed        | 435       |\n",
      "|    total_timesteps     | 57990     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.77e+08 |\n",
      "|    alpha_mean          | 12.8      |\n",
      "|    alpha_std           | 19.9      |\n",
      "|    critic_loss         | 2.81e+17  |\n",
      "|    dual_loss           | -1.77e+08 |\n",
      "|    kl_loss             | 52        |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 47950     |\n",
      "|    penalty_temperature | 15        |\n",
      "|    policy_loss         | 49.1      |\n",
      "|    std                 | 3.02      |\n",
      "|    temperature         | 5.73      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 150       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 308       |\n",
      "|    fps                 | 132       |\n",
      "|    time_elapsed        | 439       |\n",
      "|    total_timesteps     | 58313     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.95e+08 |\n",
      "|    alpha_mean          | 12.9      |\n",
      "|    alpha_std           | 20        |\n",
      "|    critic_loss         | 3.05e+17  |\n",
      "|    dual_loss           | -1.95e+08 |\n",
      "|    kl_loss             | 63.3      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 48300     |\n",
      "|    penalty_temperature | 15.1      |\n",
      "|    policy_loss         | 50.9      |\n",
      "|    std                 | 3.05      |\n",
      "|    temperature         | 5.73      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 151      |\n",
      "|    ep_rew_mean         | -123     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 312      |\n",
      "|    fps                 | 132      |\n",
      "|    time_elapsed        | 442      |\n",
      "|    total_timesteps     | 58654    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -2.2e+08 |\n",
      "|    alpha_mean          | 13       |\n",
      "|    alpha_std           | 20.1     |\n",
      "|    critic_loss         | 3.91e+17 |\n",
      "|    dual_loss           | -2.2e+08 |\n",
      "|    kl_loss             | 78.3     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 48650    |\n",
      "|    penalty_temperature | 15.2     |\n",
      "|    policy_loss         | 53.4     |\n",
      "|    std                 | 3.09     |\n",
      "|    temperature         | 5.73     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 151       |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 316       |\n",
      "|    fps                 | 132       |\n",
      "|    time_elapsed        | 444       |\n",
      "|    total_timesteps     | 58992     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.22e+08 |\n",
      "|    alpha_mean          | 13.1      |\n",
      "|    alpha_std           | 20.2      |\n",
      "|    critic_loss         | 3.63e+17  |\n",
      "|    dual_loss           | -2.22e+08 |\n",
      "|    kl_loss             | 78.7      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 48950     |\n",
      "|    penalty_temperature | 15.3      |\n",
      "|    policy_loss         | 53.6      |\n",
      "|    std                 | 3.12      |\n",
      "|    temperature         | 5.73      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 152       |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 320       |\n",
      "|    fps                 | 132       |\n",
      "|    time_elapsed        | 448       |\n",
      "|    total_timesteps     | 59337     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.11e+08 |\n",
      "|    alpha_mean          | 13.2      |\n",
      "|    alpha_std           | 20.3      |\n",
      "|    critic_loss         | 3.88e+17  |\n",
      "|    dual_loss           | -2.11e+08 |\n",
      "|    kl_loss             | 50.2      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 49300     |\n",
      "|    penalty_temperature | 15.5      |\n",
      "|    policy_loss         | 49.1      |\n",
      "|    std                 | 3.16      |\n",
      "|    temperature         | 5.74      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 152       |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 324       |\n",
      "|    fps                 | 132       |\n",
      "|    time_elapsed        | 451       |\n",
      "|    total_timesteps     | 59667     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.48e+08 |\n",
      "|    alpha_mean          | 13.3      |\n",
      "|    alpha_std           | 20.4      |\n",
      "|    critic_loss         | 4.69e+17  |\n",
      "|    dual_loss           | -2.48e+08 |\n",
      "|    kl_loss             | 57.9      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 49650     |\n",
      "|    penalty_temperature | 15.6      |\n",
      "|    policy_loss         | 50.5      |\n",
      "|    std                 | 3.2       |\n",
      "|    temperature         | 5.75      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 149       |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 328       |\n",
      "|    fps                 | 132       |\n",
      "|    time_elapsed        | 453       |\n",
      "|    total_timesteps     | 59992     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.44e+08 |\n",
      "|    alpha_mean          | 13.3      |\n",
      "|    alpha_std           | 20.4      |\n",
      "|    critic_loss         | 4.58e+17  |\n",
      "|    dual_loss           | -2.44e+08 |\n",
      "|    kl_loss             | 61.1      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 49950     |\n",
      "|    penalty_temperature | 15.7      |\n",
      "|    policy_loss         | 51.1      |\n",
      "|    std                 | 3.23      |\n",
      "|    temperature         | 5.75      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 148       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 332       |\n",
      "|    fps                 | 131       |\n",
      "|    time_elapsed        | 457       |\n",
      "|    total_timesteps     | 60325     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.62e+08 |\n",
      "|    alpha_mean          | 13.4      |\n",
      "|    alpha_std           | 20.5      |\n",
      "|    critic_loss         | 5.14e+17  |\n",
      "|    dual_loss           | -2.62e+08 |\n",
      "|    kl_loss             | 72.4      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 50300     |\n",
      "|    penalty_temperature | 15.8      |\n",
      "|    policy_loss         | 53.1      |\n",
      "|    std                 | 3.27      |\n",
      "|    temperature         | 5.76      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 148       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 336       |\n",
      "|    fps                 | 131       |\n",
      "|    time_elapsed        | 460       |\n",
      "|    total_timesteps     | 60686     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.72e+08 |\n",
      "|    alpha_mean          | 13.5      |\n",
      "|    alpha_std           | 20.6      |\n",
      "|    critic_loss         | 5.31e+17  |\n",
      "|    dual_loss           | -2.72e+08 |\n",
      "|    kl_loss             | 64.8      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 50650     |\n",
      "|    penalty_temperature | 15.9      |\n",
      "|    policy_loss         | 52        |\n",
      "|    std                 | 3.31      |\n",
      "|    temperature         | 5.77      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 148       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 340       |\n",
      "|    fps                 | 131       |\n",
      "|    time_elapsed        | 463       |\n",
      "|    total_timesteps     | 61057     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.76e+08 |\n",
      "|    alpha_mean          | 13.6      |\n",
      "|    alpha_std           | 20.8      |\n",
      "|    critic_loss         | 6.02e+17  |\n",
      "|    dual_loss           | -2.76e+08 |\n",
      "|    kl_loss             | 60.5      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 51050     |\n",
      "|    penalty_temperature | 16        |\n",
      "|    policy_loss         | 51.6      |\n",
      "|    std                 | 3.36      |\n",
      "|    temperature         | 5.79      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 146       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 344       |\n",
      "|    fps                 | 131       |\n",
      "|    time_elapsed        | 466       |\n",
      "|    total_timesteps     | 61443     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.89e+08 |\n",
      "|    alpha_mean          | 13.7      |\n",
      "|    alpha_std           | 20.9      |\n",
      "|    critic_loss         | 6.27e+17  |\n",
      "|    dual_loss           | -2.89e+08 |\n",
      "|    kl_loss             | 60.4      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 51400     |\n",
      "|    penalty_temperature | 16.1      |\n",
      "|    policy_loss         | 51.6      |\n",
      "|    std                 | 3.4       |\n",
      "|    temperature         | 5.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 132       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 348       |\n",
      "|    fps                 | 131       |\n",
      "|    time_elapsed        | 470       |\n",
      "|    total_timesteps     | 61824     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.99e+08 |\n",
      "|    alpha_mean          | 13.8      |\n",
      "|    alpha_std           | 21        |\n",
      "|    critic_loss         | 7.34e+17  |\n",
      "|    dual_loss           | -2.99e+08 |\n",
      "|    kl_loss             | 59.1      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 51800     |\n",
      "|    penalty_temperature | 16.2      |\n",
      "|    policy_loss         | 51.8      |\n",
      "|    std                 | 3.45      |\n",
      "|    temperature         | 5.81      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 133       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 352       |\n",
      "|    fps                 | 131       |\n",
      "|    time_elapsed        | 473       |\n",
      "|    total_timesteps     | 62165     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -3.14e+08 |\n",
      "|    alpha_mean          | 13.9      |\n",
      "|    alpha_std           | 21.1      |\n",
      "|    critic_loss         | 7.44e+17  |\n",
      "|    dual_loss           | -3.14e+08 |\n",
      "|    kl_loss             | 62.2      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 52150     |\n",
      "|    penalty_temperature | 16.4      |\n",
      "|    policy_loss         | 52.4      |\n",
      "|    std                 | 3.5       |\n",
      "|    temperature         | 5.81      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 103       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 356       |\n",
      "|    fps                 | 131       |\n",
      "|    time_elapsed        | 476       |\n",
      "|    total_timesteps     | 62517     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -3.02e+08 |\n",
      "|    alpha_mean          | 13.9      |\n",
      "|    alpha_std           | 21.2      |\n",
      "|    critic_loss         | 6.85e+17  |\n",
      "|    dual_loss           | -3.02e+08 |\n",
      "|    kl_loss             | 69.8      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 52500     |\n",
      "|    penalty_temperature | 16.5      |\n",
      "|    policy_loss         | 53.5      |\n",
      "|    std                 | 3.54      |\n",
      "|    temperature         | 5.82      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 104       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 360       |\n",
      "|    fps                 | 130       |\n",
      "|    time_elapsed        | 479       |\n",
      "|    total_timesteps     | 62868     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.94e+08 |\n",
      "|    alpha_mean          | 14        |\n",
      "|    alpha_std           | 21.3      |\n",
      "|    critic_loss         | 6.99e+17  |\n",
      "|    dual_loss           | -2.94e+08 |\n",
      "|    kl_loss             | 51.8      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 52850     |\n",
      "|    penalty_temperature | 16.6      |\n",
      "|    policy_loss         | 51        |\n",
      "|    std                 | 3.59      |\n",
      "|    temperature         | 5.83      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 104       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 364       |\n",
      "|    fps                 | 130       |\n",
      "|    time_elapsed        | 483       |\n",
      "|    total_timesteps     | 63225     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -3.03e+08 |\n",
      "|    alpha_mean          | 14.1      |\n",
      "|    alpha_std           | 21.4      |\n",
      "|    critic_loss         | 7.95e+17  |\n",
      "|    dual_loss           | -3.03e+08 |\n",
      "|    kl_loss             | 75.2      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 53200     |\n",
      "|    penalty_temperature | 16.7      |\n",
      "|    policy_loss         | 54.4      |\n",
      "|    std                 | 3.63      |\n",
      "|    temperature         | 5.84      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 104       |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 368       |\n",
      "|    fps                 | 130       |\n",
      "|    time_elapsed        | 486       |\n",
      "|    total_timesteps     | 63578     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -3.24e+08 |\n",
      "|    alpha_mean          | 14.2      |\n",
      "|    alpha_std           | 21.5      |\n",
      "|    critic_loss         | 8.46e+17  |\n",
      "|    dual_loss           | -3.24e+08 |\n",
      "|    kl_loss             | 54.9      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 53550     |\n",
      "|    penalty_temperature | 16.8      |\n",
      "|    policy_loss         | 51.7      |\n",
      "|    std                 | 3.68      |\n",
      "|    temperature         | 5.86      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89.2      |\n",
      "|    ep_rew_mean         | -122      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 372       |\n",
      "|    fps                 | 130       |\n",
      "|    time_elapsed        | 489       |\n",
      "|    total_timesteps     | 63917     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -3.66e+08 |\n",
      "|    alpha_mean          | 14.3      |\n",
      "|    alpha_std           | 21.6      |\n",
      "|    critic_loss         | 1.06e+18  |\n",
      "|    dual_loss           | -3.66e+08 |\n",
      "|    kl_loss             | 63.2      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 53900     |\n",
      "|    penalty_temperature | 16.9      |\n",
      "|    policy_loss         | 53.1      |\n",
      "|    std                 | 3.73      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89.3      |\n",
      "|    ep_rew_mean         | -122      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 376       |\n",
      "|    fps                 | 130       |\n",
      "|    time_elapsed        | 492       |\n",
      "|    total_timesteps     | 64286     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -3.27e+08 |\n",
      "|    alpha_mean          | 14.3      |\n",
      "|    alpha_std           | 21.7      |\n",
      "|    critic_loss         | 9.4e+17   |\n",
      "|    dual_loss           | -3.27e+08 |\n",
      "|    kl_loss             | 53.7      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 54250     |\n",
      "|    penalty_temperature | 17        |\n",
      "|    policy_loss         | 52        |\n",
      "|    std                 | 3.78      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 89.1     |\n",
      "|    ep_rew_mean         | -122     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 380      |\n",
      "|    fps                 | 130      |\n",
      "|    time_elapsed        | 496      |\n",
      "|    total_timesteps     | 64665    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -3.3e+08 |\n",
      "|    alpha_mean          | 14.4     |\n",
      "|    alpha_std           | 21.8     |\n",
      "|    critic_loss         | 9.72e+17 |\n",
      "|    dual_loss           | -3.3e+08 |\n",
      "|    kl_loss             | 62.2     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 54650    |\n",
      "|    penalty_temperature | 17.1     |\n",
      "|    policy_loss         | 53.4     |\n",
      "|    std                 | 3.84     |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89.2      |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 384       |\n",
      "|    fps                 | 130       |\n",
      "|    time_elapsed        | 499       |\n",
      "|    total_timesteps     | 65033     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -3.52e+08 |\n",
      "|    alpha_mean          | 14.5      |\n",
      "|    alpha_std           | 21.9      |\n",
      "|    critic_loss         | 1.1e+18   |\n",
      "|    dual_loss           | -3.52e+08 |\n",
      "|    kl_loss             | 56.5      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 55000     |\n",
      "|    penalty_temperature | 17.3      |\n",
      "|    policy_loss         | 52.7      |\n",
      "|    std                 | 3.89      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89.4      |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 388       |\n",
      "|    fps                 | 130       |\n",
      "|    time_elapsed        | 502       |\n",
      "|    total_timesteps     | 65405     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -3.28e+08 |\n",
      "|    alpha_mean          | 14.6      |\n",
      "|    alpha_std           | 22        |\n",
      "|    critic_loss         | 9.84e+17  |\n",
      "|    dual_loss           | -3.28e+08 |\n",
      "|    kl_loss             | 43        |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 55400     |\n",
      "|    penalty_temperature | 17.4      |\n",
      "|    policy_loss         | 51.1      |\n",
      "|    std                 | 3.95      |\n",
      "|    temperature         | 5.89      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 88.7     |\n",
      "|    ep_rew_mean         | -123     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 392      |\n",
      "|    fps                 | 130      |\n",
      "|    time_elapsed        | 506      |\n",
      "|    total_timesteps     | 65783    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -3.8e+08 |\n",
      "|    alpha_mean          | 14.7     |\n",
      "|    alpha_std           | 22.1     |\n",
      "|    critic_loss         | 1.34e+18 |\n",
      "|    dual_loss           | -3.8e+08 |\n",
      "|    kl_loss             | 59.9     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 55750    |\n",
      "|    penalty_temperature | 17.5     |\n",
      "|    policy_loss         | 53.7     |\n",
      "|    std                 | 4.01     |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89.3      |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 396       |\n",
      "|    fps                 | 129       |\n",
      "|    time_elapsed        | 509       |\n",
      "|    total_timesteps     | 66181     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -3.86e+08 |\n",
      "|    alpha_mean          | 14.8      |\n",
      "|    alpha_std           | 22.2      |\n",
      "|    critic_loss         | 1.3e+18   |\n",
      "|    dual_loss           | -3.86e+08 |\n",
      "|    kl_loss             | 48.6      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 56150     |\n",
      "|    penalty_temperature | 17.6      |\n",
      "|    policy_loss         | 52.3      |\n",
      "|    std                 | 4.07      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89.2      |\n",
      "|    ep_rew_mean         | -123      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 400       |\n",
      "|    fps                 | 129       |\n",
      "|    time_elapsed        | 512       |\n",
      "|    total_timesteps     | 66544     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -3.92e+08 |\n",
      "|    alpha_mean          | 14.8      |\n",
      "|    alpha_std           | 22.3      |\n",
      "|    critic_loss         | 1.47e+18  |\n",
      "|    dual_loss           | -3.92e+08 |\n",
      "|    kl_loss             | 62.9      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 56500     |\n",
      "|    penalty_temperature | 17.7      |\n",
      "|    policy_loss         | 54.4      |\n",
      "|    std                 | 4.13      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 89        |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 404       |\n",
      "|    fps                 | 129       |\n",
      "|    time_elapsed        | 515       |\n",
      "|    total_timesteps     | 66895     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -3.38e+08 |\n",
      "|    alpha_mean          | 14.9      |\n",
      "|    alpha_std           | 22.4      |\n",
      "|    critic_loss         | 1.2e+18   |\n",
      "|    dual_loss           | -3.38e+08 |\n",
      "|    kl_loss             | 43.2      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 56850     |\n",
      "|    penalty_temperature | 17.8      |\n",
      "|    policy_loss         | 51.8      |\n",
      "|    std                 | 4.19      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 89.6     |\n",
      "|    ep_rew_mean         | -124     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 408      |\n",
      "|    fps                 | 129      |\n",
      "|    time_elapsed        | 519      |\n",
      "|    total_timesteps     | 67269    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -4.1e+08 |\n",
      "|    alpha_mean          | 15       |\n",
      "|    alpha_std           | 22.5     |\n",
      "|    critic_loss         | 1.72e+18 |\n",
      "|    dual_loss           | -4.1e+08 |\n",
      "|    kl_loss             | 64.3     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 57250    |\n",
      "|    penalty_temperature | 18       |\n",
      "|    policy_loss         | 55       |\n",
      "|    std                 | 4.26     |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 90        |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 412       |\n",
      "|    fps                 | 129       |\n",
      "|    time_elapsed        | 523       |\n",
      "|    total_timesteps     | 67658     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -4.12e+08 |\n",
      "|    alpha_mean          | 15.1      |\n",
      "|    alpha_std           | 22.6      |\n",
      "|    critic_loss         | 1.67e+18  |\n",
      "|    dual_loss           | -4.12e+08 |\n",
      "|    kl_loss             | 44        |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 57650     |\n",
      "|    penalty_temperature | 18.1      |\n",
      "|    policy_loss         | 52.5      |\n",
      "|    std                 | 4.33      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 90.5      |\n",
      "|    ep_rew_mean         | -124      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 416       |\n",
      "|    fps                 | 129       |\n",
      "|    time_elapsed        | 526       |\n",
      "|    total_timesteps     | 68038     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -4.29e+08 |\n",
      "|    alpha_mean          | 15.1      |\n",
      "|    alpha_std           | 22.6      |\n",
      "|    critic_loss         | 1.73e+18  |\n",
      "|    dual_loss           | -4.29e+08 |\n",
      "|    kl_loss             | 46.8      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 58000     |\n",
      "|    penalty_temperature | 18.2      |\n",
      "|    policy_loss         | 53.1      |\n",
      "|    std                 | 4.4       |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 90.5      |\n",
      "|    ep_rew_mean         | -125      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 420       |\n",
      "|    fps                 | 129       |\n",
      "|    time_elapsed        | 529       |\n",
      "|    total_timesteps     | 68390     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -4.08e+08 |\n",
      "|    alpha_mean          | 15.2      |\n",
      "|    alpha_std           | 22.7      |\n",
      "|    critic_loss         | 1.8e+18   |\n",
      "|    dual_loss           | -4.08e+08 |\n",
      "|    kl_loss             | 40.1      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 58350     |\n",
      "|    penalty_temperature | 18.3      |\n",
      "|    policy_loss         | 52.4      |\n",
      "|    std                 | 4.47      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 91.5      |\n",
      "|    ep_rew_mean         | -125      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 424       |\n",
      "|    fps                 | 129       |\n",
      "|    time_elapsed        | 533       |\n",
      "|    total_timesteps     | 68819     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -4.52e+08 |\n",
      "|    alpha_mean          | 15.3      |\n",
      "|    alpha_std           | 22.8      |\n",
      "|    critic_loss         | 2.16e+18  |\n",
      "|    dual_loss           | -4.52e+08 |\n",
      "|    kl_loss             | 49.8      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 58800     |\n",
      "|    penalty_temperature | 18.5      |\n",
      "|    policy_loss         | 53.9      |\n",
      "|    std                 | 4.56      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 92        |\n",
      "|    ep_rew_mean         | -125      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 428       |\n",
      "|    fps                 | 128       |\n",
      "|    time_elapsed        | 536       |\n",
      "|    total_timesteps     | 69197     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -5.12e+08 |\n",
      "|    alpha_mean          | 15.4      |\n",
      "|    alpha_std           | 22.9      |\n",
      "|    critic_loss         | 2.54e+18  |\n",
      "|    dual_loss           | -5.12e+08 |\n",
      "|    kl_loss             | 54.6      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 59150     |\n",
      "|    penalty_temperature | 18.6      |\n",
      "|    policy_loss         | 54.7      |\n",
      "|    std                 | 4.63      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 92.1      |\n",
      "|    ep_rew_mean         | -126      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 432       |\n",
      "|    fps                 | 128       |\n",
      "|    time_elapsed        | 539       |\n",
      "|    total_timesteps     | 69535     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -4.07e+08 |\n",
      "|    alpha_mean          | 15.5      |\n",
      "|    alpha_std           | 23        |\n",
      "|    critic_loss         | 2.22e+18  |\n",
      "|    dual_loss           | -4.07e+08 |\n",
      "|    kl_loss             | 46.7      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 59500     |\n",
      "|    penalty_temperature | 18.7      |\n",
      "|    policy_loss         | 53.8      |\n",
      "|    std                 | 4.7       |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 92.5      |\n",
      "|    ep_rew_mean         | -126      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 436       |\n",
      "|    fps                 | 128       |\n",
      "|    time_elapsed        | 543       |\n",
      "|    total_timesteps     | 69931     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -5.28e+08 |\n",
      "|    alpha_mean          | 15.5      |\n",
      "|    alpha_std           | 23.1      |\n",
      "|    critic_loss         | 2.72e+18  |\n",
      "|    dual_loss           | -5.28e+08 |\n",
      "|    kl_loss             | 44.4      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 59900     |\n",
      "|    penalty_temperature | 18.8      |\n",
      "|    policy_loss         | 53.9      |\n",
      "|    std                 | 4.79      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 92.6      |\n",
      "|    ep_rew_mean         | -126      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 440       |\n",
      "|    fps                 | 128       |\n",
      "|    time_elapsed        | 546       |\n",
      "|    total_timesteps     | 70314     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -4.84e+08 |\n",
      "|    alpha_mean          | 15.6      |\n",
      "|    alpha_std           | 23.2      |\n",
      "|    critic_loss         | 2.57e+18  |\n",
      "|    dual_loss           | -4.84e+08 |\n",
      "|    kl_loss             | 46.5      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 60300     |\n",
      "|    penalty_temperature | 19        |\n",
      "|    policy_loss         | 54.3      |\n",
      "|    std                 | 4.88      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 93       |\n",
      "|    ep_rew_mean         | -126     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 444      |\n",
      "|    fps                 | 128      |\n",
      "|    time_elapsed        | 550      |\n",
      "|    total_timesteps     | 70738    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -5.3e+08 |\n",
      "|    alpha_mean          | 15.7     |\n",
      "|    alpha_std           | 23.3     |\n",
      "|    critic_loss         | 3.11e+18 |\n",
      "|    dual_loss           | -5.3e+08 |\n",
      "|    kl_loss             | 42.5     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 60700    |\n",
      "|    penalty_temperature | 19.1     |\n",
      "|    policy_loss         | 54.1     |\n",
      "|    std                 | 4.98     |\n",
      "|    temperature         | 5.87     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 92.7      |\n",
      "|    ep_rew_mean         | -126      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 448       |\n",
      "|    fps                 | 128       |\n",
      "|    time_elapsed        | 553       |\n",
      "|    total_timesteps     | 71093     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -5.48e+08 |\n",
      "|    alpha_mean          | 15.8      |\n",
      "|    alpha_std           | 23.4      |\n",
      "|    critic_loss         | 3.31e+18  |\n",
      "|    dual_loss           | -5.48e+08 |\n",
      "|    kl_loss             | 42        |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 61050     |\n",
      "|    penalty_temperature | 19.2      |\n",
      "|    policy_loss         | 54.2      |\n",
      "|    std                 | 5.06      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 93.4      |\n",
      "|    ep_rew_mean         | -126      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 452       |\n",
      "|    fps                 | 128       |\n",
      "|    time_elapsed        | 557       |\n",
      "|    total_timesteps     | 71505     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -5.59e+08 |\n",
      "|    alpha_mean          | 15.9      |\n",
      "|    alpha_std           | 23.5      |\n",
      "|    critic_loss         | 2.85e+18  |\n",
      "|    dual_loss           | -5.59e+08 |\n",
      "|    kl_loss             | 43.1      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 61500     |\n",
      "|    penalty_temperature | 19.3      |\n",
      "|    policy_loss         | 54.6      |\n",
      "|    std                 | 5.17      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 94.1      |\n",
      "|    ep_rew_mean         | -126      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 456       |\n",
      "|    fps                 | 128       |\n",
      "|    time_elapsed        | 561       |\n",
      "|    total_timesteps     | 71925     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -7.24e+08 |\n",
      "|    alpha_mean          | 16        |\n",
      "|    alpha_std           | 23.5      |\n",
      "|    critic_loss         | 4.48e+18  |\n",
      "|    dual_loss           | -7.24e+08 |\n",
      "|    kl_loss             | 46.5      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 61900     |\n",
      "|    penalty_temperature | 19.5      |\n",
      "|    policy_loss         | 55.3      |\n",
      "|    std                 | 5.27      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 94       |\n",
      "|    ep_rew_mean         | -126     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 460      |\n",
      "|    fps                 | 127      |\n",
      "|    time_elapsed        | 564      |\n",
      "|    total_timesteps     | 72265    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -6.6e+08 |\n",
      "|    alpha_mean          | 16.1     |\n",
      "|    alpha_std           | 23.6     |\n",
      "|    critic_loss         | 4.13e+18 |\n",
      "|    dual_loss           | -6.6e+08 |\n",
      "|    kl_loss             | 55       |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 62250    |\n",
      "|    penalty_temperature | 19.6     |\n",
      "|    policy_loss         | 56.5     |\n",
      "|    std                 | 5.36     |\n",
      "|    temperature         | 5.87     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 94.3      |\n",
      "|    ep_rew_mean         | -126      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 464       |\n",
      "|    fps                 | 127       |\n",
      "|    time_elapsed        | 568       |\n",
      "|    total_timesteps     | 72652     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -6.84e+08 |\n",
      "|    alpha_mean          | 16.2      |\n",
      "|    alpha_std           | 23.7      |\n",
      "|    critic_loss         | 4.1e+18   |\n",
      "|    dual_loss           | -6.84e+08 |\n",
      "|    kl_loss             | 48.7      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 62650     |\n",
      "|    penalty_temperature | 19.7      |\n",
      "|    policy_loss         | 56        |\n",
      "|    std                 | 5.47      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 95       |\n",
      "|    ep_rew_mean         | -126     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 468      |\n",
      "|    fps                 | 127      |\n",
      "|    time_elapsed        | 571      |\n",
      "|    total_timesteps     | 73077    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -7.7e+08 |\n",
      "|    alpha_mean          | 16.2     |\n",
      "|    alpha_std           | 23.8     |\n",
      "|    critic_loss         | 5.47e+18 |\n",
      "|    dual_loss           | -7.7e+08 |\n",
      "|    kl_loss             | 55.1     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 63050    |\n",
      "|    penalty_temperature | 19.8     |\n",
      "|    policy_loss         | 57       |\n",
      "|    std                 | 5.57     |\n",
      "|    temperature         | 5.87     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 95.9      |\n",
      "|    ep_rew_mean         | -126      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 472       |\n",
      "|    fps                 | 127       |\n",
      "|    time_elapsed        | 575       |\n",
      "|    total_timesteps     | 73509     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -8.01e+08 |\n",
      "|    alpha_mean          | 16.3      |\n",
      "|    alpha_std           | 23.9      |\n",
      "|    critic_loss         | 6.12e+18  |\n",
      "|    dual_loss           | -8.01e+08 |\n",
      "|    kl_loss             | 47.6      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 63500     |\n",
      "|    penalty_temperature | 20        |\n",
      "|    policy_loss         | 56.4      |\n",
      "|    std                 | 5.7       |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 97.5      |\n",
      "|    ep_rew_mean         | -127      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 476       |\n",
      "|    fps                 | 127       |\n",
      "|    time_elapsed        | 580       |\n",
      "|    total_timesteps     | 74035     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -7.55e+08 |\n",
      "|    alpha_mean          | 16.4      |\n",
      "|    alpha_std           | 24        |\n",
      "|    critic_loss         | 6.18e+18  |\n",
      "|    dual_loss           | -7.55e+08 |\n",
      "|    kl_loss             | 47.4      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 64000     |\n",
      "|    penalty_temperature | 20.1      |\n",
      "|    policy_loss         | 56.8      |\n",
      "|    std                 | 5.85      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 97.2      |\n",
      "|    ep_rew_mean         | -127      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 480       |\n",
      "|    fps                 | 127       |\n",
      "|    time_elapsed        | 583       |\n",
      "|    total_timesteps     | 74387     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -8.43e+08 |\n",
      "|    alpha_mean          | 16.5      |\n",
      "|    alpha_std           | 24.1      |\n",
      "|    critic_loss         | 7.14e+18  |\n",
      "|    dual_loss           | -8.43e+08 |\n",
      "|    kl_loss             | 51.9      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 64350     |\n",
      "|    penalty_temperature | 20.3      |\n",
      "|    policy_loss         | 57.4      |\n",
      "|    std                 | 5.95      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 97.8      |\n",
      "|    ep_rew_mean         | -127      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 484       |\n",
      "|    fps                 | 127       |\n",
      "|    time_elapsed        | 587       |\n",
      "|    total_timesteps     | 74810     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -9.77e+08 |\n",
      "|    alpha_mean          | 16.6      |\n",
      "|    alpha_std           | 24.1      |\n",
      "|    critic_loss         | 8e+18     |\n",
      "|    dual_loss           | -9.77e+08 |\n",
      "|    kl_loss             | 60        |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 64800     |\n",
      "|    penalty_temperature | 20.4      |\n",
      "|    policy_loss         | 58.8      |\n",
      "|    std                 | 6.09      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 99.8      |\n",
      "|    ep_rew_mean         | -127      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 488       |\n",
      "|    fps                 | 127       |\n",
      "|    time_elapsed        | 592       |\n",
      "|    total_timesteps     | 75384     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.01e+09 |\n",
      "|    alpha_mean          | 16.7      |\n",
      "|    alpha_std           | 24.2      |\n",
      "|    critic_loss         | 7.89e+18  |\n",
      "|    dual_loss           | -1.01e+09 |\n",
      "|    kl_loss             | 53.9      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 65350     |\n",
      "|    penalty_temperature | 20.6      |\n",
      "|    policy_loss         | 58.1      |\n",
      "|    std                 | 6.26      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 100      |\n",
      "|    ep_rew_mean         | -127     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 492      |\n",
      "|    fps                 | 127      |\n",
      "|    time_elapsed        | 596      |\n",
      "|    total_timesteps     | 75787    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -9.6e+08 |\n",
      "|    alpha_mean          | 16.8     |\n",
      "|    alpha_std           | 24.3     |\n",
      "|    critic_loss         | 1e+19    |\n",
      "|    dual_loss           | -9.6e+08 |\n",
      "|    kl_loss             | 59.3     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 65750    |\n",
      "|    penalty_temperature | 20.7     |\n",
      "|    policy_loss         | 59.2     |\n",
      "|    std                 | 6.4      |\n",
      "|    temperature         | 5.87     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 99.7      |\n",
      "|    ep_rew_mean         | -127      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 496       |\n",
      "|    fps                 | 127       |\n",
      "|    time_elapsed        | 599       |\n",
      "|    total_timesteps     | 76147     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.12e+09 |\n",
      "|    alpha_mean          | 16.8      |\n",
      "|    alpha_std           | 24.4      |\n",
      "|    critic_loss         | 1.04e+19  |\n",
      "|    dual_loss           | -1.12e+09 |\n",
      "|    kl_loss             | 48.2      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 66100     |\n",
      "|    penalty_temperature | 20.8      |\n",
      "|    policy_loss         | 58.1      |\n",
      "|    std                 | 6.52      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 101      |\n",
      "|    ep_rew_mean         | -127     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 500      |\n",
      "|    fps                 | 126      |\n",
      "|    time_elapsed        | 604      |\n",
      "|    total_timesteps     | 76610    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -1.1e+09 |\n",
      "|    alpha_mean          | 16.9     |\n",
      "|    alpha_std           | 24.5     |\n",
      "|    critic_loss         | 1.21e+19 |\n",
      "|    dual_loss           | -1.1e+09 |\n",
      "|    kl_loss             | 74.9     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 66600    |\n",
      "|    penalty_temperature | 21       |\n",
      "|    policy_loss         | 61.4     |\n",
      "|    std                 | 6.69     |\n",
      "|    temperature         | 5.87     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 101       |\n",
      "|    ep_rew_mean         | -127      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 504       |\n",
      "|    fps                 | 126       |\n",
      "|    time_elapsed        | 607       |\n",
      "|    total_timesteps     | 76988     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.21e+09 |\n",
      "|    alpha_mean          | 17        |\n",
      "|    alpha_std           | 24.5      |\n",
      "|    critic_loss         | 1.3e+19   |\n",
      "|    dual_loss           | -1.21e+09 |\n",
      "|    kl_loss             | 47.2      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 66950     |\n",
      "|    penalty_temperature | 21.1      |\n",
      "|    policy_loss         | 58.5      |\n",
      "|    std                 | 6.82      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 101       |\n",
      "|    ep_rew_mean         | -127      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 508       |\n",
      "|    fps                 | 126       |\n",
      "|    time_elapsed        | 611       |\n",
      "|    total_timesteps     | 77405     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.21e+09 |\n",
      "|    alpha_mean          | 17.1      |\n",
      "|    alpha_std           | 24.6      |\n",
      "|    critic_loss         | 1.37e+19  |\n",
      "|    dual_loss           | -1.21e+09 |\n",
      "|    kl_loss             | 59.3      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 67400     |\n",
      "|    penalty_temperature | 21.3      |\n",
      "|    policy_loss         | 60.2      |\n",
      "|    std                 | 6.99      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 101       |\n",
      "|    ep_rew_mean         | -127      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 512       |\n",
      "|    fps                 | 126       |\n",
      "|    time_elapsed        | 615       |\n",
      "|    total_timesteps     | 77805     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.47e+09 |\n",
      "|    alpha_mean          | 17.1      |\n",
      "|    alpha_std           | 24.7      |\n",
      "|    critic_loss         | 1.73e+19  |\n",
      "|    dual_loss           | -1.47e+09 |\n",
      "|    kl_loss             | 48.4      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 67800     |\n",
      "|    penalty_temperature | 21.4      |\n",
      "|    policy_loss         | 59.1      |\n",
      "|    std                 | 7.15      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 102      |\n",
      "|    ep_rew_mean         | -127     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 516      |\n",
      "|    fps                 | 126      |\n",
      "|    time_elapsed        | 618      |\n",
      "|    total_timesteps     | 78215    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -1.5e+09 |\n",
      "|    alpha_mean          | 17.2     |\n",
      "|    alpha_std           | 24.8     |\n",
      "|    critic_loss         | 1.93e+19 |\n",
      "|    dual_loss           | -1.5e+09 |\n",
      "|    kl_loss             | 58.5     |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 68200    |\n",
      "|    penalty_temperature | 21.5     |\n",
      "|    policy_loss         | 60.5     |\n",
      "|    std                 | 7.31     |\n",
      "|    temperature         | 5.87     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 106       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 520       |\n",
      "|    fps                 | 126       |\n",
      "|    time_elapsed        | 625       |\n",
      "|    total_timesteps     | 78944     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.48e+09 |\n",
      "|    alpha_mean          | 17.4      |\n",
      "|    alpha_std           | 24.9      |\n",
      "|    critic_loss         | 2.18e+19  |\n",
      "|    dual_loss           | -1.48e+09 |\n",
      "|    kl_loss             | 46.7      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 68900     |\n",
      "|    penalty_temperature | 21.8      |\n",
      "|    policy_loss         | 59.7      |\n",
      "|    std                 | 7.61      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 108       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 524       |\n",
      "|    fps                 | 126       |\n",
      "|    time_elapsed        | 632       |\n",
      "|    total_timesteps     | 79658     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.34e+09 |\n",
      "|    alpha_mean          | 17.5      |\n",
      "|    alpha_std           | 25        |\n",
      "|    critic_loss         | 2.5e+19   |\n",
      "|    dual_loss           | -1.34e+09 |\n",
      "|    kl_loss             | 69.8      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 69650     |\n",
      "|    penalty_temperature | 22        |\n",
      "|    policy_loss         | 62.8      |\n",
      "|    std                 | 7.94      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 109       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 528       |\n",
      "|    fps                 | 125       |\n",
      "|    time_elapsed        | 636       |\n",
      "|    total_timesteps     | 80145     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.48e+09 |\n",
      "|    alpha_mean          | 17.6      |\n",
      "|    alpha_std           | 25.1      |\n",
      "|    critic_loss         | 2.89e+19  |\n",
      "|    dual_loss           | -1.48e+09 |\n",
      "|    kl_loss             | 64.4      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 70100     |\n",
      "|    penalty_temperature | 22.1      |\n",
      "|    policy_loss         | 62.4      |\n",
      "|    std                 | 8.16      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 110       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 532       |\n",
      "|    fps                 | 125       |\n",
      "|    time_elapsed        | 640       |\n",
      "|    total_timesteps     | 80585     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.76e+09 |\n",
      "|    alpha_mean          | 17.7      |\n",
      "|    alpha_std           | 25.1      |\n",
      "|    critic_loss         | 3.05e+19  |\n",
      "|    dual_loss           | -1.76e+09 |\n",
      "|    kl_loss             | 76        |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 70550     |\n",
      "|    penalty_temperature | 22.3      |\n",
      "|    policy_loss         | 64.2      |\n",
      "|    std                 | 8.38      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 111       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 536       |\n",
      "|    fps                 | 125       |\n",
      "|    time_elapsed        | 644       |\n",
      "|    total_timesteps     | 81018     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.96e+09 |\n",
      "|    alpha_mean          | 17.8      |\n",
      "|    alpha_std           | 25.2      |\n",
      "|    critic_loss         | 3.98e+19  |\n",
      "|    dual_loss           | -1.96e+09 |\n",
      "|    kl_loss             | 70        |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 71000     |\n",
      "|    penalty_temperature | 22.4      |\n",
      "|    policy_loss         | 63.7      |\n",
      "|    std                 | 8.62      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 112       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 540       |\n",
      "|    fps                 | 125       |\n",
      "|    time_elapsed        | 648       |\n",
      "|    total_timesteps     | 81495     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.55e+09 |\n",
      "|    alpha_mean          | 17.9      |\n",
      "|    alpha_std           | 25.3      |\n",
      "|    critic_loss         | 5.08e+19  |\n",
      "|    dual_loss           | -2.55e+09 |\n",
      "|    kl_loss             | 87.9      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 71450     |\n",
      "|    penalty_temperature | 22.6      |\n",
      "|    policy_loss         | 66        |\n",
      "|    std                 | 8.86      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 112       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 544       |\n",
      "|    fps                 | 125       |\n",
      "|    time_elapsed        | 652       |\n",
      "|    total_timesteps     | 81980     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.55e+09 |\n",
      "|    alpha_mean          | 18        |\n",
      "|    alpha_std           | 25.4      |\n",
      "|    critic_loss         | 5.24e+19  |\n",
      "|    dual_loss           | -2.55e+09 |\n",
      "|    kl_loss             | 89.9      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 71950     |\n",
      "|    penalty_temperature | 22.8      |\n",
      "|    policy_loss         | 66.6      |\n",
      "|    std                 | 9.14      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 113       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 548       |\n",
      "|    fps                 | 125       |\n",
      "|    time_elapsed        | 656       |\n",
      "|    total_timesteps     | 82388     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.96e+09 |\n",
      "|    alpha_mean          | 18.1      |\n",
      "|    alpha_std           | 25.5      |\n",
      "|    critic_loss         | 5.24e+19  |\n",
      "|    dual_loss           | -1.96e+09 |\n",
      "|    kl_loss             | 84.4      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 72350     |\n",
      "|    penalty_temperature | 22.9      |\n",
      "|    policy_loss         | 66.1      |\n",
      "|    std                 | 9.38      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 114       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 552       |\n",
      "|    fps                 | 125       |\n",
      "|    time_elapsed        | 661       |\n",
      "|    total_timesteps     | 82920     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.55e+09 |\n",
      "|    alpha_mean          | 18.2      |\n",
      "|    alpha_std           | 25.5      |\n",
      "|    critic_loss         | 6.82e+19  |\n",
      "|    dual_loss           | -2.55e+09 |\n",
      "|    kl_loss             | 77.8      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 72900     |\n",
      "|    penalty_temperature | 23.1      |\n",
      "|    policy_loss         | 65.7      |\n",
      "|    std                 | 9.72      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 114       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 556       |\n",
      "|    fps                 | 125       |\n",
      "|    time_elapsed        | 665       |\n",
      "|    total_timesteps     | 83369     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.39e+09 |\n",
      "|    alpha_mean          | 18.3      |\n",
      "|    alpha_std           | 25.6      |\n",
      "|    critic_loss         | 6.29e+19  |\n",
      "|    dual_loss           | -2.39e+09 |\n",
      "|    kl_loss             | 80.3      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 73350     |\n",
      "|    penalty_temperature | 23.2      |\n",
      "|    policy_loss         | 66.2      |\n",
      "|    std                 | 10        |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 116       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 560       |\n",
      "|    fps                 | 125       |\n",
      "|    time_elapsed        | 669       |\n",
      "|    total_timesteps     | 83862     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.57e+09 |\n",
      "|    alpha_mean          | 18.4      |\n",
      "|    alpha_std           | 25.7      |\n",
      "|    critic_loss         | 6.85e+19  |\n",
      "|    dual_loss           | -2.57e+09 |\n",
      "|    kl_loss             | 79.6      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 73850     |\n",
      "|    penalty_temperature | 23.4      |\n",
      "|    policy_loss         | 66.5      |\n",
      "|    std                 | 10.3      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 118       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 564       |\n",
      "|    fps                 | 125       |\n",
      "|    time_elapsed        | 675       |\n",
      "|    total_timesteps     | 84465     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.64e+09 |\n",
      "|    alpha_mean          | 18.5      |\n",
      "|    alpha_std           | 25.8      |\n",
      "|    critic_loss         | 7.95e+19  |\n",
      "|    dual_loss           | -2.64e+09 |\n",
      "|    kl_loss             | 76.4      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 74450     |\n",
      "|    penalty_temperature | 23.6      |\n",
      "|    policy_loss         | 66.5      |\n",
      "|    std                 | 10.8      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 119       |\n",
      "|    ep_rew_mean         | -129      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 568       |\n",
      "|    fps                 | 124       |\n",
      "|    time_elapsed        | 680       |\n",
      "|    total_timesteps     | 85005     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.87e+09 |\n",
      "|    alpha_mean          | 18.6      |\n",
      "|    alpha_std           | 25.9      |\n",
      "|    critic_loss         | 9.29e+19  |\n",
      "|    dual_loss           | -2.87e+09 |\n",
      "|    kl_loss             | 105       |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 75000     |\n",
      "|    penalty_temperature | 23.8      |\n",
      "|    policy_loss         | 69.9      |\n",
      "|    std                 | 11.2      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 120      |\n",
      "|    ep_rew_mean         | -128     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 572      |\n",
      "|    fps                 | 124      |\n",
      "|    time_elapsed        | 684      |\n",
      "|    total_timesteps     | 85495    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -3.1e+09 |\n",
      "|    alpha_mean          | 18.7     |\n",
      "|    alpha_std           | 26       |\n",
      "|    critic_loss         | 1.08e+20 |\n",
      "|    dual_loss           | -3.1e+09 |\n",
      "|    kl_loss             | 122      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 75450    |\n",
      "|    penalty_temperature | 23.9     |\n",
      "|    policy_loss         | 72.1     |\n",
      "|    std                 | 11.5     |\n",
      "|    temperature         | 5.87     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 119       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 576       |\n",
      "|    fps                 | 124       |\n",
      "|    time_elapsed        | 688       |\n",
      "|    total_timesteps     | 85924     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.45e+09 |\n",
      "|    alpha_mean          | 18.8      |\n",
      "|    alpha_std           | 26.1      |\n",
      "|    critic_loss         | 9.68e+19  |\n",
      "|    dual_loss           | -2.45e+09 |\n",
      "|    kl_loss             | 92        |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 75900     |\n",
      "|    penalty_temperature | 24.1      |\n",
      "|    policy_loss         | 69.2      |\n",
      "|    std                 | 11.9      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 120       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 580       |\n",
      "|    fps                 | 124       |\n",
      "|    time_elapsed        | 692       |\n",
      "|    total_timesteps     | 86370     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.41e+09 |\n",
      "|    alpha_mean          | 18.8      |\n",
      "|    alpha_std           | 26.2      |\n",
      "|    critic_loss         | 1.07e+20  |\n",
      "|    dual_loss           | -2.41e+09 |\n",
      "|    kl_loss             | 110       |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 76350     |\n",
      "|    penalty_temperature | 24.2      |\n",
      "|    policy_loss         | 71.3      |\n",
      "|    std                 | 12.3      |\n",
      "|    temperature         | 5.87      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 120       |\n",
      "|    ep_rew_mean         | -128      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 584       |\n",
      "|    fps                 | 124       |\n",
      "|    time_elapsed        | 696       |\n",
      "|    total_timesteps     | 86809     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -2.01e+09 |\n",
      "|    alpha_mean          | 18.9      |\n",
      "|    alpha_std           | 26.2      |\n",
      "|    critic_loss         | 1.07e+20  |\n",
      "|    dual_loss           | -2.01e+09 |\n",
      "|    kl_loss             | 171       |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 76800     |\n",
      "|    penalty_temperature | 24.4      |\n",
      "|    policy_loss         | 78.1      |\n",
      "|    std                 | 12.7      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 119      |\n",
      "|    ep_rew_mean         | -128     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 588      |\n",
      "|    fps                 | 124      |\n",
      "|    time_elapsed        | 700      |\n",
      "|    total_timesteps     | 87327    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -1.9e+09 |\n",
      "|    alpha_mean          | 19       |\n",
      "|    alpha_std           | 26.3     |\n",
      "|    critic_loss         | 1.21e+20 |\n",
      "|    dual_loss           | -1.9e+09 |\n",
      "|    kl_loss             | 120      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 77300    |\n",
      "|    penalty_temperature | 24.5     |\n",
      "|    policy_loss         | 73       |\n",
      "|    std                 | 13.2     |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 120      |\n",
      "|    ep_rew_mean         | -127     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 592      |\n",
      "|    fps                 | 124      |\n",
      "|    time_elapsed        | 704      |\n",
      "|    total_timesteps     | 87757    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | -2.2e+09 |\n",
      "|    alpha_mean          | 19.1     |\n",
      "|    alpha_std           | 26.4     |\n",
      "|    critic_loss         | 1.34e+20 |\n",
      "|    dual_loss           | -2.2e+09 |\n",
      "|    kl_loss             | 171      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 77750    |\n",
      "|    penalty_temperature | 24.7     |\n",
      "|    policy_loss         | 78.4     |\n",
      "|    std                 | 13.6     |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 121       |\n",
      "|    ep_rew_mean         | -127      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 596       |\n",
      "|    fps                 | 124       |\n",
      "|    time_elapsed        | 709       |\n",
      "|    total_timesteps     | 88274     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.59e+09 |\n",
      "|    alpha_mean          | 19.2      |\n",
      "|    alpha_std           | 26.5      |\n",
      "|    critic_loss         | 1.42e+20  |\n",
      "|    dual_loss           | -1.59e+09 |\n",
      "|    kl_loss             | 113       |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 78250     |\n",
      "|    penalty_temperature | 24.9      |\n",
      "|    policy_loss         | 72.8      |\n",
      "|    std                 | 14.2      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 120       |\n",
      "|    ep_rew_mean         | -127      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 600       |\n",
      "|    fps                 | 124       |\n",
      "|    time_elapsed        | 712       |\n",
      "|    total_timesteps     | 88647     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -1.47e+09 |\n",
      "|    alpha_mean          | 19.3      |\n",
      "|    alpha_std           | 26.5      |\n",
      "|    critic_loss         | 1.59e+20  |\n",
      "|    dual_loss           | -1.47e+09 |\n",
      "|    kl_loss             | 162       |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 78600     |\n",
      "|    penalty_temperature | 25        |\n",
      "|    policy_loss         | 77.8      |\n",
      "|    std                 | 14.5      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 122       |\n",
      "|    ep_rew_mean         | -127      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 604       |\n",
      "|    fps                 | 124       |\n",
      "|    time_elapsed        | 717       |\n",
      "|    total_timesteps     | 89170     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -8.99e+08 |\n",
      "|    alpha_mean          | 19.4      |\n",
      "|    alpha_std           | 26.6      |\n",
      "|    critic_loss         | 1.53e+20  |\n",
      "|    dual_loss           | -8.99e+08 |\n",
      "|    kl_loss             | 97.8      |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 79150     |\n",
      "|    penalty_temperature | 25.2      |\n",
      "|    policy_loss         | 71.7      |\n",
      "|    std                 | 15.2      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/               |           |\n",
      "|    ep_len_mean         | 122       |\n",
      "|    ep_rew_mean         | -127      |\n",
      "| time/                  |           |\n",
      "|    episodes            | 608       |\n",
      "|    fps                 | 124       |\n",
      "|    time_elapsed        | 721       |\n",
      "|    total_timesteps     | 89604     |\n",
      "| train/                 |           |\n",
      "|    actor_loss          | -8.44e+08 |\n",
      "|    alpha_mean          | 19.5      |\n",
      "|    alpha_std           | 26.7      |\n",
      "|    critic_loss         | 1.5e+20   |\n",
      "|    dual_loss           | -8.44e+08 |\n",
      "|    kl_loss             | 135       |\n",
      "|    learning_rate       | 0.0003    |\n",
      "|    n_updates           | 79600     |\n",
      "|    penalty_temperature | 25.3      |\n",
      "|    policy_loss         | 75.6      |\n",
      "|    std                 | 15.7      |\n",
      "|    temperature         | 5.88      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 124      |\n",
      "|    ep_rew_mean         | -127     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 612      |\n",
      "|    fps                 | 124      |\n",
      "|    time_elapsed        | 727      |\n",
      "|    total_timesteps     | 90248    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.01e+08 |\n",
      "|    alpha_mean          | 19.6     |\n",
      "|    alpha_std           | 26.8     |\n",
      "|    critic_loss         | 1.8e+20  |\n",
      "|    dual_loss           | 5.01e+08 |\n",
      "|    kl_loss             | 140      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 80200    |\n",
      "|    penalty_temperature | 25.5     |\n",
      "|    policy_loss         | 76.7     |\n",
      "|    std                 | 16.5     |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 125      |\n",
      "|    ep_rew_mean         | -127     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 616      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 731      |\n",
      "|    total_timesteps     | 90752    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.35e+09 |\n",
      "|    alpha_mean          | 19.8     |\n",
      "|    alpha_std           | 26.9     |\n",
      "|    critic_loss         | 1.85e+20 |\n",
      "|    dual_loss           | 1.35e+09 |\n",
      "|    kl_loss             | 160      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 80750    |\n",
      "|    penalty_temperature | 25.7     |\n",
      "|    policy_loss         | 78.9     |\n",
      "|    std                 | 17.2     |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 122      |\n",
      "|    ep_rew_mean         | -126     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 620      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 735      |\n",
      "|    total_timesteps     | 91115    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.26e+09 |\n",
      "|    alpha_mean          | 19.8     |\n",
      "|    alpha_std           | 26.9     |\n",
      "|    critic_loss         | 1.68e+20 |\n",
      "|    dual_loss           | 2.26e+09 |\n",
      "|    kl_loss             | 170      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 81100    |\n",
      "|    penalty_temperature | 25.8     |\n",
      "|    policy_loss         | 80.1     |\n",
      "|    std                 | 17.7     |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 118      |\n",
      "|    ep_rew_mean         | -126     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 624      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 738      |\n",
      "|    total_timesteps     | 91453    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.54e+09 |\n",
      "|    alpha_mean          | 19.9     |\n",
      "|    alpha_std           | 27       |\n",
      "|    critic_loss         | 1.9e+20  |\n",
      "|    dual_loss           | 2.54e+09 |\n",
      "|    kl_loss             | 189      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 81450    |\n",
      "|    penalty_temperature | 25.9     |\n",
      "|    policy_loss         | 82.2     |\n",
      "|    std                 | 18.2     |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 117      |\n",
      "|    ep_rew_mean         | -126     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 628      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 741      |\n",
      "|    total_timesteps     | 91842    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.99e+09 |\n",
      "|    alpha_mean          | 20       |\n",
      "|    alpha_std           | 27       |\n",
      "|    critic_loss         | 1.94e+20 |\n",
      "|    dual_loss           | 3.99e+09 |\n",
      "|    kl_loss             | 132      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 81800    |\n",
      "|    penalty_temperature | 26       |\n",
      "|    policy_loss         | 76.6     |\n",
      "|    std                 | 18.8     |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 117      |\n",
      "|    ep_rew_mean         | -125     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 632      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 745      |\n",
      "|    total_timesteps     | 92333    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.22e+09 |\n",
      "|    alpha_mean          | 20.1     |\n",
      "|    alpha_std           | 27.1     |\n",
      "|    critic_loss         | 2.1e+20  |\n",
      "|    dual_loss           | 4.22e+09 |\n",
      "|    kl_loss             | 159      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 82300    |\n",
      "|    penalty_temperature | 26.2     |\n",
      "|    policy_loss         | 79.7     |\n",
      "|    std                 | 19.6     |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 117      |\n",
      "|    ep_rew_mean         | -125     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 636      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 749      |\n",
      "|    total_timesteps     | 92756    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.47e+09 |\n",
      "|    alpha_mean          | 20.2     |\n",
      "|    alpha_std           | 27.2     |\n",
      "|    critic_loss         | 2.15e+20 |\n",
      "|    dual_loss           | 5.47e+09 |\n",
      "|    kl_loss             | 260      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 82750    |\n",
      "|    penalty_temperature | 26.3     |\n",
      "|    policy_loss         | 90       |\n",
      "|    std                 | 20.4     |\n",
      "|    temperature         | 5.89     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 117      |\n",
      "|    ep_rew_mean         | -125     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 640      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 753      |\n",
      "|    total_timesteps     | 93197    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.78e+09 |\n",
      "|    alpha_mean          | 20.3     |\n",
      "|    alpha_std           | 27.2     |\n",
      "|    critic_loss         | 2.29e+20 |\n",
      "|    dual_loss           | 6.78e+09 |\n",
      "|    kl_loss             | 171      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 83150    |\n",
      "|    penalty_temperature | 26.5     |\n",
      "|    policy_loss         | 81.3     |\n",
      "|    std                 | 21.2     |\n",
      "|    temperature         | 5.89     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 116      |\n",
      "|    ep_rew_mean         | -125     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 644      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 756      |\n",
      "|    total_timesteps     | 93535    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 7.91e+09 |\n",
      "|    alpha_mean          | 20.4     |\n",
      "|    alpha_std           | 27.2     |\n",
      "|    critic_loss         | 2.52e+20 |\n",
      "|    dual_loss           | 7.91e+09 |\n",
      "|    kl_loss             | 247      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 83500    |\n",
      "|    penalty_temperature | 26.6     |\n",
      "|    policy_loss         | 88.8     |\n",
      "|    std                 | 21.9     |\n",
      "|    temperature         | 5.89     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 115      |\n",
      "|    ep_rew_mean         | -125     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 648      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 760      |\n",
      "|    total_timesteps     | 93928    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 8.79e+09 |\n",
      "|    alpha_mean          | 20.5     |\n",
      "|    alpha_std           | 27.3     |\n",
      "|    critic_loss         | 2.43e+20 |\n",
      "|    dual_loss           | 8.79e+09 |\n",
      "|    kl_loss             | 214      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 83900    |\n",
      "|    penalty_temperature | 26.7     |\n",
      "|    policy_loss         | 85.9     |\n",
      "|    std                 | 22.8     |\n",
      "|    temperature         | 5.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 114      |\n",
      "|    ep_rew_mean         | -124     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 652      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 763      |\n",
      "|    total_timesteps     | 94335    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.03e+10 |\n",
      "|    alpha_mean          | 20.6     |\n",
      "|    alpha_std           | 27.3     |\n",
      "|    critic_loss         | 2.5e+20  |\n",
      "|    dual_loss           | 1.03e+10 |\n",
      "|    kl_loss             | 303      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 84300    |\n",
      "|    penalty_temperature | 26.9     |\n",
      "|    policy_loss         | 94.8     |\n",
      "|    std                 | 23.8     |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 114      |\n",
      "|    ep_rew_mean         | -125     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 656      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 767      |\n",
      "|    total_timesteps     | 94732    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.12e+10 |\n",
      "|    alpha_mean          | 20.7     |\n",
      "|    alpha_std           | 27.4     |\n",
      "|    critic_loss         | 2.87e+20 |\n",
      "|    dual_loss           | 1.12e+10 |\n",
      "|    kl_loss             | 172      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 84700    |\n",
      "|    penalty_temperature | 27       |\n",
      "|    policy_loss         | 82.3     |\n",
      "|    std                 | 24.8     |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 113      |\n",
      "|    ep_rew_mean         | -124     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 660      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 771      |\n",
      "|    total_timesteps     | 95200    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.28e+10 |\n",
      "|    alpha_mean          | 20.8     |\n",
      "|    alpha_std           | 27.4     |\n",
      "|    critic_loss         | 3.27e+20 |\n",
      "|    dual_loss           | 1.28e+10 |\n",
      "|    kl_loss             | 341      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 85150    |\n",
      "|    penalty_temperature | 27.1     |\n",
      "|    policy_loss         | 98.8     |\n",
      "|    std                 | 26       |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 115      |\n",
      "|    ep_rew_mean         | -124     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 664      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 778      |\n",
      "|    total_timesteps     | 95993    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.55e+10 |\n",
      "|    alpha_mean          | 20.9     |\n",
      "|    alpha_std           | 27.5     |\n",
      "|    critic_loss         | 3.96e+20 |\n",
      "|    dual_loss           | 1.55e+10 |\n",
      "|    kl_loss             | 268      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 85950    |\n",
      "|    penalty_temperature | 27.4     |\n",
      "|    policy_loss         | 92.1     |\n",
      "|    std                 | 28.4     |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 114      |\n",
      "|    ep_rew_mean         | -124     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 668      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 782      |\n",
      "|    total_timesteps     | 96368    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.74e+10 |\n",
      "|    alpha_mean          | 21       |\n",
      "|    alpha_std           | 27.5     |\n",
      "|    critic_loss         | 4.39e+20 |\n",
      "|    dual_loss           | 1.74e+10 |\n",
      "|    kl_loss             | 324      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 86350    |\n",
      "|    penalty_temperature | 27.5     |\n",
      "|    policy_loss         | 97.7     |\n",
      "|    std                 | 29.8     |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 115      |\n",
      "|    ep_rew_mean         | -124     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 672      |\n",
      "|    fps                 | 123      |\n",
      "|    time_elapsed        | 787      |\n",
      "|    total_timesteps     | 96988    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.05e+10 |\n",
      "|    alpha_mean          | 21.1     |\n",
      "|    alpha_std           | 27.5     |\n",
      "|    critic_loss         | 5.42e+20 |\n",
      "|    dual_loss           | 2.05e+10 |\n",
      "|    kl_loss             | 227      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 86950    |\n",
      "|    penalty_temperature | 27.7     |\n",
      "|    policy_loss         | 88.6     |\n",
      "|    std                 | 32.1     |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 117      |\n",
      "|    ep_rew_mean         | -125     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 676      |\n",
      "|    fps                 | 122      |\n",
      "|    time_elapsed        | 794      |\n",
      "|    total_timesteps     | 97664    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.46e+10 |\n",
      "|    alpha_mean          | 21.3     |\n",
      "|    alpha_std           | 27.6     |\n",
      "|    critic_loss         | 6.13e+20 |\n",
      "|    dual_loss           | 2.46e+10 |\n",
      "|    kl_loss             | 278      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 87650    |\n",
      "|    penalty_temperature | 28       |\n",
      "|    policy_loss         | 93.8     |\n",
      "|    std                 | 35       |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 118      |\n",
      "|    ep_rew_mean         | -125     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 680      |\n",
      "|    fps                 | 122      |\n",
      "|    time_elapsed        | 798      |\n",
      "|    total_timesteps     | 98200    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.85e+10 |\n",
      "|    alpha_mean          | 21.4     |\n",
      "|    alpha_std           | 27.6     |\n",
      "|    critic_loss         | 6.95e+20 |\n",
      "|    dual_loss           | 2.85e+10 |\n",
      "|    kl_loss             | 373      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 88150    |\n",
      "|    penalty_temperature | 28.1     |\n",
      "|    policy_loss         | 103      |\n",
      "|    std                 | 37.5     |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 119      |\n",
      "|    ep_rew_mean         | -125     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 684      |\n",
      "|    fps                 | 122      |\n",
      "|    time_elapsed        | 804      |\n",
      "|    total_timesteps     | 98756    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.35e+10 |\n",
      "|    alpha_mean          | 21.5     |\n",
      "|    alpha_std           | 27.6     |\n",
      "|    critic_loss         | 1.04e+21 |\n",
      "|    dual_loss           | 3.35e+10 |\n",
      "|    kl_loss             | 358      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 88750    |\n",
      "|    penalty_temperature | 28.3     |\n",
      "|    policy_loss         | 102      |\n",
      "|    std                 | 40.6     |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 119      |\n",
      "|    ep_rew_mean         | -125     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 688      |\n",
      "|    fps                 | 122      |\n",
      "|    time_elapsed        | 807      |\n",
      "|    total_timesteps     | 99189    |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.69e+10 |\n",
      "|    alpha_mean          | 21.6     |\n",
      "|    alpha_std           | 27.6     |\n",
      "|    critic_loss         | 1.08e+21 |\n",
      "|    dual_loss           | 3.69e+10 |\n",
      "|    kl_loss             | 393      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 89150    |\n",
      "|    penalty_temperature | 28.5     |\n",
      "|    policy_loss         | 105      |\n",
      "|    std                 | 43       |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 135      |\n",
      "|    ep_rew_mean         | -126     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 692      |\n",
      "|    fps                 | 122      |\n",
      "|    time_elapsed        | 826      |\n",
      "|    total_timesteps     | 101210   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.19e+10 |\n",
      "|    alpha_mean          | 22.1     |\n",
      "|    alpha_std           | 27.6     |\n",
      "|    critic_loss         | 2.53e+21 |\n",
      "|    dual_loss           | 6.19e+10 |\n",
      "|    kl_loss             | 583      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 91200    |\n",
      "|    penalty_temperature | 29.1     |\n",
      "|    policy_loss         | 123      |\n",
      "|    std                 | 57.5     |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 163      |\n",
      "|    ep_rew_mean         | -127     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 696      |\n",
      "|    fps                 | 121      |\n",
      "|    time_elapsed        | 857      |\n",
      "|    total_timesteps     | 104561   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.34e+11 |\n",
      "|    alpha_mean          | 22.7     |\n",
      "|    alpha_std           | 27.4     |\n",
      "|    critic_loss         | 7.89e+21 |\n",
      "|    dual_loss           | 1.34e+11 |\n",
      "|    kl_loss             | 585      |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 94550    |\n",
      "|    penalty_temperature | 30.2     |\n",
      "|    policy_loss         | 124      |\n",
      "|    std                 | 94.6     |\n",
      "|    temperature         | 5.92     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 209      |\n",
      "|    ep_rew_mean         | -128     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 700      |\n",
      "|    fps                 | 121      |\n",
      "|    time_elapsed        | 902      |\n",
      "|    total_timesteps     | 109516   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.85e+11 |\n",
      "|    alpha_mean          | 23.8     |\n",
      "|    alpha_std           | 27.1     |\n",
      "|    critic_loss         | 4.95e+22 |\n",
      "|    dual_loss           | 3.85e+11 |\n",
      "|    kl_loss             | 1.57e+03 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 99500    |\n",
      "|    penalty_temperature | 31.8     |\n",
      "|    policy_loss         | 206      |\n",
      "|    std                 | 200      |\n",
      "|    temperature         | 5.93     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 267      |\n",
      "|    ep_rew_mean         | -130     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 704      |\n",
      "|    fps                 | 120      |\n",
      "|    time_elapsed        | 959      |\n",
      "|    total_timesteps     | 115916   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.31e+12 |\n",
      "|    alpha_mean          | 25.2     |\n",
      "|    alpha_std           | 26.8     |\n",
      "|    critic_loss         | 4.23e+23 |\n",
      "|    dual_loss           | 1.31e+12 |\n",
      "|    kl_loss             | 7.92e+03 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 105900   |\n",
      "|    penalty_temperature | 33.8     |\n",
      "|    policy_loss         | 698      |\n",
      "|    std                 | 510      |\n",
      "|    temperature         | 5.93     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 282      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 708      |\n",
      "|    fps                 | 120      |\n",
      "|    time_elapsed        | 976      |\n",
      "|    total_timesteps     | 117820   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.81e+12 |\n",
      "|    alpha_mean          | 25.6     |\n",
      "|    alpha_std           | 26.8     |\n",
      "|    critic_loss         | 7.96e+23 |\n",
      "|    dual_loss           | 1.81e+12 |\n",
      "|    kl_loss             | 1.23e+04 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 107800   |\n",
      "|    penalty_temperature | 34.4     |\n",
      "|    policy_loss         | 1.02e+03 |\n",
      "|    std                 | 665      |\n",
      "|    temperature         | 5.93     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 325      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 712      |\n",
      "|    fps                 | 120      |\n",
      "|    time_elapsed        | 1021     |\n",
      "|    total_timesteps     | 122742   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.75e+12 |\n",
      "|    alpha_mean          | 26.8     |\n",
      "|    alpha_std           | 26.5     |\n",
      "|    critic_loss         | 2.89e+24 |\n",
      "|    dual_loss           | 3.75e+12 |\n",
      "|    kl_loss             | 2.79e+04 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 112700   |\n",
      "|    penalty_temperature | 35.8     |\n",
      "|    policy_loss         | 2.12e+03 |\n",
      "|    std                 | 1.28e+03 |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 384      |\n",
      "|    ep_rew_mean         | -135     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 716      |\n",
      "|    fps                 | 119      |\n",
      "|    time_elapsed        | 1078     |\n",
      "|    total_timesteps     | 129142   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 8.44e+12 |\n",
      "|    alpha_mean          | 28.2     |\n",
      "|    alpha_std           | 26.3     |\n",
      "|    critic_loss         | 1.22e+25 |\n",
      "|    dual_loss           | 8.44e+12 |\n",
      "|    kl_loss             | 1e+05    |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 119100   |\n",
      "|    penalty_temperature | 37.8     |\n",
      "|    policy_loss         | 6.97e+03 |\n",
      "|    std                 | 2.82e+03 |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 429      |\n",
      "|    ep_rew_mean         | -138     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 720      |\n",
      "|    fps                 | 119      |\n",
      "|    time_elapsed        | 1123     |\n",
      "|    total_timesteps     | 134004   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.45e+13 |\n",
      "|    alpha_mean          | 29.2     |\n",
      "|    alpha_std           | 26.1     |\n",
      "|    critic_loss         | 3.27e+25 |\n",
      "|    dual_loss           | 1.45e+13 |\n",
      "|    kl_loss             | 1.51e+05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 124000   |\n",
      "|    penalty_temperature | 39.2     |\n",
      "|    policy_loss         | 1.01e+04 |\n",
      "|    std                 | 4.93e+03 |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 474      |\n",
      "|    ep_rew_mean         | -139     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 724      |\n",
      "|    fps                 | 118      |\n",
      "|    time_elapsed        | 1168     |\n",
      "|    total_timesteps     | 138894   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.34e+13 |\n",
      "|    alpha_mean          | 30.2     |\n",
      "|    alpha_std           | 26       |\n",
      "|    critic_loss         | 8.07e+25 |\n",
      "|    dual_loss           | 2.34e+13 |\n",
      "|    kl_loss             | 3.61e+05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 128850   |\n",
      "|    penalty_temperature | 40.7     |\n",
      "|    policy_loss         | 2.3e+04  |\n",
      "|    std                 | 8.31e+03 |\n",
      "|    temperature         | 5.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 490      |\n",
      "|    ep_rew_mean         | -140     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 728      |\n",
      "|    fps                 | 118      |\n",
      "|    time_elapsed        | 1186     |\n",
      "|    total_timesteps     | 140820   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.81e+13 |\n",
      "|    alpha_mean          | 30.5     |\n",
      "|    alpha_std           | 25.9     |\n",
      "|    critic_loss         | 1.1e+26  |\n",
      "|    dual_loss           | 2.81e+13 |\n",
      "|    kl_loss             | 4.03e+05 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 130800   |\n",
      "|    penalty_temperature | 41.3     |\n",
      "|    policy_loss         | 2.53e+04 |\n",
      "|    std                 | 1.02e+04 |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 549      |\n",
      "|    ep_rew_mean         | -142     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 732      |\n",
      "|    fps                 | 118      |\n",
      "|    time_elapsed        | 1245     |\n",
      "|    total_timesteps     | 147220   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.91e+13 |\n",
      "|    alpha_mean          | 31.4     |\n",
      "|    alpha_std           | 25.9     |\n",
      "|    critic_loss         | 2.98e+26 |\n",
      "|    dual_loss           | 4.91e+13 |\n",
      "|    kl_loss             | 1.18e+06 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 137200   |\n",
      "|    penalty_temperature | 43.2     |\n",
      "|    policy_loss         | 7.06e+04 |\n",
      "|    std                 | 1.91e+04 |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 578      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 736      |\n",
      "|    fps                 | 117      |\n",
      "|    time_elapsed        | 1276     |\n",
      "|    total_timesteps     | 150561   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.51e+13 |\n",
      "|    alpha_mean          | 31.8     |\n",
      "|    alpha_std           | 25.9     |\n",
      "|    critic_loss         | 4.84e+26 |\n",
      "|    dual_loss           | 6.51e+13 |\n",
      "|    kl_loss             | 1.62e+06 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 140550   |\n",
      "|    penalty_temperature | 44.2     |\n",
      "|    policy_loss         | 9.49e+04 |\n",
      "|    std                 | 2.61e+04 |\n",
      "|    temperature         | 5.86     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 622      |\n",
      "|    ep_rew_mean         | -145     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 740      |\n",
      "|    fps                 | 117      |\n",
      "|    time_elapsed        | 1320     |\n",
      "|    total_timesteps     | 155430   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.87e+13 |\n",
      "|    alpha_mean          | 32.3     |\n",
      "|    alpha_std           | 25.9     |\n",
      "|    critic_loss         | 1.01e+27 |\n",
      "|    dual_loss           | 9.87e+13 |\n",
      "|    kl_loss             | 3.46e+06 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 145400   |\n",
      "|    penalty_temperature | 45.7     |\n",
      "|    policy_loss         | 1.95e+05 |\n",
      "|    std                 | 4.02e+04 |\n",
      "|    temperature         | 5.82     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 668      |\n",
      "|    ep_rew_mean         | -147     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 744      |\n",
      "|    fps                 | 117      |\n",
      "|    time_elapsed        | 1364     |\n",
      "|    total_timesteps     | 160293   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.49e+14 |\n",
      "|    alpha_mean          | 32.9     |\n",
      "|    alpha_std           | 25.9     |\n",
      "|    critic_loss         | 2.15e+27 |\n",
      "|    dual_loss           | 1.49e+14 |\n",
      "|    kl_loss             | 4.95e+06 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 150250   |\n",
      "|    penalty_temperature | 47.2     |\n",
      "|    policy_loss         | 2.7e+05  |\n",
      "|    std                 | 6.11e+04 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 713      |\n",
      "|    ep_rew_mean         | -149     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 748      |\n",
      "|    fps                 | 116      |\n",
      "|    time_elapsed        | 1412     |\n",
      "|    total_timesteps     | 165205   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.17e+14 |\n",
      "|    alpha_mean          | 33.4     |\n",
      "|    alpha_std           | 26       |\n",
      "|    critic_loss         | 4.19e+27 |\n",
      "|    dual_loss           | 2.17e+14 |\n",
      "|    kl_loss             | 1.06e+07 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 155200   |\n",
      "|    penalty_temperature | 48.6     |\n",
      "|    policy_loss         | 5.6e+05  |\n",
      "|    std                 | 9.17e+04 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 728      |\n",
      "|    ep_rew_mean         | -149     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 752      |\n",
      "|    fps                 | 116      |\n",
      "|    time_elapsed        | 1429     |\n",
      "|    total_timesteps     | 167137   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.51e+14 |\n",
      "|    alpha_mean          | 33.6     |\n",
      "|    alpha_std           | 26       |\n",
      "|    critic_loss         | 5.64e+27 |\n",
      "|    dual_loss           | 2.51e+14 |\n",
      "|    kl_loss             | 1.33e+07 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 157100   |\n",
      "|    penalty_temperature | 49.2     |\n",
      "|    policy_loss         | 6.97e+05 |\n",
      "|    std                 | 1.07e+05 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 788      |\n",
      "|    ep_rew_mean         | -152     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 756      |\n",
      "|    fps                 | 116      |\n",
      "|    time_elapsed        | 1488     |\n",
      "|    total_timesteps     | 173537   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.09e+14 |\n",
      "|    alpha_mean          | 34.2     |\n",
      "|    alpha_std           | 26       |\n",
      "|    critic_loss         | 1.37e+28 |\n",
      "|    dual_loss           | 4.09e+14 |\n",
      "|    kl_loss             | 3.33e+07 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 163500   |\n",
      "|    penalty_temperature | 51.2     |\n",
      "|    policy_loss         | 1.68e+06 |\n",
      "|    std                 | 1.76e+05 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 832      |\n",
      "|    ep_rew_mean         | -154     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 760      |\n",
      "|    fps                 | 116      |\n",
      "|    time_elapsed        | 1534     |\n",
      "|    total_timesteps     | 178449   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.83e+14 |\n",
      "|    alpha_mean          | 34.7     |\n",
      "|    alpha_std           | 25.9     |\n",
      "|    critic_loss         | 2.6e+28  |\n",
      "|    dual_loss           | 5.83e+14 |\n",
      "|    kl_loss             | 4.9e+07  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 168400   |\n",
      "|    penalty_temperature | 52.6     |\n",
      "|    policy_loss         | 2.4e+06  |\n",
      "|    std                 | 2.53e+05 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 843      |\n",
      "|    ep_rew_mean         | -153     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 764      |\n",
      "|    fps                 | 116      |\n",
      "|    time_elapsed        | 1552     |\n",
      "|    total_timesteps     | 180342   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.66e+14 |\n",
      "|    alpha_mean          | 34.9     |\n",
      "|    alpha_std           | 25.9     |\n",
      "|    critic_loss         | 3.24e+28 |\n",
      "|    dual_loss           | 6.66e+14 |\n",
      "|    kl_loss             | 4.94e+07 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 170300   |\n",
      "|    penalty_temperature | 53.2     |\n",
      "|    policy_loss         | 2.39e+06 |\n",
      "|    std                 | 2.91e+05 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 858      |\n",
      "|    ep_rew_mean         | -154     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 768      |\n",
      "|    fps                 | 116      |\n",
      "|    time_elapsed        | 1568     |\n",
      "|    total_timesteps     | 182150   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 7.55e+14 |\n",
      "|    alpha_mean          | 35.1     |\n",
      "|    alpha_std           | 26       |\n",
      "|    critic_loss         | 4.13e+28 |\n",
      "|    dual_loss           | 7.55e+14 |\n",
      "|    kl_loss             | 5.89e+07 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 172100   |\n",
      "|    penalty_temperature | 53.7     |\n",
      "|    policy_loss         | 2.82e+06 |\n",
      "|    std                 | 3.32e+05 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 885      |\n",
      "|    ep_rew_mean         | -155     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 772      |\n",
      "|    fps                 | 115      |\n",
      "|    time_elapsed        | 1599     |\n",
      "|    total_timesteps     | 185487   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.46e+14 |\n",
      "|    alpha_mean          | 35.4     |\n",
      "|    alpha_std           | 26.2     |\n",
      "|    critic_loss         | 6.23e+28 |\n",
      "|    dual_loss           | 9.46e+14 |\n",
      "|    kl_loss             | 6.96e+07 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 175450   |\n",
      "|    penalty_temperature | 54.8     |\n",
      "|    policy_loss         | 3.27e+06 |\n",
      "|    std                 | 4.21e+05 |\n",
      "|    temperature         | 5.84     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 927      |\n",
      "|    ep_rew_mean         | -156     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 776      |\n",
      "|    fps                 | 115      |\n",
      "|    time_elapsed        | 1645     |\n",
      "|    total_timesteps     | 190337   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.31e+15 |\n",
      "|    alpha_mean          | 36       |\n",
      "|    alpha_std           | 26.2     |\n",
      "|    critic_loss         | 1.15e+29 |\n",
      "|    dual_loss           | 1.31e+15 |\n",
      "|    kl_loss             | 1.29e+08 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 180300   |\n",
      "|    penalty_temperature | 56.2     |\n",
      "|    policy_loss         | 5.9e+06  |\n",
      "|    std                 | 5.89e+05 |\n",
      "|    temperature         | 5.84     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 940      |\n",
      "|    ep_rew_mean         | -156     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 780      |\n",
      "|    fps                 | 115      |\n",
      "|    time_elapsed        | 1662     |\n",
      "|    total_timesteps     | 192186   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.49e+15 |\n",
      "|    alpha_mean          | 36.2     |\n",
      "|    alpha_std           | 26.3     |\n",
      "|    critic_loss         | 1.46e+29 |\n",
      "|    dual_loss           | 1.49e+15 |\n",
      "|    kl_loss             | 1.66e+08 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 182150   |\n",
      "|    penalty_temperature | 56.8     |\n",
      "|    policy_loss         | 7.5e+06  |\n",
      "|    std                 | 6.68e+05 |\n",
      "|    temperature         | 5.84     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 953      |\n",
      "|    ep_rew_mean         | -156     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 784      |\n",
      "|    fps                 | 115      |\n",
      "|    time_elapsed        | 1681     |\n",
      "|    total_timesteps     | 194082   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.69e+15 |\n",
      "|    alpha_mean          | 36.4     |\n",
      "|    alpha_std           | 26.4     |\n",
      "|    critic_loss         | 1.85e+29 |\n",
      "|    dual_loss           | 1.69e+15 |\n",
      "|    kl_loss             | 1.8e+08  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 184050   |\n",
      "|    penalty_temperature | 57.3     |\n",
      "|    policy_loss         | 8.03e+06 |\n",
      "|    std                 | 7.6e+05  |\n",
      "|    temperature         | 5.84     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 999      |\n",
      "|    ep_rew_mean         | -158     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 788      |\n",
      "|    fps                 | 115      |\n",
      "|    time_elapsed        | 1728     |\n",
      "|    total_timesteps     | 199060   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.34e+15 |\n",
      "|    alpha_mean          | 36.9     |\n",
      "|    alpha_std           | 26.6     |\n",
      "|    critic_loss         | 3.5e+29  |\n",
      "|    dual_loss           | 2.34e+15 |\n",
      "|    kl_loss             | 3.13e+08 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 189050   |\n",
      "|    penalty_temperature | 58.8     |\n",
      "|    policy_loss         | 1.36e+07 |\n",
      "|    std                 | 1.06e+06 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 1.01e+03 |\n",
      "|    ep_rew_mean         | -158     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 792      |\n",
      "|    fps                 | 115      |\n",
      "|    time_elapsed        | 1759     |\n",
      "|    total_timesteps     | 202426   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.87e+15 |\n",
      "|    alpha_mean          | 37.2     |\n",
      "|    alpha_std           | 26.7     |\n",
      "|    critic_loss         | 5.15e+29 |\n",
      "|    dual_loss           | 2.87e+15 |\n",
      "|    kl_loss             | 3.23e+08 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 192400   |\n",
      "|    penalty_temperature | 59.9     |\n",
      "|    policy_loss         | 1.38e+07 |\n",
      "|    std                 | 1.32e+06 |\n",
      "|    temperature         | 5.85     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 1.01e+03 |\n",
      "|    ep_rew_mean         | -158     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 796      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 1790     |\n",
      "|    total_timesteps     | 205770   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.55e+15 |\n",
      "|    alpha_mean          | 37.6     |\n",
      "|    alpha_std           | 26.7     |\n",
      "|    critic_loss         | 7.57e+29 |\n",
      "|    dual_loss           | 3.55e+15 |\n",
      "|    kl_loss             | 6.11e+08 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 195750   |\n",
      "|    penalty_temperature | 60.9     |\n",
      "|    policy_loss         | 2.57e+07 |\n",
      "|    std                 | 1.63e+06 |\n",
      "|    temperature         | 5.85     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 981      |\n",
      "|    ep_rew_mean         | -157     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 800      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 1807     |\n",
      "|    total_timesteps     | 207659   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.98e+15 |\n",
      "|    alpha_mean          | 37.8     |\n",
      "|    alpha_std           | 26.8     |\n",
      "|    critic_loss         | 9.55e+29 |\n",
      "|    dual_loss           | 3.98e+15 |\n",
      "|    kl_loss             | 5.86e+08 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 197650   |\n",
      "|    penalty_temperature | 61.4     |\n",
      "|    policy_loss         | 2.44e+07 |\n",
      "|    std                 | 1.84e+06 |\n",
      "|    temperature         | 5.82     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 951      |\n",
      "|    ep_rew_mean         | -156     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 804      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 1838     |\n",
      "|    total_timesteps     | 211036   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.88e+15 |\n",
      "|    alpha_mean          | 38.2     |\n",
      "|    alpha_std           | 26.9     |\n",
      "|    critic_loss         | 1.4e+30  |\n",
      "|    dual_loss           | 4.88e+15 |\n",
      "|    kl_loss             | 8.15e+08 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 201000   |\n",
      "|    penalty_temperature | 62.4     |\n",
      "|    policy_loss         | 3.34e+07 |\n",
      "|    std                 | 2.26e+06 |\n",
      "|    temperature         | 5.81     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 967      |\n",
      "|    ep_rew_mean         | -157     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 808      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 1871     |\n",
      "|    total_timesteps     | 214504   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.03e+15 |\n",
      "|    alpha_mean          | 38.5     |\n",
      "|    alpha_std           | 27       |\n",
      "|    critic_loss         | 2.12e+30 |\n",
      "|    dual_loss           | 6.03e+15 |\n",
      "|    kl_loss             | 1.02e+09 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 204500   |\n",
      "|    penalty_temperature | 63.5     |\n",
      "|    policy_loss         | 4.12e+07 |\n",
      "|    std                 | 2.81e+06 |\n",
      "|    temperature         | 5.81     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 936      |\n",
      "|    ep_rew_mean         | -156     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 812      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 1888     |\n",
      "|    total_timesteps     | 216339   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.73e+15 |\n",
      "|    alpha_mean          | 38.7     |\n",
      "|    alpha_std           | 27.1     |\n",
      "|    critic_loss         | 2.68e+30 |\n",
      "|    dual_loss           | 6.73e+15 |\n",
      "|    kl_loss             | 1.1e+09  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 206300   |\n",
      "|    penalty_temperature | 64       |\n",
      "|    policy_loss         | 4.4e+07  |\n",
      "|    std                 | 3.13e+06 |\n",
      "|    temperature         | 5.82     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 891      |\n",
      "|    ep_rew_mean         | -154     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 816      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 1906     |\n",
      "|    total_timesteps     | 218261   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 7.59e+15 |\n",
      "|    alpha_mean          | 38.9     |\n",
      "|    alpha_std           | 27.2     |\n",
      "|    critic_loss         | 3.33e+30 |\n",
      "|    dual_loss           | 7.59e+15 |\n",
      "|    kl_loss             | 1.12e+09 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 208250   |\n",
      "|    penalty_temperature | 64.6     |\n",
      "|    policy_loss         | 4.43e+07 |\n",
      "|    std                 | 3.52e+06 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 861      |\n",
      "|    ep_rew_mean         | -151     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 820      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 1922     |\n",
      "|    total_timesteps     | 220080   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 8.36e+15 |\n",
      "|    alpha_mean          | 39.1     |\n",
      "|    alpha_std           | 27.2     |\n",
      "|    critic_loss         | 3.99e+30 |\n",
      "|    dual_loss           | 8.36e+15 |\n",
      "|    kl_loss             | 1.55e+09 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 210050   |\n",
      "|    penalty_temperature | 65.1     |\n",
      "|    policy_loss         | 6.07e+07 |\n",
      "|    std                 | 3.92e+06 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 831      |\n",
      "|    ep_rew_mean         | -150     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 824      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 1940     |\n",
      "|    total_timesteps     | 221968   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.38e+15 |\n",
      "|    alpha_mean          | 39.3     |\n",
      "|    alpha_std           | 27.3     |\n",
      "|    critic_loss         | 5.03e+30 |\n",
      "|    dual_loss           | 9.38e+15 |\n",
      "|    kl_loss             | 1.43e+09 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 211950   |\n",
      "|    penalty_temperature | 65.7     |\n",
      "|    policy_loss         | 5.55e+07 |\n",
      "|    std                 | 4.38e+06 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 860      |\n",
      "|    ep_rew_mean         | -151     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 828      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 1984     |\n",
      "|    total_timesteps     | 226839   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.24e+16 |\n",
      "|    alpha_mean          | 39.8     |\n",
      "|    alpha_std           | 27.4     |\n",
      "|    critic_loss         | 8.57e+30 |\n",
      "|    dual_loss           | 1.24e+16 |\n",
      "|    kl_loss             | 2.62e+09 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 216800   |\n",
      "|    penalty_temperature | 67.2     |\n",
      "|    policy_loss         | 9.96e+07 |\n",
      "|    std                 | 5.82e+06 |\n",
      "|    temperature         | 5.81     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 815      |\n",
      "|    ep_rew_mean         | -149     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 832      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 2000     |\n",
      "|    total_timesteps     | 228693   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.37e+16 |\n",
      "|    alpha_mean          | 40       |\n",
      "|    alpha_std           | 27.5     |\n",
      "|    critic_loss         | 1.09e+31 |\n",
      "|    dual_loss           | 1.37e+16 |\n",
      "|    kl_loss             | 3e+09    |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 218650   |\n",
      "|    penalty_temperature | 67.7     |\n",
      "|    policy_loss         | 1.13e+08 |\n",
      "|    std                 | 6.47e+06 |\n",
      "|    temperature         | 5.81     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 785      |\n",
      "|    ep_rew_mean         | -148     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 836      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 2004     |\n",
      "|    total_timesteps     | 229054   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.4e+16  |\n",
      "|    alpha_mean          | 40.1     |\n",
      "|    alpha_std           | 27.6     |\n",
      "|    critic_loss         | 1.13e+31 |\n",
      "|    dual_loss           | 1.4e+16  |\n",
      "|    kl_loss             | 3.28e+09 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 219050   |\n",
      "|    penalty_temperature | 67.8     |\n",
      "|    policy_loss         | 1.23e+08 |\n",
      "|    std                 | 6.62e+06 |\n",
      "|    temperature         | 5.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 770      |\n",
      "|    ep_rew_mean         | -147     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 840      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 2034     |\n",
      "|    total_timesteps     | 232447   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.69e+16 |\n",
      "|    alpha_mean          | 40.5     |\n",
      "|    alpha_std           | 27.7     |\n",
      "|    critic_loss         | 1.62e+31 |\n",
      "|    dual_loss           | 1.69e+16 |\n",
      "|    kl_loss             | 4.23e+09 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 222400   |\n",
      "|    penalty_temperature | 68.8     |\n",
      "|    policy_loss         | 1.57e+08 |\n",
      "|    std                 | 8.01e+06 |\n",
      "|    temperature         | 5.82     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 741      |\n",
      "|    ep_rew_mean         | -146     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 844      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 2052     |\n",
      "|    total_timesteps     | 234357   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.9e+16  |\n",
      "|    alpha_mean          | 40.8     |\n",
      "|    alpha_std           | 27.8     |\n",
      "|    critic_loss         | 1.97e+31 |\n",
      "|    dual_loss           | 1.9e+16  |\n",
      "|    kl_loss             | 3.6e+09  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 224350   |\n",
      "|    penalty_temperature | 69.4     |\n",
      "|    policy_loss         | 1.33e+08 |\n",
      "|    std                 | 8.95e+06 |\n",
      "|    temperature         | 5.82     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 709      |\n",
      "|    ep_rew_mean         | -145     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 848      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 2068     |\n",
      "|    total_timesteps     | 236129   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.08e+16 |\n",
      "|    alpha_mean          | 41       |\n",
      "|    alpha_std           | 27.8     |\n",
      "|    critic_loss         | 2.39e+31 |\n",
      "|    dual_loss           | 2.08e+16 |\n",
      "|    kl_loss             | 4.56e+09 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 226100   |\n",
      "|    penalty_temperature | 69.9     |\n",
      "|    policy_loss         | 1.67e+08 |\n",
      "|    std                 | 9.86e+06 |\n",
      "|    temperature         | 5.82     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 708      |\n",
      "|    ep_rew_mean         | -144     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 852      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 2084     |\n",
      "|    total_timesteps     | 237926   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.3e+16  |\n",
      "|    alpha_mean          | 41.3     |\n",
      "|    alpha_std           | 27.9     |\n",
      "|    critic_loss         | 2.95e+31 |\n",
      "|    dual_loss           | 2.3e+16  |\n",
      "|    kl_loss             | 5.42e+09 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 227900   |\n",
      "|    penalty_temperature | 70.5     |\n",
      "|    policy_loss         | 1.96e+08 |\n",
      "|    std                 | 1.09e+07 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 693      |\n",
      "|    ep_rew_mean         | -144     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 856      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 2128     |\n",
      "|    total_timesteps     | 242806   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.99e+16 |\n",
      "|    alpha_mean          | 42.1     |\n",
      "|    alpha_std           | 28.1     |\n",
      "|    critic_loss         | 4.88e+31 |\n",
      "|    dual_loss           | 2.99e+16 |\n",
      "|    kl_loss             | 7.76e+09 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 232800   |\n",
      "|    penalty_temperature | 71.9     |\n",
      "|    policy_loss         | 2.75e+08 |\n",
      "|    std                 | 1.43e+07 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 677      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 860      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 2158     |\n",
      "|    total_timesteps     | 246169   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.57e+16 |\n",
      "|    alpha_mean          | 42.7     |\n",
      "|    alpha_std           | 28.3     |\n",
      "|    critic_loss         | 7.06e+31 |\n",
      "|    dual_loss           | 3.57e+16 |\n",
      "|    kl_loss             | 1.02e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 236150   |\n",
      "|    penalty_temperature | 72.9     |\n",
      "|    policy_loss         | 3.58e+08 |\n",
      "|    std                 | 1.71e+07 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 691      |\n",
      "|    ep_rew_mean         | -144     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 864      |\n",
      "|    fps                 | 114      |\n",
      "|    time_elapsed        | 2188     |\n",
      "|    total_timesteps     | 249485   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.29e+16 |\n",
      "|    alpha_mean          | 43.3     |\n",
      "|    alpha_std           | 28.5     |\n",
      "|    critic_loss         | 9.99e+31 |\n",
      "|    dual_loss           | 4.29e+16 |\n",
      "|    kl_loss             | 9.61e+09 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 239450   |\n",
      "|    penalty_temperature | 73.9     |\n",
      "|    policy_loss         | 3.32e+08 |\n",
      "|    std                 | 2.04e+07 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 692      |\n",
      "|    ep_rew_mean         | -144     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 868      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2205     |\n",
      "|    total_timesteps     | 251316   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.76e+16 |\n",
      "|    alpha_mean          | 43.6     |\n",
      "|    alpha_std           | 28.6     |\n",
      "|    critic_loss         | 1.19e+32 |\n",
      "|    dual_loss           | 4.76e+16 |\n",
      "|    kl_loss             | 1.16e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 241300   |\n",
      "|    penalty_temperature | 74.5     |\n",
      "|    policy_loss         | 3.99e+08 |\n",
      "|    std                 | 2.25e+07 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 662      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 872      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2208     |\n",
      "|    total_timesteps     | 251703   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.79e+16 |\n",
      "|    alpha_mean          | 43.7     |\n",
      "|    alpha_std           | 28.6     |\n",
      "|    critic_loss         | 1.26e+32 |\n",
      "|    dual_loss           | 4.79e+16 |\n",
      "|    kl_loss             | 1.33e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 241700   |\n",
      "|    penalty_temperature | 74.6     |\n",
      "|    policy_loss         | 4.53e+08 |\n",
      "|    std                 | 2.3e+07  |\n",
      "|    temperature         | 5.82     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 633      |\n",
      "|    ep_rew_mean         | -142     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 876      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2226     |\n",
      "|    total_timesteps     | 253682   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.33e+16 |\n",
      "|    alpha_mean          | 44       |\n",
      "|    alpha_std           | 28.7     |\n",
      "|    critic_loss         | 1.52e+32 |\n",
      "|    dual_loss           | 5.33e+16 |\n",
      "|    kl_loss             | 1.47e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 243650   |\n",
      "|    penalty_temperature | 75.1     |\n",
      "|    policy_loss         | 4.97e+08 |\n",
      "|    std                 | 2.54e+07 |\n",
      "|    temperature         | 5.83     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 633      |\n",
      "|    ep_rew_mean         | -142     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 880      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2242     |\n",
      "|    total_timesteps     | 255467   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.86e+16 |\n",
      "|    alpha_mean          | 44.3     |\n",
      "|    alpha_std           | 28.8     |\n",
      "|    critic_loss         | 1.87e+32 |\n",
      "|    dual_loss           | 5.86e+16 |\n",
      "|    kl_loss             | 1.87e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 245450   |\n",
      "|    penalty_temperature | 75.6     |\n",
      "|    policy_loss         | 6.29e+08 |\n",
      "|    std                 | 2.79e+07 |\n",
      "|    temperature         | 5.86     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 634      |\n",
      "|    ep_rew_mean         | -142     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 884      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2260     |\n",
      "|    total_timesteps     | 257451   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.5e+16  |\n",
      "|    alpha_mean          | 44.7     |\n",
      "|    alpha_std           | 28.9     |\n",
      "|    critic_loss         | 2.33e+32 |\n",
      "|    dual_loss           | 6.5e+16  |\n",
      "|    kl_loss             | 2e+10    |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 247450   |\n",
      "|    penalty_temperature | 76.2     |\n",
      "|    policy_loss         | 6.69e+08 |\n",
      "|    std                 | 3.1e+07  |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 617      |\n",
      "|    ep_rew_mean         | -141     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 888      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2290     |\n",
      "|    total_timesteps     | 260804   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 7.72e+16 |\n",
      "|    alpha_mean          | 45.3     |\n",
      "|    alpha_std           | 29.1     |\n",
      "|    critic_loss         | 3.18e+32 |\n",
      "|    dual_loss           | 7.72e+16 |\n",
      "|    kl_loss             | 2.52e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 250800   |\n",
      "|    penalty_temperature | 77.2     |\n",
      "|    policy_loss         | 8.32e+08 |\n",
      "|    std                 | 3.68e+07 |\n",
      "|    temperature         | 5.87     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 617      |\n",
      "|    ep_rew_mean         | -141     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 892      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2320     |\n",
      "|    total_timesteps     | 264106   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.07e+16 |\n",
      "|    alpha_mean          | 45.9     |\n",
      "|    alpha_std           | 29.3     |\n",
      "|    critic_loss         | 4.44e+32 |\n",
      "|    dual_loss           | 9.07e+16 |\n",
      "|    kl_loss             | 2.38e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 254100   |\n",
      "|    penalty_temperature | 78.1     |\n",
      "|    policy_loss         | 7.74e+08 |\n",
      "|    std                 | 4.35e+07 |\n",
      "|    temperature         | 5.87     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 601      |\n",
      "|    ep_rew_mean         | -140     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 896      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2335     |\n",
      "|    total_timesteps     | 265896   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.91e+16 |\n",
      "|    alpha_mean          | 46.2     |\n",
      "|    alpha_std           | 29.4     |\n",
      "|    critic_loss         | 5.27e+32 |\n",
      "|    dual_loss           | 9.91e+16 |\n",
      "|    kl_loss             | 2.92e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 255850   |\n",
      "|    penalty_temperature | 78.6     |\n",
      "|    policy_loss         | 9.45e+08 |\n",
      "|    std                 | 4.75e+07 |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 615      |\n",
      "|    ep_rew_mean         | -141     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 900      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2365     |\n",
      "|    total_timesteps     | 269208   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.17e+17 |\n",
      "|    alpha_mean          | 46.8     |\n",
      "|    alpha_std           | 29.7     |\n",
      "|    critic_loss         | 7.18e+32 |\n",
      "|    dual_loss           | 1.17e+17 |\n",
      "|    kl_loss             | 3.65e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 259200   |\n",
      "|    penalty_temperature | 79.6     |\n",
      "|    policy_loss         | 1.16e+09 |\n",
      "|    std                 | 5.61e+07 |\n",
      "|    temperature         | 5.86     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 646      |\n",
      "|    ep_rew_mean         | -142     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 904      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2423     |\n",
      "|    total_timesteps     | 275608   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.61e+17 |\n",
      "|    alpha_mean          | 48       |\n",
      "|    alpha_std           | 30.1     |\n",
      "|    critic_loss         | 1.38e+33 |\n",
      "|    dual_loss           | 1.61e+17 |\n",
      "|    kl_loss             | 4.39e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 265600   |\n",
      "|    penalty_temperature | 81.3     |\n",
      "|    policy_loss         | 1.37e+09 |\n",
      "|    std                 | 7.68e+07 |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 629      |\n",
      "|    ep_rew_mean         | -141     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 908      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2439     |\n",
      "|    total_timesteps     | 277401   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.75e+17 |\n",
      "|    alpha_mean          | 48.3     |\n",
      "|    alpha_std           | 30.2     |\n",
      "|    critic_loss         | 1.59e+33 |\n",
      "|    dual_loss           | 1.75e+17 |\n",
      "|    kl_loss             | 4.62e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 267400   |\n",
      "|    penalty_temperature | 81.8     |\n",
      "|    policy_loss         | 1.43e+09 |\n",
      "|    std                 | 8.38e+07 |\n",
      "|    temperature         | 5.88     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 644      |\n",
      "|    ep_rew_mean         | -142     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 912      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2469     |\n",
      "|    total_timesteps     | 280778   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.05e+17 |\n",
      "|    alpha_mean          | 48.9     |\n",
      "|    alpha_std           | 30.4     |\n",
      "|    critic_loss         | 2.25e+33 |\n",
      "|    dual_loss           | 2.05e+17 |\n",
      "|    kl_loss             | 4.12e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 270750   |\n",
      "|    penalty_temperature | 82.8     |\n",
      "|    policy_loss         | 1.26e+09 |\n",
      "|    std                 | 9.84e+07 |\n",
      "|    temperature         | 5.89     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 644      |\n",
      "|    ep_rew_mean         | -142     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 916      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2487     |\n",
      "|    total_timesteps     | 282707   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.25e+17 |\n",
      "|    alpha_mean          | 49.2     |\n",
      "|    alpha_std           | 30.5     |\n",
      "|    critic_loss         | 2.69e+33 |\n",
      "|    dual_loss           | 2.25e+17 |\n",
      "|    kl_loss             | 7.93e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 272700   |\n",
      "|    penalty_temperature | 83.2     |\n",
      "|    policy_loss         | 2.41e+09 |\n",
      "|    std                 | 1.08e+08 |\n",
      "|    temperature         | 5.89     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 675      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 920      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2531     |\n",
      "|    total_timesteps     | 287626   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.85e+17 |\n",
      "|    alpha_mean          | 50.1     |\n",
      "|    alpha_std           | 30.8     |\n",
      "|    critic_loss         | 4.27e+33 |\n",
      "|    dual_loss           | 2.85e+17 |\n",
      "|    kl_loss             | 7.89e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 277600   |\n",
      "|    penalty_temperature | 84.6     |\n",
      "|    policy_loss         | 2.35e+09 |\n",
      "|    std                 | 1.36e+08 |\n",
      "|    temperature         | 5.89     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 690      |\n",
      "|    ep_rew_mean         | -144     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 924      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2561     |\n",
      "|    total_timesteps     | 290997   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.33e+17 |\n",
      "|    alpha_mean          | 50.7     |\n",
      "|    alpha_std           | 31       |\n",
      "|    critic_loss         | 5.93e+33 |\n",
      "|    dual_loss           | 3.33e+17 |\n",
      "|    kl_loss             | 7.77e+10 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 280950   |\n",
      "|    penalty_temperature | 85.4     |\n",
      "|    policy_loss         | 2.29e+09 |\n",
      "|    std                 | 1.59e+08 |\n",
      "|    temperature         | 5.89     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 675      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 928      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2591     |\n",
      "|    total_timesteps     | 294310   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.86e+17 |\n",
      "|    alpha_mean          | 51.3     |\n",
      "|    alpha_std           | 31.2     |\n",
      "|    critic_loss         | 7.88e+33 |\n",
      "|    dual_loss           | 3.86e+17 |\n",
      "|    kl_loss             | 1.07e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 284300   |\n",
      "|    penalty_temperature | 86.1     |\n",
      "|    policy_loss         | 3.11e+09 |\n",
      "|    std                 | 1.86e+08 |\n",
      "|    temperature         | 5.89     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 675      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 932      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2608     |\n",
      "|    total_timesteps     | 296156   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.19e+17 |\n",
      "|    alpha_mean          | 51.6     |\n",
      "|    alpha_std           | 31.3     |\n",
      "|    critic_loss         | 9.38e+33 |\n",
      "|    dual_loss           | 4.19e+17 |\n",
      "|    kl_loss             | 1.08e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 286150   |\n",
      "|    penalty_temperature | 86.2     |\n",
      "|    policy_loss         | 3.12e+09 |\n",
      "|    std                 | 2.02e+08 |\n",
      "|    temperature         | 5.89     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 675      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 936      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2611     |\n",
      "|    total_timesteps     | 296560   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.27e+17 |\n",
      "|    alpha_mean          | 51.7     |\n",
      "|    alpha_std           | 31.3     |\n",
      "|    critic_loss         | 9.51e+33 |\n",
      "|    dual_loss           | 4.27e+17 |\n",
      "|    kl_loss             | 1.11e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 286550   |\n",
      "|    penalty_temperature | 86.3     |\n",
      "|    policy_loss         | 3.2e+09  |\n",
      "|    std                 | 2.06e+08 |\n",
      "|    temperature         | 5.89     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 675      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 940      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2641     |\n",
      "|    total_timesteps     | 299943   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.99e+17 |\n",
      "|    alpha_mean          | 52.3     |\n",
      "|    alpha_std           | 31.6     |\n",
      "|    critic_loss         | 1.3e+34  |\n",
      "|    dual_loss           | 4.99e+17 |\n",
      "|    kl_loss             | 1.09e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 289900   |\n",
      "|    penalty_temperature | 86.5     |\n",
      "|    policy_loss         | 3.11e+09 |\n",
      "|    std                 | 2.39e+08 |\n",
      "|    temperature         | 5.91     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 704      |\n",
      "|    ep_rew_mean         | -144     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 944      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2685     |\n",
      "|    total_timesteps     | 304781   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.21e+17 |\n",
      "|    alpha_mean          | 53.1     |\n",
      "|    alpha_std           | 31.9     |\n",
      "|    critic_loss         | 2.02e+34 |\n",
      "|    dual_loss           | 6.21e+17 |\n",
      "|    kl_loss             | 1.66e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 294750   |\n",
      "|    penalty_temperature | 87.5     |\n",
      "|    policy_loss         | 4.68e+09 |\n",
      "|    std                 | 2.97e+08 |\n",
      "|    temperature         | 5.94     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 705      |\n",
      "|    ep_rew_mean         | -144     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 948      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2701     |\n",
      "|    total_timesteps     | 306581   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.71e+17 |\n",
      "|    alpha_mean          | 53.4     |\n",
      "|    alpha_std           | 32       |\n",
      "|    critic_loss         | 2.38e+34 |\n",
      "|    dual_loss           | 6.71e+17 |\n",
      "|    kl_loss             | 1.39e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 296550   |\n",
      "|    penalty_temperature | 88       |\n",
      "|    policy_loss         | 3.9e+09  |\n",
      "|    std                 | 3.22e+08 |\n",
      "|    temperature         | 5.95     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 721      |\n",
      "|    ep_rew_mean         | -145     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 952      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2732     |\n",
      "|    total_timesteps     | 309991   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 7.75e+17 |\n",
      "|    alpha_mean          | 54       |\n",
      "|    alpha_std           | 32.2     |\n",
      "|    critic_loss         | 3.13e+34 |\n",
      "|    dual_loss           | 7.75e+17 |\n",
      "|    kl_loss             | 2.05e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 299950   |\n",
      "|    penalty_temperature | 89       |\n",
      "|    policy_loss         | 5.67e+09 |\n",
      "|    std                 | 3.74e+08 |\n",
      "|    temperature         | 5.94     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 690      |\n",
      "|    ep_rew_mean         | -144     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 956      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2748     |\n",
      "|    total_timesteps     | 311763   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 8.37e+17 |\n",
      "|    alpha_mean          | 54.4     |\n",
      "|    alpha_std           | 32.3     |\n",
      "|    critic_loss         | 3.74e+34 |\n",
      "|    dual_loss           | 8.37e+17 |\n",
      "|    kl_loss             | 2.61e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 301750   |\n",
      "|    penalty_temperature | 89.2     |\n",
      "|    policy_loss         | 7.18e+09 |\n",
      "|    std                 | 4.04e+08 |\n",
      "|    temperature         | 5.94     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 705      |\n",
      "|    ep_rew_mean         | -144     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 960      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2792     |\n",
      "|    total_timesteps     | 316664   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.04e+18 |\n",
      "|    alpha_mean          | 55.2     |\n",
      "|    alpha_std           | 32.6     |\n",
      "|    critic_loss         | 5.63e+34 |\n",
      "|    dual_loss           | 1.04e+18 |\n",
      "|    kl_loss             | 2.42e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 306650   |\n",
      "|    penalty_temperature | 90.1     |\n",
      "|    policy_loss         | 6.55e+09 |\n",
      "|    std                 | 4.99e+08 |\n",
      "|    temperature         | 5.95     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 706      |\n",
      "|    ep_rew_mean         | -144     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 964      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2823     |\n",
      "|    total_timesteps     | 320101   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.19e+18 |\n",
      "|    alpha_mean          | 55.8     |\n",
      "|    alpha_std           | 32.8     |\n",
      "|    critic_loss         | 7.51e+34 |\n",
      "|    dual_loss           | 1.19e+18 |\n",
      "|    kl_loss             | 2.94e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 310100   |\n",
      "|    penalty_temperature | 90.5     |\n",
      "|    policy_loss         | 7.88e+09 |\n",
      "|    std                 | 5.78e+08 |\n",
      "|    temperature         | 5.95     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 721      |\n",
      "|    ep_rew_mean         | -145     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 968      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2853     |\n",
      "|    total_timesteps     | 323455   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.38e+18 |\n",
      "|    alpha_mean          | 56.4     |\n",
      "|    alpha_std           | 33       |\n",
      "|    critic_loss         | 9.84e+34 |\n",
      "|    dual_loss           | 1.38e+18 |\n",
      "|    kl_loss             | 3.21e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 313450   |\n",
      "|    penalty_temperature | 91.4     |\n",
      "|    policy_loss         | 8.52e+09 |\n",
      "|    std                 | 6.66e+08 |\n",
      "|    temperature         | 5.95     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 736      |\n",
      "|    ep_rew_mean         | -145     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 972      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2869     |\n",
      "|    total_timesteps     | 325279   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.49e+18 |\n",
      "|    alpha_mean          | 56.7     |\n",
      "|    alpha_std           | 33.2     |\n",
      "|    critic_loss         | 1.15e+35 |\n",
      "|    dual_loss           | 1.49e+18 |\n",
      "|    kl_loss             | 2.74e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 315250   |\n",
      "|    penalty_temperature | 91.9     |\n",
      "|    policy_loss         | 7.22e+09 |\n",
      "|    std                 | 7.19e+08 |\n",
      "|    temperature         | 5.95     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 765      |\n",
      "|    ep_rew_mean         | -146     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 976      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2913     |\n",
      "|    total_timesteps     | 330225   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.83e+18 |\n",
      "|    alpha_mean          | 57.6     |\n",
      "|    alpha_std           | 33.6     |\n",
      "|    critic_loss         | 1.74e+35 |\n",
      "|    dual_loss           | 1.83e+18 |\n",
      "|    kl_loss             | 3.88e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 320200   |\n",
      "|    penalty_temperature | 93.4     |\n",
      "|    policy_loss         | 1.01e+10 |\n",
      "|    std                 | 8.84e+08 |\n",
      "|    temperature         | 5.96     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 765      |\n",
      "|    ep_rew_mean         | -146     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 980      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2929     |\n",
      "|    total_timesteps     | 331992   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.96e+18 |\n",
      "|    alpha_mean          | 57.9     |\n",
      "|    alpha_std           | 33.7     |\n",
      "|    critic_loss         | 2.04e+35 |\n",
      "|    dual_loss           | 1.96e+18 |\n",
      "|    kl_loss             | 3.9e+11  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 321950   |\n",
      "|    penalty_temperature | 93.9     |\n",
      "|    policy_loss         | 1.01e+10 |\n",
      "|    std                 | 9.49e+08 |\n",
      "|    temperature         | 5.96     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 779      |\n",
      "|    ep_rew_mean         | -147     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 984      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2959     |\n",
      "|    total_timesteps     | 335349   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.25e+18 |\n",
      "|    alpha_mean          | 58.5     |\n",
      "|    alpha_std           | 33.9     |\n",
      "|    critic_loss         | 2.63e+35 |\n",
      "|    dual_loss           | 2.25e+18 |\n",
      "|    kl_loss             | 4.4e+11  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 325300   |\n",
      "|    penalty_temperature | 94.7     |\n",
      "|    policy_loss         | 1.12e+10 |\n",
      "|    std                 | 1.09e+09 |\n",
      "|    temperature         | 5.98     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 764      |\n",
      "|    ep_rew_mean         | -146     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 988      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 2976     |\n",
      "|    total_timesteps     | 337220   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.44e+18 |\n",
      "|    alpha_mean          | 58.8     |\n",
      "|    alpha_std           | 34       |\n",
      "|    critic_loss         | 3.05e+35 |\n",
      "|    dual_loss           | 2.44e+18 |\n",
      "|    kl_loss             | 4.62e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 327200   |\n",
      "|    penalty_temperature | 95.3     |\n",
      "|    policy_loss         | 1.17e+10 |\n",
      "|    std                 | 1.18e+09 |\n",
      "|    temperature         | 5.98     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 766      |\n",
      "|    ep_rew_mean         | -146     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 992      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3007     |\n",
      "|    total_timesteps     | 340659   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.82e+18 |\n",
      "|    alpha_mean          | 59.5     |\n",
      "|    alpha_std           | 34.3     |\n",
      "|    critic_loss         | 4.15e+35 |\n",
      "|    dual_loss           | 2.82e+18 |\n",
      "|    kl_loss             | 9.1e+11  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 330650   |\n",
      "|    penalty_temperature | 96       |\n",
      "|    policy_loss         | 2.29e+10 |\n",
      "|    std                 | 1.35e+09 |\n",
      "|    temperature         | 6        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 751      |\n",
      "|    ep_rew_mean         | -145     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 996      |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3011     |\n",
      "|    total_timesteps     | 341042   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.84e+18 |\n",
      "|    alpha_mean          | 59.5     |\n",
      "|    alpha_std           | 34.3     |\n",
      "|    critic_loss         | 4.27e+35 |\n",
      "|    dual_loss           | 2.84e+18 |\n",
      "|    kl_loss             | 6.38e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 331000   |\n",
      "|    penalty_temperature | 96       |\n",
      "|    policy_loss         | 1.6e+10  |\n",
      "|    std                 | 1.37e+09 |\n",
      "|    temperature         | 6        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 782      |\n",
      "|    ep_rew_mean         | -147     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1000     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3068     |\n",
      "|    total_timesteps     | 347442   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.68e+18 |\n",
      "|    alpha_mean          | 60.7     |\n",
      "|    alpha_std           | 34.9     |\n",
      "|    critic_loss         | 7.07e+35 |\n",
      "|    dual_loss           | 3.68e+18 |\n",
      "|    kl_loss             | 9.2e+11  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 337400   |\n",
      "|    penalty_temperature | 96.8     |\n",
      "|    policy_loss         | 2.27e+10 |\n",
      "|    std                 | 1.77e+09 |\n",
      "|    temperature         | 6        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 753      |\n",
      "|    ep_rew_mean         | -146     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1004     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3099     |\n",
      "|    total_timesteps     | 350880   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.18e+18 |\n",
      "|    alpha_mean          | 61.3     |\n",
      "|    alpha_std           | 35.1     |\n",
      "|    critic_loss         | 9.17e+35 |\n",
      "|    dual_loss           | 4.18e+18 |\n",
      "|    kl_loss             | 8.94e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 340850   |\n",
      "|    penalty_temperature | 97.7     |\n",
      "|    policy_loss         | 2.18e+10 |\n",
      "|    std                 | 2.02e+09 |\n",
      "|    temperature         | 6        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 753      |\n",
      "|    ep_rew_mean         | -145     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1008     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3116     |\n",
      "|    total_timesteps     | 352733   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.48e+18 |\n",
      "|    alpha_mean          | 61.6     |\n",
      "|    alpha_std           | 35.2     |\n",
      "|    critic_loss         | 1.05e+36 |\n",
      "|    dual_loss           | 4.48e+18 |\n",
      "|    kl_loss             | 8.82e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 342700   |\n",
      "|    penalty_temperature | 98.2     |\n",
      "|    policy_loss         | 2.14e+10 |\n",
      "|    std                 | 2.17e+09 |\n",
      "|    temperature         | 5.99     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 753      |\n",
      "|    ep_rew_mean         | -145     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1012     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3146     |\n",
      "|    total_timesteps     | 356053   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.11e+18 |\n",
      "|    alpha_mean          | 62.2     |\n",
      "|    alpha_std           | 35.5     |\n",
      "|    critic_loss         | 1.37e+36 |\n",
      "|    dual_loss           | 5.11e+18 |\n",
      "|    kl_loss             | 9.97e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 346050   |\n",
      "|    penalty_temperature | 99.2     |\n",
      "|    policy_loss         | 2.4e+10  |\n",
      "|    std                 | 2.47e+09 |\n",
      "|    temperature         | 6.01     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 767      |\n",
      "|    ep_rew_mean         | -146     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1016     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3176     |\n",
      "|    total_timesteps     | 359410   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.9e+18  |\n",
      "|    alpha_mean          | 62.8     |\n",
      "|    alpha_std           | 35.7     |\n",
      "|    critic_loss         | 1.79e+36 |\n",
      "|    dual_loss           | 5.9e+18  |\n",
      "|    kl_loss             | 1.11e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 349400   |\n",
      "|    penalty_temperature | 100      |\n",
      "|    policy_loss         | 2.65e+10 |\n",
      "|    std                 | 2.81e+09 |\n",
      "|    temperature         | 6.01     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 735      |\n",
      "|    ep_rew_mean         | -145     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1020     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3192     |\n",
      "|    total_timesteps     | 361171   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.25e+18 |\n",
      "|    alpha_mean          | 63.1     |\n",
      "|    alpha_std           | 35.8     |\n",
      "|    critic_loss         | 2.02e+36 |\n",
      "|    dual_loss           | 6.25e+18 |\n",
      "|    kl_loss             | 9.66e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 351150   |\n",
      "|    penalty_temperature | 100      |\n",
      "|    policy_loss         | 2.29e+10 |\n",
      "|    std                 | 3.01e+09 |\n",
      "|    temperature         | 6.03     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 720      |\n",
      "|    ep_rew_mean         | -144     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1024     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3208     |\n",
      "|    total_timesteps     | 362985   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.65e+18 |\n",
      "|    alpha_mean          | 63.4     |\n",
      "|    alpha_std           | 36       |\n",
      "|    critic_loss         | 2.3e+36  |\n",
      "|    dual_loss           | 6.65e+18 |\n",
      "|    kl_loss             | 1.01e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 352950   |\n",
      "|    penalty_temperature | 100      |\n",
      "|    policy_loss         | 2.39e+10 |\n",
      "|    std                 | 3.22e+09 |\n",
      "|    temperature         | 6.03     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 704      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1028     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3223     |\n",
      "|    total_timesteps     | 364735   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 7.1e+18  |\n",
      "|    alpha_mean          | 63.7     |\n",
      "|    alpha_std           | 36.2     |\n",
      "|    critic_loss         | 2.64e+36 |\n",
      "|    dual_loss           | 7.1e+18  |\n",
      "|    kl_loss             | 9.53e+11 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 354700   |\n",
      "|    penalty_temperature | 101      |\n",
      "|    policy_loss         | 2.23e+10 |\n",
      "|    std                 | 3.44e+09 |\n",
      "|    temperature         | 6.05     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 705      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1032     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3241     |\n",
      "|    total_timesteps     | 366684   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 7.73e+18 |\n",
      "|    alpha_mean          | 64.1     |\n",
      "|    alpha_std           | 36.3     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 7.73e+18 |\n",
      "|    kl_loss             | 1.18e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 356650   |\n",
      "|    penalty_temperature | 101      |\n",
      "|    policy_loss         | 2.74e+10 |\n",
      "|    std                 | 3.71e+09 |\n",
      "|    temperature         | 6.05     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 734      |\n",
      "|    ep_rew_mean         | -144     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1036     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3271     |\n",
      "|    total_timesteps     | 369993   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 8.72e+18 |\n",
      "|    alpha_mean          | 64.7     |\n",
      "|    alpha_std           | 36.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 8.72e+18 |\n",
      "|    kl_loss             | 1.81e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 359950   |\n",
      "|    penalty_temperature | 102      |\n",
      "|    policy_loss         | 4.18e+10 |\n",
      "|    std                 | 4.19e+09 |\n",
      "|    temperature         | 6.06     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 719      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1040     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3288     |\n",
      "|    total_timesteps     | 371862   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.3e+18  |\n",
      "|    alpha_mean          | 65       |\n",
      "|    alpha_std           | 36.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 9.3e+18  |\n",
      "|    kl_loss             | 1.83e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 361850   |\n",
      "|    penalty_temperature | 103      |\n",
      "|    policy_loss         | 4.21e+10 |\n",
      "|    std                 | 4.5e+09  |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 704      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1044     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3318     |\n",
      "|    total_timesteps     | 375211   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.06e+19 |\n",
      "|    alpha_mean          | 65.6     |\n",
      "|    alpha_std           | 36.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.06e+19 |\n",
      "|    kl_loss             | 1.75e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 365200   |\n",
      "|    penalty_temperature | 103      |\n",
      "|    policy_loss         | 4e+10    |\n",
      "|    std                 | 5.09e+09 |\n",
      "|    temperature         | 6.08     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 705      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1048     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3335     |\n",
      "|    total_timesteps     | 377114   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.14e+19 |\n",
      "|    alpha_mean          | 65.9     |\n",
      "|    alpha_std           | 37       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.14e+19 |\n",
      "|    kl_loss             | 1.86e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 367100   |\n",
      "|    penalty_temperature | 103      |\n",
      "|    policy_loss         | 4.22e+10 |\n",
      "|    std                 | 5.46e+09 |\n",
      "|    temperature         | 6.08     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 673      |\n",
      "|    ep_rew_mean         | -141     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1052     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3336     |\n",
      "|    total_timesteps     | 377247   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.14e+19 |\n",
      "|    alpha_mean          | 65.9     |\n",
      "|    alpha_std           | 37       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.14e+19 |\n",
      "|    kl_loss             | 1.84e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 367200   |\n",
      "|    penalty_temperature | 103      |\n",
      "|    policy_loss         | 4.18e+10 |\n",
      "|    std                 | 5.48e+09 |\n",
      "|    temperature         | 6.08     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 688      |\n",
      "|    ep_rew_mean         | -142     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1056     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3366     |\n",
      "|    total_timesteps     | 380569   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.28e+19 |\n",
      "|    alpha_mean          | 66.6     |\n",
      "|    alpha_std           | 37.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.28e+19 |\n",
      "|    kl_loss             | 1.66e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 370550   |\n",
      "|    penalty_temperature | 103      |\n",
      "|    policy_loss         | 3.73e+10 |\n",
      "|    std                 | 6.19e+09 |\n",
      "|    temperature         | 6.08     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 672      |\n",
      "|    ep_rew_mean         | -141     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1060     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3395     |\n",
      "|    total_timesteps     | 383837   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.44e+19 |\n",
      "|    alpha_mean          | 67.1     |\n",
      "|    alpha_std           | 37.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.44e+19 |\n",
      "|    kl_loss             | 1.96e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 373800   |\n",
      "|    penalty_temperature | 103      |\n",
      "|    policy_loss         | 4.36e+10 |\n",
      "|    std                 | 6.96e+09 |\n",
      "|    temperature         | 6.08     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 701      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1064     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3452     |\n",
      "|    total_timesteps     | 390237   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.8e+19  |\n",
      "|    alpha_mean          | 68.3     |\n",
      "|    alpha_std           | 38.1     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.8e+19  |\n",
      "|    kl_loss             | 2.96e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 380200   |\n",
      "|    penalty_temperature | 104      |\n",
      "|    policy_loss         | 6.49e+10 |\n",
      "|    std                 | 8.75e+09 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 686      |\n",
      "|    ep_rew_mean         | -142     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1068     |\n",
      "|    fps                 | 113      |\n",
      "|    time_elapsed        | 3469     |\n",
      "|    total_timesteps     | 392023   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.95e+19 |\n",
      "|    alpha_mean          | 68.6     |\n",
      "|    alpha_std           | 38.3     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.95e+19 |\n",
      "|    kl_loss             | 2.56e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 382000   |\n",
      "|    penalty_temperature | 105      |\n",
      "|    policy_loss         | 5.59e+10 |\n",
      "|    std                 | 9.32e+09 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 700      |\n",
      "|    ep_rew_mean         | -143     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1072     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3498     |\n",
      "|    total_timesteps     | 395289   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.17e+19 |\n",
      "|    alpha_mean          | 69.2     |\n",
      "|    alpha_std           | 38.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.17e+19 |\n",
      "|    kl_loss             | 2.83e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 385250   |\n",
      "|    penalty_temperature | 106      |\n",
      "|    policy_loss         | 6.12e+10 |\n",
      "|    std                 | 1.04e+10 |\n",
      "|    temperature         | 6.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 669      |\n",
      "|    ep_rew_mean         | -141     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1076     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3514     |\n",
      "|    total_timesteps     | 397106   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.3e+19  |\n",
      "|    alpha_mean          | 69.5     |\n",
      "|    alpha_std           | 38.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.3e+19  |\n",
      "|    kl_loss             | 2.8e+12  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 387100   |\n",
      "|    penalty_temperature | 106      |\n",
      "|    policy_loss         | 6.04e+10 |\n",
      "|    std                 | 1.11e+10 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 684      |\n",
      "|    ep_rew_mean         | -142     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1080     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3544     |\n",
      "|    total_timesteps     | 400413   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.58e+19 |\n",
      "|    alpha_mean          | 70.1     |\n",
      "|    alpha_std           | 38.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.58e+19 |\n",
      "|    kl_loss             | 2.56e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 390400   |\n",
      "|    penalty_temperature | 107      |\n",
      "|    policy_loss         | 5.46e+10 |\n",
      "|    std                 | 1.25e+10 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 668      |\n",
      "|    ep_rew_mean         | -141     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1084     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3560     |\n",
      "|    total_timesteps     | 402163   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.75e+19 |\n",
      "|    alpha_mean          | 70.4     |\n",
      "|    alpha_std           | 38.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.75e+19 |\n",
      "|    kl_loss             | 3.17e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 392150   |\n",
      "|    penalty_temperature | 107      |\n",
      "|    policy_loss         | 6.73e+10 |\n",
      "|    std                 | 1.33e+10 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 682      |\n",
      "|    ep_rew_mean         | -142     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1088     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3589     |\n",
      "|    total_timesteps     | 405426   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.06e+19 |\n",
      "|    alpha_mean          | 71       |\n",
      "|    alpha_std           | 39.1     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.06e+19 |\n",
      "|    kl_loss             | 3.74e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 395400   |\n",
      "|    penalty_temperature | 107      |\n",
      "|    policy_loss         | 7.88e+10 |\n",
      "|    std                 | 1.48e+10 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 665      |\n",
      "|    ep_rew_mean         | -141     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1092     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3605     |\n",
      "|    total_timesteps     | 407179   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.26e+19 |\n",
      "|    alpha_mean          | 71.3     |\n",
      "|    alpha_std           | 39.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.26e+19 |\n",
      "|    kl_loss             | 4.44e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 397150   |\n",
      "|    penalty_temperature | 107      |\n",
      "|    policy_loss         | 9.31e+10 |\n",
      "|    std                 | 1.58e+10 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 678      |\n",
      "|    ep_rew_mean         | -141     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1096     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3620     |\n",
      "|    total_timesteps     | 408877   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.46e+19 |\n",
      "|    alpha_mean          | 71.6     |\n",
      "|    alpha_std           | 39.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.46e+19 |\n",
      "|    kl_loss             | 3.93e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 398850   |\n",
      "|    penalty_temperature | 107      |\n",
      "|    policy_loss         | 8.22e+10 |\n",
      "|    std                 | 1.67e+10 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 631      |\n",
      "|    ep_rew_mean         | -139     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1100     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3635     |\n",
      "|    total_timesteps     | 410568   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.65e+19 |\n",
      "|    alpha_mean          | 71.9     |\n",
      "|    alpha_std           | 39.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.65e+19 |\n",
      "|    kl_loss             | 3.61e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 400550   |\n",
      "|    penalty_temperature | 107      |\n",
      "|    policy_loss         | 7.5e+10  |\n",
      "|    std                 | 1.77e+10 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 598      |\n",
      "|    ep_rew_mean         | -138     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1104     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3637     |\n",
      "|    total_timesteps     | 410717   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.67e+19 |\n",
      "|    alpha_mean          | 71.9     |\n",
      "|    alpha_std           | 39.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.67e+19 |\n",
      "|    kl_loss             | 4.86e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 400700   |\n",
      "|    penalty_temperature | 107      |\n",
      "|    policy_loss         | 1.01e+11 |\n",
      "|    std                 | 1.78e+10 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 582      |\n",
      "|    ep_rew_mean         | -137     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1108     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3639     |\n",
      "|    total_timesteps     | 410914   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.71e+19 |\n",
      "|    alpha_mean          | 71.9     |\n",
      "|    alpha_std           | 39.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.71e+19 |\n",
      "|    kl_loss             | 3.53e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 400900   |\n",
      "|    penalty_temperature | 107      |\n",
      "|    policy_loss         | 7.34e+10 |\n",
      "|    std                 | 1.79e+10 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 566      |\n",
      "|    ep_rew_mean         | -136     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1112     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3654     |\n",
      "|    total_timesteps     | 412668   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.93e+19 |\n",
      "|    alpha_mean          | 72.3     |\n",
      "|    alpha_std           | 39.7     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.93e+19 |\n",
      "|    kl_loss             | 4.71e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 402650   |\n",
      "|    penalty_temperature | 107      |\n",
      "|    policy_loss         | 9.75e+10 |\n",
      "|    std                 | 1.9e+10  |\n",
      "|    temperature         | 6.12     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 535      |\n",
      "|    ep_rew_mean         | -134     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1116     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3656     |\n",
      "|    total_timesteps     | 412865   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.96e+19 |\n",
      "|    alpha_mean          | 72.3     |\n",
      "|    alpha_std           | 39.7     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.96e+19 |\n",
      "|    kl_loss             | 3.64e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 402850   |\n",
      "|    penalty_temperature | 107      |\n",
      "|    policy_loss         | 7.53e+10 |\n",
      "|    std                 | 1.91e+10 |\n",
      "|    temperature         | 6.12     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 565      |\n",
      "|    ep_rew_mean         | -135     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1120     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3700     |\n",
      "|    total_timesteps     | 417714   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.64e+19 |\n",
      "|    alpha_mean          | 73.2     |\n",
      "|    alpha_std           | 40.1     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 4.64e+19 |\n",
      "|    kl_loss             | 4.6e+12  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 407700   |\n",
      "|    penalty_temperature | 108      |\n",
      "|    policy_loss         | 9.4e+10  |\n",
      "|    std                 | 2.25e+10 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 597      |\n",
      "|    ep_rew_mean         | -135     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1124     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3744     |\n",
      "|    total_timesteps     | 422657   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.5e+19  |\n",
      "|    alpha_mean          | 74.1     |\n",
      "|    alpha_std           | 40.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 5.5e+19  |\n",
      "|    kl_loss             | 6.2e+12  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 412650   |\n",
      "|    penalty_temperature | 108      |\n",
      "|    policy_loss         | 1.25e+11 |\n",
      "|    std                 | 2.65e+10 |\n",
      "|    temperature         | 6.16     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 597      |\n",
      "|    ep_rew_mean         | -136     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1128     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3761     |\n",
      "|    total_timesteps     | 424469   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.85e+19 |\n",
      "|    alpha_mean          | 74.4     |\n",
      "|    alpha_std           | 40.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 5.85e+19 |\n",
      "|    kl_loss             | 5.81e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 414450   |\n",
      "|    penalty_temperature | 108      |\n",
      "|    policy_loss         | 1.17e+11 |\n",
      "|    std                 | 2.81e+10 |\n",
      "|    temperature         | 6.15     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 596      |\n",
      "|    ep_rew_mean         | -135     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1132     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3777     |\n",
      "|    total_timesteps     | 426259   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.15e+19 |\n",
      "|    alpha_mean          | 74.7     |\n",
      "|    alpha_std           | 40.7     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 6.15e+19 |\n",
      "|    kl_loss             | 4.71e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 416250   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 9.43e+10 |\n",
      "|    std                 | 2.98e+10 |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 581      |\n",
      "|    ep_rew_mean         | -134     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1136     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3793     |\n",
      "|    total_timesteps     | 428069   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.54e+19 |\n",
      "|    alpha_mean          | 75.1     |\n",
      "|    alpha_std           | 40.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 6.54e+19 |\n",
      "|    kl_loss             | 5.21e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 418050   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.04e+11 |\n",
      "|    std                 | 3.16e+10 |\n",
      "|    temperature         | 6.12     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 565      |\n",
      "|    ep_rew_mean         | -133     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1140     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3795     |\n",
      "|    total_timesteps     | 428345   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.59e+19 |\n",
      "|    alpha_mean          | 75.1     |\n",
      "|    alpha_std           | 40.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 6.59e+19 |\n",
      "|    kl_loss             | 5.08e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 418300   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.01e+11 |\n",
      "|    std                 | 3.18e+10 |\n",
      "|    temperature         | 6.12     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 549      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1144     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3811     |\n",
      "|    total_timesteps     | 430139   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 7.01e+19 |\n",
      "|    alpha_mean          | 75.5     |\n",
      "|    alpha_std           | 41.1     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 7.01e+19 |\n",
      "|    kl_loss             | 6.25e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 420100   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.24e+11 |\n",
      "|    std                 | 3.38e+10 |\n",
      "|    temperature         | 6.12     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 579      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1148     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3855     |\n",
      "|    total_timesteps     | 434992   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 8.19e+19 |\n",
      "|    alpha_mean          | 76.4     |\n",
      "|    alpha_std           | 41.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 8.19e+19 |\n",
      "|    kl_loss             | 6.23e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 424950   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.22e+11 |\n",
      "|    std                 | 3.95e+10 |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 596      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1152     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3872     |\n",
      "|    total_timesteps     | 436815   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 8.73e+19 |\n",
      "|    alpha_mean          | 76.7     |\n",
      "|    alpha_std           | 41.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 8.73e+19 |\n",
      "|    kl_loss             | 7.34e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 426800   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.43e+11 |\n",
      "|    std                 | 4.19e+10 |\n",
      "|    temperature         | 6.15     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 582      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1156     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3889     |\n",
      "|    total_timesteps     | 438771   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.19e+19 |\n",
      "|    alpha_mean          | 77       |\n",
      "|    alpha_std           | 41.7     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 9.19e+19 |\n",
      "|    kl_loss             | 7.85e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 428750   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.52e+11 |\n",
      "|    std                 | 4.46e+10 |\n",
      "|    temperature         | 6.13     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 583      |\n",
      "|    ep_rew_mean         | -130     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1160     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3920     |\n",
      "|    total_timesteps     | 442138   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.02e+20 |\n",
      "|    alpha_mean          | 77.7     |\n",
      "|    alpha_std           | 42       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.02e+20 |\n",
      "|    kl_loss             | 6.53e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 432100   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.26e+11 |\n",
      "|    std                 | 4.95e+10 |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 540      |\n",
      "|    ep_rew_mean         | -128     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1164     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3939     |\n",
      "|    total_timesteps     | 444204   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.1e+20  |\n",
      "|    alpha_mean          | 78       |\n",
      "|    alpha_std           | 42.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.1e+20  |\n",
      "|    kl_loss             | 7.9e+12  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 434200   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.52e+11 |\n",
      "|    std                 | 5.3e+10  |\n",
      "|    temperature         | 6.15     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 524      |\n",
      "|    ep_rew_mean         | -127     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1168     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3940     |\n",
      "|    total_timesteps     | 444408   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.1e+20  |\n",
      "|    alpha_mean          | 78.1     |\n",
      "|    alpha_std           | 42.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.1e+20  |\n",
      "|    kl_loss             | 8.97e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 434400   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.72e+11 |\n",
      "|    std                 | 5.33e+10 |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 509      |\n",
      "|    ep_rew_mean         | -126     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1172     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3956     |\n",
      "|    total_timesteps     | 446159   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.16e+20 |\n",
      "|    alpha_mean          | 78.4     |\n",
      "|    alpha_std           | 42.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.16e+20 |\n",
      "|    kl_loss             | 9.17e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 436150   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.75e+11 |\n",
      "|    std                 | 5.62e+10 |\n",
      "|    temperature         | 6.16     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 493      |\n",
      "|    ep_rew_mean         | -126     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1176     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3958     |\n",
      "|    total_timesteps     | 446371   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.17e+20 |\n",
      "|    alpha_mean          | 78.4     |\n",
      "|    alpha_std           | 42.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.17e+20 |\n",
      "|    kl_loss             | 1.01e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 436350   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.92e+11 |\n",
      "|    std                 | 5.66e+10 |\n",
      "|    temperature         | 6.17     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 493      |\n",
      "|    ep_rew_mean         | -125     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1180     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3988     |\n",
      "|    total_timesteps     | 449672   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.3e+20  |\n",
      "|    alpha_mean          | 79.1     |\n",
      "|    alpha_std           | 42.7     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.3e+20  |\n",
      "|    kl_loss             | 8.53e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 439650   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.61e+11 |\n",
      "|    std                 | 6.27e+10 |\n",
      "|    temperature         | 6.17     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 478      |\n",
      "|    ep_rew_mean         | -124     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1184     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 3990     |\n",
      "|    total_timesteps     | 449965   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.31e+20 |\n",
      "|    alpha_mean          | 79.1     |\n",
      "|    alpha_std           | 42.7     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.31e+20 |\n",
      "|    kl_loss             | 1.29e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 439950   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.44e+11 |\n",
      "|    std                 | 6.33e+10 |\n",
      "|    temperature         | 6.16     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 478      |\n",
      "|    ep_rew_mean         | -123     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1188     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4020     |\n",
      "|    total_timesteps     | 453261   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.46e+20 |\n",
      "|    alpha_mean          | 79.7     |\n",
      "|    alpha_std           | 43       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.46e+20 |\n",
      "|    kl_loss             | 1.03e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 443250   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.93e+11 |\n",
      "|    std                 | 7.02e+10 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 463      |\n",
      "|    ep_rew_mean         | -122     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1192     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4022     |\n",
      "|    total_timesteps     | 453516   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.47e+20 |\n",
      "|    alpha_mean          | 79.8     |\n",
      "|    alpha_std           | 43       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.47e+20 |\n",
      "|    kl_loss             | 1.01e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 443500   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.89e+11 |\n",
      "|    std                 | 7.07e+10 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 480      |\n",
      "|    ep_rew_mean         | -122     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1196     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4053     |\n",
      "|    total_timesteps     | 456861   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.62e+20 |\n",
      "|    alpha_mean          | 80.4     |\n",
      "|    alpha_std           | 43.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.62e+20 |\n",
      "|    kl_loss             | 9.44e+12 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 446850   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 1.76e+11 |\n",
      "|    std                 | 7.84e+10 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 496      |\n",
      "|    ep_rew_mean         | -122     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1200     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4082     |\n",
      "|    total_timesteps     | 460182   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.8e+20  |\n",
      "|    alpha_mean          | 81       |\n",
      "|    alpha_std           | 43.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.8e+20  |\n",
      "|    kl_loss             | 1.23e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 450150   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.28e+11 |\n",
      "|    std                 | 8.67e+10 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 544      |\n",
      "|    ep_rew_mean         | -123     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1204     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4126     |\n",
      "|    total_timesteps     | 465072   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.09e+20 |\n",
      "|    alpha_mean          | 81.9     |\n",
      "|    alpha_std           | 43.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.09e+20 |\n",
      "|    kl_loss             | 1.37e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 455050   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.51e+11 |\n",
      "|    std                 | 1.01e+11 |\n",
      "|    temperature         | 6.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 544      |\n",
      "|    ep_rew_mean         | -123     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1208     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4129     |\n",
      "|    total_timesteps     | 465305   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.11e+20 |\n",
      "|    alpha_mean          | 82       |\n",
      "|    alpha_std           | 43.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.11e+20 |\n",
      "|    kl_loss             | 1.38e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 455300   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.52e+11 |\n",
      "|    std                 | 1.01e+11 |\n",
      "|    temperature         | 6.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 530      |\n",
      "|    ep_rew_mean         | -122     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1212     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4132     |\n",
      "|    total_timesteps     | 465651   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.12e+20 |\n",
      "|    alpha_mean          | 82       |\n",
      "|    alpha_std           | 43.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.12e+20 |\n",
      "|    kl_loss             | 1.24e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 455650   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.27e+11 |\n",
      "|    std                 | 1.02e+11 |\n",
      "|    temperature         | 6.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 531      |\n",
      "|    ep_rew_mean         | -122     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1216     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4134     |\n",
      "|    total_timesteps     | 465924   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.13e+20 |\n",
      "|    alpha_mean          | 82.1     |\n",
      "|    alpha_std           | 43.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.13e+20 |\n",
      "|    kl_loss             | 1.27e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 455900   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.31e+11 |\n",
      "|    std                 | 1.03e+11 |\n",
      "|    temperature         | 6.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 485      |\n",
      "|    ep_rew_mean         | -120     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1220     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4136     |\n",
      "|    total_timesteps     | 466193   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.17e+20 |\n",
      "|    alpha_mean          | 82.1     |\n",
      "|    alpha_std           | 44       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.17e+20 |\n",
      "|    kl_loss             | 1.31e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 456150   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.39e+11 |\n",
      "|    std                 | 1.04e+11 |\n",
      "|    temperature         | 6.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 440      |\n",
      "|    ep_rew_mean         | -120     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1224     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4141     |\n",
      "|    total_timesteps     | 466681   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.2e+20  |\n",
      "|    alpha_mean          | 82.2     |\n",
      "|    alpha_std           | 44       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.2e+20  |\n",
      "|    kl_loss             | 1.42e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 456650   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.58e+11 |\n",
      "|    std                 | 1.06e+11 |\n",
      "|    temperature         | 6.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 425      |\n",
      "|    ep_rew_mean         | -119     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1228     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4144     |\n",
      "|    total_timesteps     | 467013   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.22e+20 |\n",
      "|    alpha_mean          | 82.3     |\n",
      "|    alpha_std           | 44       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.22e+20 |\n",
      "|    kl_loss             | 1.62e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 457000   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.96e+11 |\n",
      "|    std                 | 1.07e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 410      |\n",
      "|    ep_rew_mean         | -119     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1232     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4146     |\n",
      "|    total_timesteps     | 467260   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.24e+20 |\n",
      "|    alpha_mean          | 82.3     |\n",
      "|    alpha_std           | 44       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.24e+20 |\n",
      "|    kl_loss             | 1.43e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 457250   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.61e+11 |\n",
      "|    std                 | 1.07e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 410      |\n",
      "|    ep_rew_mean         | -119     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1236     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4163     |\n",
      "|    total_timesteps     | 469096   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.35e+20 |\n",
      "|    alpha_mean          | 82.7     |\n",
      "|    alpha_std           | 44.1     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.35e+20 |\n",
      "|    kl_loss             | 1.52e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 459050   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.75e+11 |\n",
      "|    std                 | 1.13e+11 |\n",
      "|    temperature         | 6.18     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 441      |\n",
      "|    ep_rew_mean         | -120     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1240     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4193     |\n",
      "|    total_timesteps     | 472440   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.58e+20 |\n",
      "|    alpha_mean          | 83.3     |\n",
      "|    alpha_std           | 44.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.58e+20 |\n",
      "|    kl_loss             | 1.52e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 462400   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.74e+11 |\n",
      "|    std                 | 1.25e+11 |\n",
      "|    temperature         | 6.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 441      |\n",
      "|    ep_rew_mean         | -120     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1244     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4209     |\n",
      "|    total_timesteps     | 474228   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.75e+20 |\n",
      "|    alpha_mean          | 83.6     |\n",
      "|    alpha_std           | 44.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.75e+20 |\n",
      "|    kl_loss             | 1.57e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 464200   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.81e+11 |\n",
      "|    std                 | 1.32e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 395      |\n",
      "|    ep_rew_mean         | -119     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1248     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4211     |\n",
      "|    total_timesteps     | 474478   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.77e+20 |\n",
      "|    alpha_mean          | 83.7     |\n",
      "|    alpha_std           | 44.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.77e+20 |\n",
      "|    kl_loss             | 1.34e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 464450   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.39e+11 |\n",
      "|    std                 | 1.33e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 379      |\n",
      "|    ep_rew_mean         | -118     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1252     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4213     |\n",
      "|    total_timesteps     | 474696   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.79e+20 |\n",
      "|    alpha_mean          | 83.7     |\n",
      "|    alpha_std           | 44.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.79e+20 |\n",
      "|    kl_loss             | 1.86e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 464650   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.32e+11 |\n",
      "|    std                 | 1.34e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 362      |\n",
      "|    ep_rew_mean         | -118     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1256     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4216     |\n",
      "|    total_timesteps     | 474959   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.81e+20 |\n",
      "|    alpha_mean          | 83.8     |\n",
      "|    alpha_std           | 44.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.81e+20 |\n",
      "|    kl_loss             | 1.72e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 464950   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.07e+11 |\n",
      "|    std                 | 1.35e+11 |\n",
      "|    temperature         | 6.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 350      |\n",
      "|    ep_rew_mean         | -118     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1260     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4235     |\n",
      "|    total_timesteps     | 477096   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.99e+20 |\n",
      "|    alpha_mean          | 84.2     |\n",
      "|    alpha_std           | 44.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.99e+20 |\n",
      "|    kl_loss             | 1.72e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 467050   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.06e+11 |\n",
      "|    std                 | 1.44e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 333      |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1264     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4238     |\n",
      "|    total_timesteps     | 477463   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3e+20    |\n",
      "|    alpha_mean          | 84.3     |\n",
      "|    alpha_std           | 44.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3e+20    |\n",
      "|    kl_loss             | 2.04e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 467450   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.62e+11 |\n",
      "|    std                 | 1.46e+11 |\n",
      "|    temperature         | 6.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 333      |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1268     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4240     |\n",
      "|    total_timesteps     | 477692   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.04e+20 |\n",
      "|    alpha_mean          | 84.3     |\n",
      "|    alpha_std           | 44.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.04e+20 |\n",
      "|    kl_loss             | 1.57e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 467650   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.79e+11 |\n",
      "|    std                 | 1.46e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 318      |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1272     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4243     |\n",
      "|    total_timesteps     | 477977   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.07e+20 |\n",
      "|    alpha_mean          | 84.3     |\n",
      "|    alpha_std           | 44.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.07e+20 |\n",
      "|    kl_loss             | 1.5e+13  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 467950   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.66e+11 |\n",
      "|    std                 | 1.48e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 333      |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1276     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4259     |\n",
      "|    total_timesteps     | 479716   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.24e+20 |\n",
      "|    alpha_mean          | 84.6     |\n",
      "|    alpha_std           | 45       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.24e+20 |\n",
      "|    kl_loss             | 1.51e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 469700   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.67e+11 |\n",
      "|    std                 | 1.56e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 303      |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1280     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4261     |\n",
      "|    total_timesteps     | 479994   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.26e+20 |\n",
      "|    alpha_mean          | 84.7     |\n",
      "|    alpha_std           | 45       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.26e+20 |\n",
      "|    kl_loss             | 1.58e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 469950   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 2.8e+11  |\n",
      "|    std                 | 1.57e+11 |\n",
      "|    temperature         | 6.18     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 318      |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1284     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4277     |\n",
      "|    total_timesteps     | 481800   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.44e+20 |\n",
      "|    alpha_mean          | 85       |\n",
      "|    alpha_std           | 45.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.44e+20 |\n",
      "|    kl_loss             | 1.86e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 471750   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.28e+11 |\n",
      "|    std                 | 1.65e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 287      |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1288     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4279     |\n",
      "|    total_timesteps     | 481997   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.47e+20 |\n",
      "|    alpha_mean          | 85.1     |\n",
      "|    alpha_std           | 45.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.47e+20 |\n",
      "|    kl_loss             | 1.84e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 471950   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.24e+11 |\n",
      "|    std                 | 1.66e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 303      |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1292     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4296     |\n",
      "|    total_timesteps     | 483815   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.65e+20 |\n",
      "|    alpha_mean          | 85.4     |\n",
      "|    alpha_std           | 45.3     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.65e+20 |\n",
      "|    kl_loss             | 2.01e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 473800   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.53e+11 |\n",
      "|    std                 | 1.75e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 287      |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1296     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4311     |\n",
      "|    total_timesteps     | 485540   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.81e+20 |\n",
      "|    alpha_mean          | 85.7     |\n",
      "|    alpha_std           | 45.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.81e+20 |\n",
      "|    kl_loss             | 2.12e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 475500   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.71e+11 |\n",
      "|    std                 | 1.84e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 255      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1300     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4313     |\n",
      "|    total_timesteps     | 485721   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.82e+20 |\n",
      "|    alpha_mean          | 85.8     |\n",
      "|    alpha_std           | 45.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.82e+20 |\n",
      "|    kl_loss             | 1.84e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 475700   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.21e+11 |\n",
      "|    std                 | 1.85e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 208      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1304     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4314     |\n",
      "|    total_timesteps     | 485919   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.85e+20 |\n",
      "|    alpha_mean          | 85.8     |\n",
      "|    alpha_std           | 45.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.85e+20 |\n",
      "|    kl_loss             | 1.89e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 475900   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.3e+11  |\n",
      "|    std                 | 1.86e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 209      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1308     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4317     |\n",
      "|    total_timesteps     | 486157   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.88e+20 |\n",
      "|    alpha_mean          | 85.9     |\n",
      "|    alpha_std           | 45.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.88e+20 |\n",
      "|    kl_loss             | 2.02e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 476150   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.52e+11 |\n",
      "|    std                 | 1.88e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 224      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1312     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4333     |\n",
      "|    total_timesteps     | 488012   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.06e+20 |\n",
      "|    alpha_mean          | 86.2     |\n",
      "|    alpha_std           | 45.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 4.06e+20 |\n",
      "|    kl_loss             | 2.56e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 478000   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.45e+11 |\n",
      "|    std                 | 1.98e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 223      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1316     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4335     |\n",
      "|    total_timesteps     | 488189   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.13e+20 |\n",
      "|    alpha_mean          | 86.2     |\n",
      "|    alpha_std           | 45.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 4.13e+20 |\n",
      "|    kl_loss             | 1.99e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 478150   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.45e+11 |\n",
      "|    std                 | 1.99e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 222      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1320     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4337     |\n",
      "|    total_timesteps     | 488379   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.12e+20 |\n",
      "|    alpha_mean          | 86.3     |\n",
      "|    alpha_std           | 45.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 4.12e+20 |\n",
      "|    kl_loss             | 2.11e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 478350   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.66e+11 |\n",
      "|    std                 | 2e+11    |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 219      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1324     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4338     |\n",
      "|    total_timesteps     | 488572   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.13e+20 |\n",
      "|    alpha_mean          | 86.3     |\n",
      "|    alpha_std           | 45.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 4.13e+20 |\n",
      "|    kl_loss             | 1.97e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 478550   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.42e+11 |\n",
      "|    std                 | 2.01e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 233      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1328     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4354     |\n",
      "|    total_timesteps     | 490306   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.39e+20 |\n",
      "|    alpha_mean          | 86.6     |\n",
      "|    alpha_std           | 45.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 4.39e+20 |\n",
      "|    kl_loss             | 2.39e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 480300   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.12e+11 |\n",
      "|    std                 | 2.11e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 233      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1332     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4356     |\n",
      "|    total_timesteps     | 490554   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.42e+20 |\n",
      "|    alpha_mean          | 86.7     |\n",
      "|    alpha_std           | 45.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 4.42e+20 |\n",
      "|    kl_loss             | 1.79e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 480550   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.09e+11 |\n",
      "|    std                 | 2.13e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 216      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1336     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4358     |\n",
      "|    total_timesteps     | 490730   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.46e+20 |\n",
      "|    alpha_mean          | 86.7     |\n",
      "|    alpha_std           | 45.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 4.46e+20 |\n",
      "|    kl_loss             | 2.07e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 480700   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.57e+11 |\n",
      "|    std                 | 2.14e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 202      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1340     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4375     |\n",
      "|    total_timesteps     | 492604   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.68e+20 |\n",
      "|    alpha_mean          | 87       |\n",
      "|    alpha_std           | 46       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 4.68e+20 |\n",
      "|    kl_loss             | 2.18e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 482600   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.75e+11 |\n",
      "|    std                 | 2.26e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 187      |\n",
      "|    ep_rew_mean         | -114     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1344     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4377     |\n",
      "|    total_timesteps     | 492882   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.71e+20 |\n",
      "|    alpha_mean          | 87.1     |\n",
      "|    alpha_std           | 46       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 4.71e+20 |\n",
      "|    kl_loss             | 2.28e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 482850   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.93e+11 |\n",
      "|    std                 | 2.27e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 186      |\n",
      "|    ep_rew_mean         | -114     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1348     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4379     |\n",
      "|    total_timesteps     | 493100   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.76e+20 |\n",
      "|    alpha_mean          | 87.1     |\n",
      "|    alpha_std           | 46.1     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 4.76e+20 |\n",
      "|    kl_loss             | 2.18e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 483050   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.76e+11 |\n",
      "|    std                 | 2.29e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 193      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1352     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4387     |\n",
      "|    total_timesteps     | 494006   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.92e+20 |\n",
      "|    alpha_mean          | 87.3     |\n",
      "|    alpha_std           | 46.1     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 4.92e+20 |\n",
      "|    kl_loss             | 2.56e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 484000   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.39e+11 |\n",
      "|    std                 | 2.35e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 198      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1356     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4394     |\n",
      "|    total_timesteps     | 494773   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 4.98e+20 |\n",
      "|    alpha_mean          | 87.4     |\n",
      "|    alpha_std           | 46.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 4.98e+20 |\n",
      "|    kl_loss             | 2.49e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 484750   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.26e+11 |\n",
      "|    std                 | 2.4e+11  |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 179      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1360     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4396     |\n",
      "|    total_timesteps     | 495022   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.02e+20 |\n",
      "|    alpha_mean          | 87.5     |\n",
      "|    alpha_std           | 46.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 5.02e+20 |\n",
      "|    kl_loss             | 2.12e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 485000   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.63e+11 |\n",
      "|    std                 | 2.42e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 194      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1364     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4413     |\n",
      "|    total_timesteps     | 496853   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.3e+20  |\n",
      "|    alpha_mean          | 87.8     |\n",
      "|    alpha_std           | 46.3     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 5.3e+20  |\n",
      "|    kl_loss             | 2.56e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 486850   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.37e+11 |\n",
      "|    std                 | 2.55e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 194      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1368     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4415     |\n",
      "|    total_timesteps     | 497096   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.31e+20 |\n",
      "|    alpha_mean          | 87.8     |\n",
      "|    alpha_std           | 46.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 5.31e+20 |\n",
      "|    kl_loss             | 2.11e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 487050   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.59e+11 |\n",
      "|    std                 | 2.56e+11 |\n",
      "|    temperature         | 6.18     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 194      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1372     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4418     |\n",
      "|    total_timesteps     | 497355   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.34e+20 |\n",
      "|    alpha_mean          | 87.9     |\n",
      "|    alpha_std           | 46.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 5.34e+20 |\n",
      "|    kl_loss             | 2.61e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 487350   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.45e+11 |\n",
      "|    std                 | 2.58e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 179      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1376     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4420     |\n",
      "|    total_timesteps     | 497630   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.38e+20 |\n",
      "|    alpha_mean          | 87.9     |\n",
      "|    alpha_std           | 46.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 5.38e+20 |\n",
      "|    kl_loss             | 2.59e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 487600   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.4e+11  |\n",
      "|    std                 | 2.6e+11  |\n",
      "|    temperature         | 6.18     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 180      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1380     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4423     |\n",
      "|    total_timesteps     | 497993   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.51e+20 |\n",
      "|    alpha_mean          | 88       |\n",
      "|    alpha_std           | 46.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 5.51e+20 |\n",
      "|    kl_loss             | 2.82e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 487950   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.8e+11  |\n",
      "|    std                 | 2.63e+11 |\n",
      "|    temperature         | 6.18     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 168      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1384     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4429     |\n",
      "|    total_timesteps     | 498610   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.55e+20 |\n",
      "|    alpha_mean          | 88.1     |\n",
      "|    alpha_std           | 46.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 5.55e+20 |\n",
      "|    kl_loss             | 2.47e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 488600   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.19e+11 |\n",
      "|    std                 | 2.68e+11 |\n",
      "|    temperature         | 6.18     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 169      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1388     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4431     |\n",
      "|    total_timesteps     | 498860   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.6e+20  |\n",
      "|    alpha_mean          | 88.2     |\n",
      "|    alpha_std           | 46.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 5.6e+20  |\n",
      "|    kl_loss             | 2.62e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 488850   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.44e+11 |\n",
      "|    std                 | 2.7e+11  |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 153      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1392     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4434     |\n",
      "|    total_timesteps     | 499160   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.66e+20 |\n",
      "|    alpha_mean          | 88.2     |\n",
      "|    alpha_std           | 46.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 5.66e+20 |\n",
      "|    kl_loss             | 2.54e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 489150   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.31e+11 |\n",
      "|    std                 | 2.72e+11 |\n",
      "|    temperature         | 6.18     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 139      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1396     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4436     |\n",
      "|    total_timesteps     | 499410   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 5.69e+20 |\n",
      "|    alpha_mean          | 88.3     |\n",
      "|    alpha_std           | 46.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 5.69e+20 |\n",
      "|    kl_loss             | 2.26e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 489400   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.83e+11 |\n",
      "|    std                 | 2.74e+11 |\n",
      "|    temperature         | 6.19     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 156      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1400     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4453     |\n",
      "|    total_timesteps     | 501280   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.02e+20 |\n",
      "|    alpha_mean          | 88.6     |\n",
      "|    alpha_std           | 46.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 6.02e+20 |\n",
      "|    kl_loss             | 2.82e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 491250   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.77e+11 |\n",
      "|    std                 | 2.89e+11 |\n",
      "|    temperature         | 6.18     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 156      |\n",
      "|    ep_rew_mean         | -115     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1404     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4455     |\n",
      "|    total_timesteps     | 501537   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.06e+20 |\n",
      "|    alpha_mean          | 88.7     |\n",
      "|    alpha_std           | 46.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 6.06e+20 |\n",
      "|    kl_loss             | 2.34e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 491500   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.94e+11 |\n",
      "|    std                 | 2.9e+11  |\n",
      "|    temperature         | 6.17     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 187      |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1408     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4485     |\n",
      "|    total_timesteps     | 504828   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.59e+20 |\n",
      "|    alpha_mean          | 89.3     |\n",
      "|    alpha_std           | 47.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 6.59e+20 |\n",
      "|    kl_loss             | 2.41e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 494800   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.04e+11 |\n",
      "|    std                 | 3.19e+11 |\n",
      "|    temperature         | 6.16     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 171      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1412     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4487     |\n",
      "|    total_timesteps     | 505095   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.64e+20 |\n",
      "|    alpha_mean          | 89.3     |\n",
      "|    alpha_std           | 47.3     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 6.64e+20 |\n",
      "|    kl_loss             | 2.77e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 495050   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.65e+11 |\n",
      "|    std                 | 3.21e+11 |\n",
      "|    temperature         | 6.15     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 172      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1416     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4489     |\n",
      "|    total_timesteps     | 505340   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.75e+20 |\n",
      "|    alpha_mean          | 89.4     |\n",
      "|    alpha_std           | 47.3     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 6.75e+20 |\n",
      "|    kl_loss             | 2.85e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 495300   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.77e+11 |\n",
      "|    std                 | 3.23e+11 |\n",
      "|    temperature         | 6.16     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 172      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1420     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4491     |\n",
      "|    total_timesteps     | 505547   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.73e+20 |\n",
      "|    alpha_mean          | 89.4     |\n",
      "|    alpha_std           | 47.3     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 6.73e+20 |\n",
      "|    kl_loss             | 2.47e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 495500   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.14e+11 |\n",
      "|    std                 | 3.25e+11 |\n",
      "|    temperature         | 6.16     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 177      |\n",
      "|    ep_rew_mean         | -116     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1424     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4497     |\n",
      "|    total_timesteps     | 506224   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 6.91e+20 |\n",
      "|    alpha_mean          | 89.6     |\n",
      "|    alpha_std           | 47.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 6.91e+20 |\n",
      "|    kl_loss             | 3.1e+13  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 496200   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 5.19e+11 |\n",
      "|    std                 | 3.31e+11 |\n",
      "|    temperature         | 6.16     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 178      |\n",
      "|    ep_rew_mean         | -117     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1428     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4514     |\n",
      "|    total_timesteps     | 508064   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 7.23e+20 |\n",
      "|    alpha_mean          | 89.9     |\n",
      "|    alpha_std           | 47.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 7.23e+20 |\n",
      "|    kl_loss             | 2.21e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 498050   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 3.68e+11 |\n",
      "|    std                 | 3.49e+11 |\n",
      "|    temperature         | 6.16     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 198      |\n",
      "|    ep_rew_mean         | -118     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1432     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4534     |\n",
      "|    total_timesteps     | 510327   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 7.76e+20 |\n",
      "|    alpha_mean          | 90.3     |\n",
      "|    alpha_std           | 47.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 7.76e+20 |\n",
      "|    kl_loss             | 2.42e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 500300   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.01e+11 |\n",
      "|    std                 | 3.72e+11 |\n",
      "|    temperature         | 6.16     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 210      |\n",
      "|    ep_rew_mean         | -120     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1436     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4547     |\n",
      "|    total_timesteps     | 511724   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 7.99e+20 |\n",
      "|    alpha_mean          | 90.6     |\n",
      "|    alpha_std           | 47.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 7.99e+20 |\n",
      "|    kl_loss             | 2.86e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 501700   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.73e+11 |\n",
      "|    std                 | 3.86e+11 |\n",
      "|    temperature         | 6.15     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 195      |\n",
      "|    ep_rew_mean         | -120     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1440     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4551     |\n",
      "|    total_timesteps     | 512134   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 8.06e+20 |\n",
      "|    alpha_mean          | 90.6     |\n",
      "|    alpha_std           | 48       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 8.06e+20 |\n",
      "|    kl_loss             | 3.01e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 502100   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 4.98e+11 |\n",
      "|    std                 | 3.9e+11  |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 206      |\n",
      "|    ep_rew_mean         | -121     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1444     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4563     |\n",
      "|    total_timesteps     | 513514   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 8.38e+20 |\n",
      "|    alpha_mean          | 90.9     |\n",
      "|    alpha_std           | 48.1     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 8.38e+20 |\n",
      "|    kl_loss             | 3.25e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 503500   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 5.36e+11 |\n",
      "|    std                 | 4.06e+11 |\n",
      "|    temperature         | 6.15     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 229      |\n",
      "|    ep_rew_mean         | -123     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1448     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4585     |\n",
      "|    total_timesteps     | 515951   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.03e+20 |\n",
      "|    alpha_mean          | 91.4     |\n",
      "|    alpha_std           | 48.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 9.03e+20 |\n",
      "|    kl_loss             | 3.74e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 505950   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.13e+11 |\n",
      "|    std                 | 4.34e+11 |\n",
      "|    temperature         | 6.16     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 225      |\n",
      "|    ep_rew_mean         | -123     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1452     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4590     |\n",
      "|    total_timesteps     | 516515   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.19e+20 |\n",
      "|    alpha_mean          | 91.5     |\n",
      "|    alpha_std           | 48.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 9.19e+20 |\n",
      "|    kl_loss             | 3.44e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 506500   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 5.64e+11 |\n",
      "|    std                 | 4.4e+11  |\n",
      "|    temperature         | 6.17     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 223      |\n",
      "|    ep_rew_mean         | -123     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1456     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4595     |\n",
      "|    total_timesteps     | 517075   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.26e+20 |\n",
      "|    alpha_mean          | 91.6     |\n",
      "|    alpha_std           | 48.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 9.26e+20 |\n",
      "|    kl_loss             | 3.63e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 507050   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 5.94e+11 |\n",
      "|    std                 | 4.47e+11 |\n",
      "|    temperature         | 6.17     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 232      |\n",
      "|    ep_rew_mean         | -124     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1460     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4605     |\n",
      "|    total_timesteps     | 518184   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.52e+20 |\n",
      "|    alpha_mean          | 91.8     |\n",
      "|    alpha_std           | 48.7     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 9.52e+20 |\n",
      "|    kl_loss             | 3.31e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 508150   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 5.4e+11  |\n",
      "|    std                 | 4.6e+11  |\n",
      "|    temperature         | 6.17     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 226      |\n",
      "|    ep_rew_mean         | -125     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1464     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4616     |\n",
      "|    total_timesteps     | 519418   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 9.85e+20 |\n",
      "|    alpha_mean          | 92       |\n",
      "|    alpha_std           | 48.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 9.85e+20 |\n",
      "|    kl_loss             | 3.49e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 509400   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 5.68e+11 |\n",
      "|    std                 | 4.76e+11 |\n",
      "|    temperature         | 6.16     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 234      |\n",
      "|    ep_rew_mean         | -126     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1468     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4626     |\n",
      "|    total_timesteps     | 520521   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.02e+21 |\n",
      "|    alpha_mean          | 92.2     |\n",
      "|    alpha_std           | 48.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.02e+21 |\n",
      "|    kl_loss             | 3.38e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 510500   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 5.48e+11 |\n",
      "|    std                 | 4.91e+11 |\n",
      "|    temperature         | 6.15     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 240      |\n",
      "|    ep_rew_mean         | -127     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1472     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4633     |\n",
      "|    total_timesteps     | 521331   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.05e+21 |\n",
      "|    alpha_mean          | 92.4     |\n",
      "|    alpha_std           | 49       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.05e+21 |\n",
      "|    kl_loss             | 3.85e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 511300   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.24e+11 |\n",
      "|    std                 | 5.02e+11 |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 240      |\n",
      "|    ep_rew_mean         | -127     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1476     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4636     |\n",
      "|    total_timesteps     | 521580   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.05e+21 |\n",
      "|    alpha_mean          | 92.4     |\n",
      "|    alpha_std           | 49       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.05e+21 |\n",
      "|    kl_loss             | 3.58e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 511550   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 5.8e+11  |\n",
      "|    std                 | 5.05e+11 |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 247      |\n",
      "|    ep_rew_mean         | -128     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1480     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4646     |\n",
      "|    total_timesteps     | 522728   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.08e+21 |\n",
      "|    alpha_mean          | 92.6     |\n",
      "|    alpha_std           | 49.1     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.08e+21 |\n",
      "|    kl_loss             | 3.67e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 512700   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 5.93e+11 |\n",
      "|    std                 | 5.21e+11 |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 245      |\n",
      "|    ep_rew_mean         | -128     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1484     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4650     |\n",
      "|    total_timesteps     | 523154   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.1e+21  |\n",
      "|    alpha_mean          | 92.7     |\n",
      "|    alpha_std           | 49.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.1e+21  |\n",
      "|    kl_loss             | 3.14e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 513150   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 5.08e+11 |\n",
      "|    std                 | 5.27e+11 |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 258      |\n",
      "|    ep_rew_mean         | -129     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1488     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4664     |\n",
      "|    total_timesteps     | 524672   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.14e+21 |\n",
      "|    alpha_mean          | 93       |\n",
      "|    alpha_std           | 49.3     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.14e+21 |\n",
      "|    kl_loss             | 4.36e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 514650   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.03e+11 |\n",
      "|    std                 | 5.49e+11 |\n",
      "|    temperature         | 6.13     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 259      |\n",
      "|    ep_rew_mean         | -130     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1492     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4667     |\n",
      "|    total_timesteps     | 525049   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.15e+21 |\n",
      "|    alpha_mean          | 93.1     |\n",
      "|    alpha_std           | 49.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.15e+21 |\n",
      "|    kl_loss             | 3.52e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 515000   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 5.66e+11 |\n",
      "|    std                 | 5.55e+11 |\n",
      "|    temperature         | 6.13     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 262      |\n",
      "|    ep_rew_mean         | -130     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1496     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4672     |\n",
      "|    total_timesteps     | 525632   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.17e+21 |\n",
      "|    alpha_mean          | 93.2     |\n",
      "|    alpha_std           | 49.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.17e+21 |\n",
      "|    kl_loss             | 3.86e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 515600   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.21e+11 |\n",
      "|    std                 | 5.64e+11 |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 257      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1500     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4684     |\n",
      "|    total_timesteps     | 526999   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.21e+21 |\n",
      "|    alpha_mean          | 93.4     |\n",
      "|    alpha_std           | 49.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.21e+21 |\n",
      "|    kl_loss             | 4.42e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 516950   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.09e+11 |\n",
      "|    std                 | 5.84e+11 |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 257      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1504     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4687     |\n",
      "|    total_timesteps     | 527245   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.22e+21 |\n",
      "|    alpha_mean          | 93.5     |\n",
      "|    alpha_std           | 49.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.22e+21 |\n",
      "|    kl_loss             | 4.11e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 517200   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.58e+11 |\n",
      "|    std                 | 5.88e+11 |\n",
      "|    temperature         | 6.15     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 232      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1508     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4693     |\n",
      "|    total_timesteps     | 527991   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.25e+21 |\n",
      "|    alpha_mean          | 93.6     |\n",
      "|    alpha_std           | 49.7     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.25e+21 |\n",
      "|    kl_loss             | 4.46e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 517950   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.14e+11 |\n",
      "|    std                 | 6e+11    |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 232      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1512     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4696     |\n",
      "|    total_timesteps     | 528280   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.26e+21 |\n",
      "|    alpha_mean          | 93.7     |\n",
      "|    alpha_std           | 49.7     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.26e+21 |\n",
      "|    kl_loss             | 3.91e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 518250   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.26e+11 |\n",
      "|    std                 | 6.05e+11 |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 233      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1516     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4699     |\n",
      "|    total_timesteps     | 528612   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.27e+21 |\n",
      "|    alpha_mean          | 93.7     |\n",
      "|    alpha_std           | 49.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.27e+21 |\n",
      "|    kl_loss             | 4.11e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 518600   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.57e+11 |\n",
      "|    std                 | 6.11e+11 |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 235      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1520     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4703     |\n",
      "|    total_timesteps     | 529057   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.28e+21 |\n",
      "|    alpha_mean          | 93.8     |\n",
      "|    alpha_std           | 49.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.28e+21 |\n",
      "|    kl_loss             | 4.05e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 519050   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.47e+11 |\n",
      "|    std                 | 6.18e+11 |\n",
      "|    temperature         | 6.13     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 242      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1524     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4716     |\n",
      "|    total_timesteps     | 530406   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.34e+21 |\n",
      "|    alpha_mean          | 94.1     |\n",
      "|    alpha_std           | 50       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.34e+21 |\n",
      "|    kl_loss             | 3.63e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 520400   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 5.78e+11 |\n",
      "|    std                 | 6.41e+11 |\n",
      "|    temperature         | 6.14     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 227      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1528     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4719     |\n",
      "|    total_timesteps     | 530795   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.35e+21 |\n",
      "|    alpha_mean          | 94.1     |\n",
      "|    alpha_std           | 50       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.35e+21 |\n",
      "|    kl_loss             | 4.35e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 520750   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.92e+11 |\n",
      "|    std                 | 6.47e+11 |\n",
      "|    temperature         | 6.13     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 212      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1532     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4725     |\n",
      "|    total_timesteps     | 531537   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.37e+21 |\n",
      "|    alpha_mean          | 94.3     |\n",
      "|    alpha_std           | 50.1     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.37e+21 |\n",
      "|    kl_loss             | 3.82e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 521500   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.07e+11 |\n",
      "|    std                 | 6.6e+11  |\n",
      "|    temperature         | 6.13     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 203      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1536     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4730     |\n",
      "|    total_timesteps     | 532039   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.38e+21 |\n",
      "|    alpha_mean          | 94.4     |\n",
      "|    alpha_std           | 50.1     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.38e+21 |\n",
      "|    kl_loss             | 4.42e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 522000   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.02e+11 |\n",
      "|    std                 | 6.69e+11 |\n",
      "|    temperature         | 6.13     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 211      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1540     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4741     |\n",
      "|    total_timesteps     | 533271   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.44e+21 |\n",
      "|    alpha_mean          | 94.6     |\n",
      "|    alpha_std           | 50.3     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.44e+21 |\n",
      "|    kl_loss             | 4.63e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 523250   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.34e+11 |\n",
      "|    std                 | 6.91e+11 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 221      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1544     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4763     |\n",
      "|    total_timesteps     | 535633   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.54e+21 |\n",
      "|    alpha_mean          | 95.1     |\n",
      "|    alpha_std           | 50.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.54e+21 |\n",
      "|    kl_loss             | 4.51e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 525600   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.11e+11 |\n",
      "|    std                 | 7.37e+11 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 212      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1548     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4777     |\n",
      "|    total_timesteps     | 537189   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.59e+21 |\n",
      "|    alpha_mean          | 95.4     |\n",
      "|    alpha_std           | 50.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.59e+21 |\n",
      "|    kl_loss             | 4.71e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 527150   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.4e+11  |\n",
      "|    std                 | 7.67e+11 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 210      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1552     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4779     |\n",
      "|    total_timesteps     | 537496   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.61e+21 |\n",
      "|    alpha_mean          | 95.4     |\n",
      "|    alpha_std           | 50.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.61e+21 |\n",
      "|    kl_loss             | 4.63e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 527450   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.28e+11 |\n",
      "|    std                 | 7.73e+11 |\n",
      "|    temperature         | 6.12     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 208      |\n",
      "|    ep_rew_mean         | -130     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1556     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4782     |\n",
      "|    total_timesteps     | 537846   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.62e+21 |\n",
      "|    alpha_mean          | 95.5     |\n",
      "|    alpha_std           | 50.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.62e+21 |\n",
      "|    kl_loss             | 4.3e+13  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 527800   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.75e+11 |\n",
      "|    std                 | 7.8e+11  |\n",
      "|    temperature         | 6.12     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 201      |\n",
      "|    ep_rew_mean         | -130     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1560     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4786     |\n",
      "|    total_timesteps     | 538276   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.64e+21 |\n",
      "|    alpha_mean          | 95.6     |\n",
      "|    alpha_std           | 50.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.64e+21 |\n",
      "|    kl_loss             | 4.41e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 528250   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.92e+11 |\n",
      "|    std                 | 7.89e+11 |\n",
      "|    temperature         | 6.12     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 196      |\n",
      "|    ep_rew_mean         | -129     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1564     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4794     |\n",
      "|    total_timesteps     | 539055   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.67e+21 |\n",
      "|    alpha_mean          | 95.7     |\n",
      "|    alpha_std           | 51       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.67e+21 |\n",
      "|    kl_loss             | 4.33e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 529050   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.78e+11 |\n",
      "|    std                 | 8.06e+11 |\n",
      "|    temperature         | 6.12     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 190      |\n",
      "|    ep_rew_mean         | -129     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1568     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4798     |\n",
      "|    total_timesteps     | 539535   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.7e+21  |\n",
      "|    alpha_mean          | 95.8     |\n",
      "|    alpha_std           | 51       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.7e+21  |\n",
      "|    kl_loss             | 4e+13    |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 529500   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.26e+11 |\n",
      "|    std                 | 8.15e+11 |\n",
      "|    temperature         | 6.12     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 195      |\n",
      "|    ep_rew_mean         | -129     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1572     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4809     |\n",
      "|    total_timesteps     | 540812   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.74e+21 |\n",
      "|    alpha_mean          | 96.1     |\n",
      "|    alpha_std           | 51.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.74e+21 |\n",
      "|    kl_loss             | 4.08e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 530800   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.37e+11 |\n",
      "|    std                 | 8.43e+11 |\n",
      "|    temperature         | 6.13     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 203      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1576     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4819     |\n",
      "|    total_timesteps     | 541904   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.81e+21 |\n",
      "|    alpha_mean          | 96.3     |\n",
      "|    alpha_std           | 51.3     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.81e+21 |\n",
      "|    kl_loss             | 4.83e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 531900   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.52e+11 |\n",
      "|    std                 | 8.69e+11 |\n",
      "|    temperature         | 6.12     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 199      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1580     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4826     |\n",
      "|    total_timesteps     | 542655   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.84e+21 |\n",
      "|    alpha_mean          | 96.4     |\n",
      "|    alpha_std           | 51.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.84e+21 |\n",
      "|    kl_loss             | 4.67e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 532650   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.25e+11 |\n",
      "|    std                 | 8.86e+11 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 219      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1584     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4847     |\n",
      "|    total_timesteps     | 545009   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 1.96e+21 |\n",
      "|    alpha_mean          | 96.8     |\n",
      "|    alpha_std           | 51.7     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 1.96e+21 |\n",
      "|    kl_loss             | 4.98e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 535000   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.71e+11 |\n",
      "|    std                 | 9.42e+11 |\n",
      "|    temperature         | 6.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 218      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1588     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4860     |\n",
      "|    total_timesteps     | 546495   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.03e+21 |\n",
      "|    alpha_mean          | 97.1     |\n",
      "|    alpha_std           | 51.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.03e+21 |\n",
      "|    kl_loss             | 5.07e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 536450   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.83e+11 |\n",
      "|    std                 | 9.77e+11 |\n",
      "|    temperature         | 6.08     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 218      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1592     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4864     |\n",
      "|    total_timesteps     | 546834   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.05e+21 |\n",
      "|    alpha_mean          | 97.2     |\n",
      "|    alpha_std           | 51.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.05e+21 |\n",
      "|    kl_loss             | 4.78e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 536800   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.37e+11 |\n",
      "|    std                 | 9.86e+11 |\n",
      "|    temperature         | 6.08     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 215      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1596     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4867     |\n",
      "|    total_timesteps     | 547180   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.06e+21 |\n",
      "|    alpha_mean          | 97.2     |\n",
      "|    alpha_std           | 51.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.06e+21 |\n",
      "|    kl_loss             | 5.01e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 537150   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.73e+11 |\n",
      "|    std                 | 9.95e+11 |\n",
      "|    temperature         | 6.08     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 208      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1600     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4872     |\n",
      "|    total_timesteps     | 547788   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.11e+21 |\n",
      "|    alpha_mean          | 97.4     |\n",
      "|    alpha_std           | 52       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.11e+21 |\n",
      "|    kl_loss             | 4.49e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 537750   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 6.91e+11 |\n",
      "|    std                 | 1.01e+12 |\n",
      "|    temperature         | 6.07     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 209      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1604     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4875     |\n",
      "|    total_timesteps     | 548145   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.13e+21 |\n",
      "|    alpha_mean          | 97.4     |\n",
      "|    alpha_std           | 52       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.13e+21 |\n",
      "|    kl_loss             | 5.37e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 538100   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 8.26e+11 |\n",
      "|    std                 | 1.02e+12 |\n",
      "|    temperature         | 6.08     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 220      |\n",
      "|    ep_rew_mean         | -131     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1608     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4892     |\n",
      "|    total_timesteps     | 550000   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.21e+21 |\n",
      "|    alpha_mean          | 97.8     |\n",
      "|    alpha_std           | 52.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.21e+21 |\n",
      "|    kl_loss             | 5.48e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 539950   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 8.4e+11  |\n",
      "|    std                 | 1.07e+12 |\n",
      "|    temperature         | 6.07     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 228      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1612     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4902     |\n",
      "|    total_timesteps     | 551055   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.28e+21 |\n",
      "|    alpha_mean          | 98       |\n",
      "|    alpha_std           | 52.3     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.28e+21 |\n",
      "|    kl_loss             | 4.62e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 541050   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.07e+11 |\n",
      "|    std                 | 1.1e+12  |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 232      |\n",
      "|    ep_rew_mean         | -133     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1616     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4908     |\n",
      "|    total_timesteps     | 551775   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.32e+21 |\n",
      "|    alpha_mean          | 98.1     |\n",
      "|    alpha_std           | 52.4     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.32e+21 |\n",
      "|    kl_loss             | 5.38e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 541750   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 8.21e+11 |\n",
      "|    std                 | 1.12e+12 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 251      |\n",
      "|    ep_rew_mean         | -134     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1620     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4929     |\n",
      "|    total_timesteps     | 554150   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.48e+21 |\n",
      "|    alpha_mean          | 98.6     |\n",
      "|    alpha_std           | 52.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.48e+21 |\n",
      "|    kl_loss             | 5.34e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 544100   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 8.12e+11 |\n",
      "|    std                 | 1.19e+12 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 251      |\n",
      "|    ep_rew_mean         | -134     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1624     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4942     |\n",
      "|    total_timesteps     | 555541   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.56e+21 |\n",
      "|    alpha_mean          | 98.8     |\n",
      "|    alpha_std           | 52.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.56e+21 |\n",
      "|    kl_loss             | 5.36e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 545500   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 8.12e+11 |\n",
      "|    std                 | 1.23e+12 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 256      |\n",
      "|    ep_rew_mean         | -134     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1628     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4950     |\n",
      "|    total_timesteps     | 556353   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.61e+21 |\n",
      "|    alpha_mean          | 99       |\n",
      "|    alpha_std           | 52.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.61e+21 |\n",
      "|    kl_loss             | 4.97e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 546350   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.53e+11 |\n",
      "|    std                 | 1.26e+12 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 258      |\n",
      "|    ep_rew_mean         | -134     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1632     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4958     |\n",
      "|    total_timesteps     | 557298   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.68e+21 |\n",
      "|    alpha_mean          | 99.2     |\n",
      "|    alpha_std           | 53       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.68e+21 |\n",
      "|    kl_loss             | 5.11e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 547250   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.73e+11 |\n",
      "|    std                 | 1.29e+12 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 260      |\n",
      "|    ep_rew_mean         | -134     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1636     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4965     |\n",
      "|    total_timesteps     | 558074   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.72e+21 |\n",
      "|    alpha_mean          | 99.3     |\n",
      "|    alpha_std           | 53.1     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.72e+21 |\n",
      "|    kl_loss             | 5.79e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 548050   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 8.74e+11 |\n",
      "|    std                 | 1.32e+12 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 256      |\n",
      "|    ep_rew_mean         | -134     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1640     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4972     |\n",
      "|    total_timesteps     | 558830   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.76e+21 |\n",
      "|    alpha_mean          | 99.5     |\n",
      "|    alpha_std           | 53.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.76e+21 |\n",
      "|    kl_loss             | 5.51e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 548800   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 8.31e+11 |\n",
      "|    std                 | 1.34e+12 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 237      |\n",
      "|    ep_rew_mean         | -133     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1644     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4976     |\n",
      "|    total_timesteps     | 559287   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.83e+21 |\n",
      "|    alpha_mean          | 99.6     |\n",
      "|    alpha_std           | 53.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.83e+21 |\n",
      "|    kl_loss             | 5.58e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 549250   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 8.39e+11 |\n",
      "|    std                 | 1.36e+12 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 226      |\n",
      "|    ep_rew_mean         | -132     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1648     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 4980     |\n",
      "|    total_timesteps     | 559740   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 2.84e+21 |\n",
      "|    alpha_mean          | 99.6     |\n",
      "|    alpha_std           | 53.2     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 2.84e+21 |\n",
      "|    kl_loss             | 5.71e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 549700   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 8.59e+11 |\n",
      "|    std                 | 1.37e+12 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 245      |\n",
      "|    ep_rew_mean         | -133     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1652     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 5000     |\n",
      "|    total_timesteps     | 561949   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.01e+21 |\n",
      "|    alpha_mean          | 100      |\n",
      "|    alpha_std           | 53.5     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.01e+21 |\n",
      "|    kl_loss             | 5.62e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 551900   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 8.41e+11 |\n",
      "|    std                 | 1.45e+12 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 246      |\n",
      "|    ep_rew_mean         | -133     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1656     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 5004     |\n",
      "|    total_timesteps     | 562401   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.05e+21 |\n",
      "|    alpha_mean          | 100      |\n",
      "|    alpha_std           | 53.6     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.05e+21 |\n",
      "|    kl_loss             | 5.07e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 552400   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.59e+11 |\n",
      "|    std                 | 1.47e+12 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 260      |\n",
      "|    ep_rew_mean         | -133     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1660     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 5021     |\n",
      "|    total_timesteps     | 564291   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.21e+21 |\n",
      "|    alpha_mean          | 101      |\n",
      "|    alpha_std           | 53.8     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.21e+21 |\n",
      "|    kl_loss             | 4.9e+13  |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 554250   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 7.31e+11 |\n",
      "|    std                 | 1.54e+12 |\n",
      "|    temperature         | 6.09     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 267      |\n",
      "|    ep_rew_mean         | -134     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1664     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 5034     |\n",
      "|    total_timesteps     | 565717   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.31e+21 |\n",
      "|    alpha_mean          | 101      |\n",
      "|    alpha_std           | 53.9     |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.31e+21 |\n",
      "|    kl_loss             | 6.16e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 555700   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 9.16e+11 |\n",
      "|    std                 | 1.6e+12  |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/               |          |\n",
      "|    ep_len_mean         | 265      |\n",
      "|    ep_rew_mean         | -133     |\n",
      "| time/                  |          |\n",
      "|    episodes            | 1668     |\n",
      "|    fps                 | 112      |\n",
      "|    time_elapsed        | 5037     |\n",
      "|    total_timesteps     | 566024   |\n",
      "| train/                 |          |\n",
      "|    actor_loss          | 3.35e+21 |\n",
      "|    alpha_mean          | 101      |\n",
      "|    alpha_std           | 54       |\n",
      "|    critic_loss         | inf      |\n",
      "|    dual_loss           | 3.35e+21 |\n",
      "|    kl_loss             | 6.04e+13 |\n",
      "|    learning_rate       | 0.0003   |\n",
      "|    n_updates           | 556000   |\n",
      "|    penalty_temperature | 109      |\n",
      "|    policy_loss         | 8.97e+11 |\n",
      "|    std                 | 1.61e+12 |\n",
      "|    temperature         | 6.11     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter loc (Tensor of shape (100, 4)) of distribution Normal(loc: torch.Size([100, 4]), scale: torch.Size([100, 4])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan]])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m MPO(policy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMlpPolicy\u001b[39m\u001b[39m\"\u001b[39m, env\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBipedalWalker-v3\u001b[39m\u001b[39m\"\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, tensorboard_log\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./logs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jankaiser/Documents/DESY/stable-baselines3-contrib/test_mpo.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m2_000_000\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/DESY/stable-baselines3-contrib/sb3_contrib/mpo/mpo.py:357\u001b[0m, in \u001b[0;36mMPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m: SelfMPO,\n\u001b[1;32m    350\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    356\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfMPO:\n\u001b[0;32m--> 357\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    358\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    359\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    360\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    361\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    362\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    363\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m    364\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/stable-baselines3-contrib/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:331\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[39m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    330\u001b[0m         \u001b[39mif\u001b[39;00m gradient_steps \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size, gradient_steps\u001b[39m=\u001b[39;49mgradient_steps)\n\u001b[1;32m    333\u001b[0m callback\u001b[39m.\u001b[39mon_training_end()\n\u001b[1;32m    335\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/DESY/stable-baselines3-contrib/sb3_contrib/mpo/mpo.py:216\u001b[0m, in \u001b[0;36mMPO.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    213\u001b[0m replay_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplay_buffer\u001b[39m.\u001b[39msample(batch_size, env\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vec_normalize_env)  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 216\u001b[0m     target_distributions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactor_target\u001b[39m.\u001b[39;49mpredict_action_distribution(\n\u001b[1;32m    217\u001b[0m         replay_data\u001b[39m.\u001b[39;49mnext_observations\n\u001b[1;32m    218\u001b[0m     )\u001b[39m.\u001b[39mdistribution\n\u001b[1;32m    219\u001b[0m     next_action_samples \u001b[39m=\u001b[39m target_distributions\u001b[39m.\u001b[39msample((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples,))\n\u001b[1;32m    221\u001b[0m     tiled_observations \u001b[39m=\u001b[39m replay_data\u001b[39m.\u001b[39mobservations\u001b[39m.\u001b[39mtile(\n\u001b[1;32m    222\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples,\n\u001b[1;32m    223\u001b[0m         \u001b[39m*\u001b[39m(\u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(replay_data\u001b[39m.\u001b[39mobservations\u001b[39m.\u001b[39mdim())),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/DESY/stable-baselines3-contrib/sb3_contrib/mpo/policies.py:136\u001b[0m, in \u001b[0;36mActor.predict_action_distribution\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    134\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_features(obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_extractor)\n\u001b[1;32m    135\u001b[0m latent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(features)\n\u001b[0;32m--> 136\u001b[0m distribution \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_action_dist_from_latent(latent)\n\u001b[1;32m    137\u001b[0m \u001b[39mreturn\u001b[39;00m distribution\n",
      "File \u001b[0;32m~/Documents/DESY/stable-baselines3-contrib/sb3_contrib/mpo/policies.py:112\u001b[0m, in \u001b[0;36mActor._get_action_dist_from_latent\u001b[0;34m(self, latent)\u001b[0m\n\u001b[1;32m    109\u001b[0m mean_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_net(latent)\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist, DiagGaussianDistribution):\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_dist\u001b[39m.\u001b[39;49mproba_distribution(mean_actions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_std)\n\u001b[1;32m    113\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[1;32m    114\u001b[0m     \u001b[39m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist\u001b[39m.\u001b[39mproba_distribution(action_logits\u001b[39m=\u001b[39mmean_actions)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/stable-baselines3-contrib/lib/python3.9/site-packages/stable_baselines3/common/distributions.py:164\u001b[0m, in \u001b[0;36mDiagGaussianDistribution.proba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mCreate the distribution given its parameters (mean, std)\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m:return:\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m action_std \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mones_like(mean_actions) \u001b[39m*\u001b[39m log_std\u001b[39m.\u001b[39mexp()\n\u001b[0;32m--> 164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution \u001b[39m=\u001b[39m Normal(mean_actions, action_std)\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/stable-baselines3-contrib/lib/python3.9/site-packages/torch/distributions/normal.py:56\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     batch_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc\u001b[39m.\u001b[39msize()\n\u001b[0;32m---> 56\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(batch_shape, validate_args\u001b[39m=\u001b[39;49mvalidate_args)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/stable-baselines3-contrib/lib/python3.9/site-packages/torch/distributions/distribution.py:62\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m         valid \u001b[39m=\u001b[39m constraint\u001b[39m.\u001b[39mcheck(value)\n\u001b[1;32m     61\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid\u001b[39m.\u001b[39mall():\n\u001b[0;32m---> 62\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     63\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected parameter \u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof distribution \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mto satisfy the constraint \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(constraint)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut found invalid values:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m             )\n\u001b[1;32m     69\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter loc (Tensor of shape (100, 4)) of distribution Normal(loc: torch.Size([100, 4]), scale: torch.Size([100, 4])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan],\n        [nan, nan, nan, nan]])"
     ]
    }
   ],
   "source": [
    "model = MPO(policy=\"MlpPolicy\", env=\"BipedalWalker-v3\", verbose=1, tensorboard_log=\"./logs\")\n",
    "model.learn(total_timesteps=2_000_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable-baselines3-contrib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
